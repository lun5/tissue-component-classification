{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/testing list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3, csv, os\n",
    "from datetime import datetime\n",
    "from sklearn import datasets\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "#from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "# from unsupervised_alt import *\n",
    "from __future__ import division\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = '/home/lun5/ADH/input'\n",
    "im_names = []\n",
    "folder_names = []\n",
    "labels = []\n",
    "with open(os.path.join(input_dir,'Jeff_annotations_ADHAllSets.csv'),'rb') as f:\n",
    "    f_dict = csv.DictReader(f)\n",
    "    for row in f_dict:\n",
    "        im_names.append(row['Image'])\n",
    "        folder_names.append(row['FolderName'])\n",
    "        labels.append(row['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Normal Duct', 'skipped', 'Other', 'Columnar', \"Don't know\", 'ADH', 'Flat Epithelial'])\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "print(set(labels))\n",
    "print(len(set(folder_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Normal Duct has 812 images\n",
      "Label skipped has 12 images\n",
      "Label Other has 150 images\n",
      "Label Columnar has 287 images\n",
      "Label Don't know has 128 images\n",
      "Label ADH has 190 images\n",
      "Label Flat Epithelial has 180 images\n"
     ]
    }
   ],
   "source": [
    "for label in set(labels):\n",
    "    num_im = np.sum(np.array([labels[j] == label for j in xrange(len(labels))]))\n",
    "    print('Label %s has %d images' %(label, num_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adh33-1b_seg54.jpg', 'adh29-2b_seg6.jpg', 'adh23-2b_seg14.jpg', 'adh30-1a_seg58.jpg', 'adh38-1a_seg46.jpg', 'adh08-1b_seg35.jpg', 'adh17-1b_seg12.jpg', 'adh23-2b_seg134.jpg', 'adh13-1a_seg3.jpg', 'adh37-1c_seg63.jpg', 'adh24-1b_seg56.jpg', 'adh30-1b_seg67.jpg']\n",
      "['adh22-2b_seg14.jpg', 'adh23-1a_seg98.jpg', 'adh37-4b_seg77.jpg', 'adh30-1c_seg94.jpg', 'adh37-1a_seg77.jpg', 'adh19-1b_seg16.jpg', 'adh27-2c_seg1.jpg', 'adh10-1b_seg13.jpg', 'adh29-2a_seg26.jpg', 'adh23-1a_seg29.jpg', 'adh08-1a_seg35.jpg', 'adh29-2a_seg12.jpg']\n",
      "['adh33-1b_seg13.jpg', 'adh15-1a_seg13.jpg', 'adh39-1d_seg101.jpg', 'adh31-1c_seg11.jpg', 'adh04-1a_seg3.jpg', 'adh31-1e_seg17.jpg', 'adh33-1b_seg50.jpg', 'adh39-1d_seg66.jpg', 'adh05-1a_seg37.jpg', 'adh47-1a_seg41.jpg', 'adh23-1a_seg13.jpg', 'adh31-1e_seg38.jpg']\n",
      "['adh43-2c_seg4.jpg', 'adh17-1b_seg23.jpg', 'adh19-1a_seg37.jpg', 'adh37-1c_seg64.jpg', 'adh31-1c_seg1.jpg', 'adh23-1a_seg89.jpg', 'adh29-2a_seg36.jpg', 'adh37-3a_seg18.jpg', 'adh31-1b_seg4.jpg', 'adh29-2a_seg1.jpg', 'adh04-1c_seg1.jpg', 'adh11-1a_seg40.jpg']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "np.random.seed(10)\n",
    "sample_indx = []\n",
    "if not os.path.isdir(os.path.join(input_dir,'sample')):\n",
    "    os.makedirs(os.path.join(input_dir,'sample'))\n",
    "for label in ['Normal Duct', 'Columnar', 'Flat Epithelial', 'ADH']:\n",
    "    indx_label = np.nonzero([labels[j] == label for j in xrange(len(labels))])[0]\n",
    "    indx_label = np.random.permutation(indx_label)[:12]\n",
    "    dstdir = os.path.join(input_dir,'sample_indx',label.replace(' ','_'))\n",
    "    if not os.path.isdir(dstdir):\n",
    "        os.makedirs(dstdir)\n",
    "    print([im_names[i] for i in indx_label])\n",
    "    for j in indx_label:\n",
    "        shutil.copy(os.path.join(input_dir,folder_names[j],im_names[j].replace(\n",
    "                    '.jpg','_boundary_2ndPass.jpg')), dstdir)\n",
    "\n",
    "# sample_indx = np.hstack(sample_indx)\n",
    "# [im_names[j] for j in sample_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder_classes = []\n",
    "for folder in list(set(folder_names)):\n",
    "    current_folder = []\n",
    "    for label in ['Normal Duct', 'Columnar', 'Flat Epithelial', 'ADH']:\n",
    "        num_im = np.sum(np.array([(folder_names[j] == folder) and \n",
    "                                  (labels[j] == label) for j in xrange(len(labels))]))\n",
    "        current_folder.append(num_im)\n",
    "    folder_classes.append(np.array(current_folder))\n",
    "        #print('Folder %s, label %s has %d images' %(folder, label, num_im))\n",
    "    #print('\\n')\n",
    "folder_classes = np.vstack(folder_classes[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([115,  71,  30,  48])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(41) # 10\n",
    "indx = np.random.permutation(np.arange(len(set(folder_names))))\n",
    "shuffle_folder_classes = folder_classes[indx,:]\n",
    "np.sum(shuffle_folder_classes[:17,:], axis = 0)\n",
    "#np.sum(folder_classes[:17,:], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([87, 18, 23, 19])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(shuffle_folder_classes[80:89,:],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_list = [list(set(folder_names))[j] for j in indx[:17]]\n",
    "val_list = [list(set(folder_names))[j] for j in indx[80:89]]\n",
    "train_indx = np.hstack([indx[17:80],indx[89:]])\n",
    "train_list = [list(set(folder_names))[j] for j in train_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adh39-1d', 'adh39-1a', 'adh37-3b', 'adh04-1a', 'adh42-1b', 'adh11-1a', 'adh30-1a', 'adh19-1b', 'adh32-1b', 'adh31-1c', 'adh24-1a', 'adh07-1b', 'adh26-1a', 'adh29-2b', 'adh43-1a', 'adh05-1a', 'adh45-3a', 'adh07-1a', 'adh04-1e', 'adh37-1a', 'adh29-3a', 'adh16-1a', 'adh24-1c', 'adh19-2a', 'adh03-2a', 'adh39-1b', 'adh42-1a', 'adh24-1b', 'adh13-1a', 'adh38-1a', 'adh08-1a', 'adh46-2a', 'adh46-2b', 'adh37-1e', 'adh36-1d', 'adh37-1c', 'adh37-1b', 'adh04-1c', 'adh30-1c', 'adh37-1d', 'adh43-2c', 'adh31-1e', 'adh20-1a', 'adh44-1a', 'adh21-1a', 'adh48-1a', 'adh23-1a', 'adh34-1a', 'adh40-1b', 'adh23-3a', 'adh41-1a', 'adh35-1a', 'adh27-2c', 'adh14-1a', 'adh37-4b', 'adh12-1b', 'adh33-1b', 'adh06-1b', 'adh07-1c', 'adh18-1a', 'adh10-1c', 'adh27-1a', 'adh10-1b', 'adh22-2b', 'adh19-1a', 'adh37-4a', 'adh36-1a', 'adh22-2a']\n"
     ]
    }
   ],
   "source": [
    "print(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([163,  49,  36,  25])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes = []\n",
    "for folder in test_list:\n",
    "    current_folder = []\n",
    "    for label in ['Normal Duct', 'Columnar',  'Flat Epithelial','ADH']:\n",
    "        num_im = np.sum(np.array([(folder_names[j] == folder) and \n",
    "                                  (labels[j] == label) for j in xrange(len(labels))]))\n",
    "        current_folder.append(num_im)\n",
    "    test_classes.append(np.array(current_folder))\n",
    "\n",
    "test_classes = np.vstack(test_classes)\n",
    "np.sum(test_classes, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "#curr_list = train_list\n",
    "#curr_list = val_list\n",
    "curr_list = test_list\n",
    "mask_dir = 'masked_images'\n",
    "list_label = []\n",
    "for folder in curr_list:\n",
    "    curr_list_label = []\n",
    "    for label in ['Normal Duct', 'Columnar', 'ADH', 'Flat Epithelial']:\n",
    "        curr_indx = np.nonzero(np.array([folder_names[j] == folder and\n",
    "                             (labels[j] == label) for j in xrange(len(labels))]))[0]\n",
    "        if len(curr_indx) > 0:\n",
    "            for j in curr_indx:\n",
    "                fname = os.path.join(input_dir,mask_dir,im_names[j].replace('.','_boundary_2ndPass_normalized_masked.'))\n",
    "                if os.path.isfile(fname):\n",
    "                    curr_list_label.append((os.path.join(\n",
    "                            mask_dir,im_names[j].replace('.','_boundary_2ndPass_normalized_masked.')),label.replace(' ','_')))\n",
    "            #curr_list_label.append([(os.path.join(\n",
    "            #                mask_dir,im_names[j].replace('.','_boundary_2ndPass_normalized_masked.')),label.replace(' ','_'))\n",
    "            #                   for j in curr_indx])\n",
    "    #list_label.append(sum(curr_list_label[:],[]))\n",
    "    list_label.append(curr_list_label)\n",
    "\n",
    "list_label = sum(list_label[:],[])\n",
    "print(len(list_label))\n",
    "\n",
    "#with open(os.path.join(input_dir,'train_cs.txt'),'w') as fp:\n",
    "#with open(os.path.join(input_dir,'val_cs.txt'),'w') as fp:\n",
    "with open(os.path.join(input_dir,'test_cs.txt'),'w') as fp:\n",
    "     fp.write('\\n'.join('%s %s' %x for x in list_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_sizes = []\n",
    "non_exist_images = []\n",
    "for i in xrange(len(im_names)):\n",
    "    fname = os.path.join(input_dir,mask_dir,im_names[i].replace('.','_boundary_2ndPass_normalized_masked.'))\n",
    "    if os.path.isfile(fname):\n",
    "        im = Image.open(fname)\n",
    "        image_sizes.append(im.size)\n",
    "    else:\n",
    "        non_exist_images.append(im_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adh03-2a_seg53.jpg',\n",
       " 'adh06-1b_seg48.jpg',\n",
       " 'adh08-1b_seg35.jpg',\n",
       " 'adh13-3b_seg8.jpg',\n",
       " 'adh18-1c_seg9.jpg',\n",
       " 'adh18-1c_seg22.jpg',\n",
       " 'adh19-1a_seg18.jpg',\n",
       " 'adh19-1a_seg28.jpg',\n",
       " 'adh25-1a_seg70.jpg',\n",
       " 'adh29-2a_seg52.jpg',\n",
       " 'adh37-4b_seg28.jpg',\n",
       " 'adh45-4c_seg78.jpg',\n",
       " 'adh48-1a_seg19.jpg']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_exist_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1746"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification using PMI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelmap = {'Normal_Duct':0, 'Columnar':1, 'ADH':2, 'Flat_Epithelial':3}\n",
    "n_classes = len(labelmap)\n",
    "\n",
    "def read_data_list(input_path, list_fname):\n",
    "    \"\"\"\n",
    "    Read <train_data_dir>/TRAIN which containing paths and labels in\n",
    "    the format label, channel1 file, channel2 file, channel3 \n",
    "    Returns:\n",
    "        List with all filenames in file image_list_file\n",
    "    \"\"\"\n",
    "    image_list_file = os.path.join(input_path,list_fname)\n",
    "    f = open(image_list_file, 'r') #this can read files from the cloud\n",
    "    filenames = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    n_classes = len(labelmap)\n",
    "    for line in f:\n",
    "        fname, label = line.rstrip().split(' ')\n",
    "        fname = fname.replace('_original.jpg', '_PMIfeatures.mat')\n",
    "        mat_dict = scipy.io.loadmat(os.path.join(input_path, fname))\n",
    "        data.append(mat_dict['features'])\n",
    "        #convert labels into onehot encoding\n",
    "        onehot = np.zeros(n_classes)\n",
    "        onehot[labelmap[label]] = 1.0\n",
    "        labels.append(onehot)\n",
    "        #create absolute paths for image files\n",
    "        filenames.append(os.path.join(input_path, fname))\n",
    "    \n",
    "    data = np.vstack(data)\n",
    "    labels = np.vstack(labels)\n",
    "    return data, labels, filenames, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e623650aa538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/lun5/ADH/input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# read train/val list, # load up the PMI features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_data_list' is not defined"
     ]
    }
   ],
   "source": [
    "input_dir = '/home/lun5/ADH/input'\n",
    "# read train/val list, # load up the PMI features\n",
    "X_train, y_train, _, _ = read_data_list(input_dir,'train.txt')\n",
    "X_val, y_val,_,_ = read_data_list(input_dir,'val.txt')\n",
    "X_test, y_test,_,_ = read_data_list(input_dir,'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary\n",
    "def toBin(labels):\n",
    "    coded_labels = np.argmax(labels,axis = 1)\n",
    "    return np.array([int(coded_labels[i] >1) for i in xrange(len(coded_labels))])\n",
    "\n",
    "toBin(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the input \n",
    "input_dir = '/home/lun5/ADH/input_Feb16'\n",
    "feature_fnames = ['ADHFeatures_maxCooc10_k90_onlynuclei.xls',\n",
    "                  'ADHFeatures_maxCooc10_k95.xls',\n",
    "                  'ADHFeatures_maxCooc10_k90.xls',\n",
    "                  'ADHFeatures_maxCooc5_k90.xls',\n",
    "                  'ADHFeatures_maxCooc10_k95_onlynuclei.xls',\n",
    "                  'ADHFeatures_maxCooc5_k95.xls']\n",
    "\n",
    "gt_fname = 'ADH_annotation.csv'\n",
    "gt = pd.read_csv(os.path.join(input_dir,gt_fname))\n",
    "gt.columns = ['Participant.1','Image', 'Score.1', 'FolderName',\n",
    "             'Participant.2','Score.2','Participant.3','Score.3']\n",
    "#gt = gt.loc[gt['Score.1'].isin(['ADH','Flat Epithelial', 'Columnar', 'Normal Duct']) ,:].loc[\n",
    "#    gt['Score.1'].isin(['ADH','Flat Epithelial', 'Columnar', 'Normal Duct']) ,:]\n",
    "a = list(gt['Score.1'])\n",
    "b = list(gt['Score.2'])\n",
    "c = list(gt['Score.3'])\n",
    "gt.loc[:,('Consensus')] = pd.Series(np.asarray([((a[i] == b[i]) or (a[i]==c[i])) or (b[i] == c[i])\n",
    "                                             for i in xrange(len(a))]), index= reduced_gt.index)\n",
    "gt.loc[:,('ConsensusLabel')] = pd.Series([mode([a[i],b[i],c[i]])[0][0] for i in xrange(len(a))], \n",
    "                                             index=reduced_gt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accepted_labels = ['ADH','Flat Epithelial', 'Columnar', 'Normal Duct',\"Don't know\",'Other']\n",
    "reduced_gt = gt.loc[gt['Score.1'].isin(accepted_labels) & gt[\n",
    "    'Score.2'].isin(accepted_labels) & gt['Score.3'].isin(accepted_labels),:]\n",
    "#reduced_gt = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = list(reduced_gt['Score.1'])\n",
    "b = list(reduced_gt['Score.2'])\n",
    "c = list(reduced_gt['Score.3'])\n",
    "reduced_gt.loc[:,('Consensus')] = pd.Series(np.asarray([((a[i] == b[i]) or (a[i]==c[i])) or (b[i] == c[i])\n",
    "                                             for i in xrange(len(a))]), index= reduced_gt.index)\n",
    "reduced_gt.loc[:,('ConsensusLabel')] = pd.Series([mode([a[i],b[i],c[i]])[0][0] for i in xrange(len(a))], \n",
    "                                             index=reduced_gt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accepted_labels = ['ADH','Flat Epithelial', 'Columnar', 'Normal Duct']\n",
    "reduced_gt = reduced_gt.loc[reduced_gt['ConsensusLabel'].isin(accepted_labels),:]\n",
    "reduced_gt.to_csv(os.path.join(input_dir,'data_concensus_v2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 36, 107, 427]\n",
      "[35, 36, 50, 50]\n"
     ]
    }
   ],
   "source": [
    "index_conc_by_classes = [np.random.permutation(np.nonzero(reduced_gt['ConsensusLabel'].isin([label]) & \n",
    "                                    reduced_gt['Consensus'].isin([True]))[0]) for label in accepted_labels]\n",
    "                         \n",
    "print([len(a) for a in index_conc_by_classes])\n",
    "index_test = [a[:np.minimum(len(a),50)] for a in index_conc_by_classes]\n",
    "print([len(a) for a in index_test])\n",
    "index_test = np.hstack(index_test)\n",
    "test_gt = reduced_gt.iloc[index_test,:]\n",
    "test_gt.to_csv(os.path.join(input_dir,'test_concensus_v2.csv'))\n",
    "index_train = np.delete(xrange(len(reduced_gt)), index_test)\n",
    "train_gt = reduced_gt.iloc[index_train,:]\n",
    "train_gt.to_csv(os.path.join(input_dir,'train_concensus_v2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(os.path.join(input_dir, feature_fnames[0]))\n",
    "data['Image'] = [str(a)[1:-1] for a in list(data.index)]\n",
    "data.index = xrange(len(data))\n",
    "data_label_indx = [list(gt.Image).index(a) for a in list(data.Image)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(input_dir, feature_fname, gt):\n",
    "    data = pd.read_excel(os.path.join(input_dir, feature_fname))\n",
    "    data['imageName'] = [str(a)[1:-1] for a in list(data.imageName)]\n",
    "    data_label_indx = [list(reduced_gt.Image).index(a) for a in list(data.imageName)]\n",
    "    data['Score.1'] = gt.iloc[data_label_indx]['Score.1'].as_matrix()\n",
    "    data['Score.2'] = gt.iloc[data_label_indx]['Score.2'].as_matrix()\n",
    "    data['Score.3'] = gt.iloc[data_label_indx]['Score.3'].as_matrix()\n",
    "    data['ConsensusLabel'] = gt.iloc[data_label_indx]['ConsensusLabel'].as_matrix()\n",
    "\n",
    "    train_indx = data['train/test'].isin([1])\n",
    "    test_indx = data['train/test'].isin([0])\n",
    "    X_train = data.loc[train_indx, data.columns[2:-4]].as_matrix()\n",
    "    X_test =  data.loc[test_indx, data.columns[2:-4]].as_matrix()\n",
    "\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    y_test = dict()\n",
    "    y_test[1] = data.loc[test_indx,'ConsensusLabel'].as_matrix()\n",
    "\n",
    "    y_train = dict()\n",
    "    y_train[1] = data.loc[train_indx,'Score.1'].as_matrix()\n",
    "    y_train[2] = data.loc[train_indx,'Score.2'].as_matrix()\n",
    "    y_train[3] = data.loc[train_indx,'Score.3'].as_matrix()\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = read_data(input_dir, feature_fnames[1], reduced_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Normal Duct', 'Columnar',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Columnar', 'Columnar',\n",
       "       'Columnar', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'Normal Duct', 'Columnar',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Normal Duct', 'Columnar',\n",
       "       \"Don't know\", 'Normal Duct', 'Columnar', 'Normal Duct', 'Columnar',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Columnar', 'Columnar',\n",
       "       'Columnar', 'Normal Duct', 'Normal Duct', 'Normal Duct', 'Columnar',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Flat Epithelial',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Columnar',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Columnar', 'Normal Duct', \"Don't know\", 'Flat Epithelial',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Columnar', 'Normal Duct', 'Columnar', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       \"Don't know\", 'Normal Duct', \"Don't know\", 'Columnar',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Columnar', 'Normal Duct', \"Don't know\",\n",
       "       'Columnar', 'Normal Duct', 'Normal Duct', \"Don't know\",\n",
       "       'Normal Duct', 'Columnar', 'Columnar', \"Don't know\", 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Flat Epithelial', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Columnar', 'Columnar',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Columnar', 'Columnar', 'Columnar', 'Columnar', 'Columnar',\n",
       "       'Normal Duct', 'Columnar', 'Columnar', 'Columnar', 'Columnar',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Columnar', 'Normal Duct', 'Normal Duct',\n",
       "       'Columnar', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'ADH', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Columnar', 'Columnar', 'Columnar', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Other', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Other', 'Normal Duct', 'Normal Duct', 'Columnar',\n",
       "       'Columnar', 'Columnar', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'ADH', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Columnar', 'Columnar',\n",
       "       'Flat Epithelial', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Columnar',\n",
       "       'Flat Epithelial', 'Normal Duct', 'Normal Duct', 'Columnar',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Columnar',\n",
       "       'Normal Duct', 'Flat Epithelial', 'Flat Epithelial', 'Columnar',\n",
       "       'Flat Epithelial', 'Columnar', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Columnar', 'Columnar', 'Columnar',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'Columnar', 'Columnar',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       \"Don't know\", 'Columnar', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Columnar', 'Columnar', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Columnar', 'Columnar', 'Normal Duct',\n",
       "       'Columnar', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'ADH', 'Normal Duct', 'Normal Duct',\n",
       "       'Columnar', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       \"Don't know\", 'Normal Duct', 'Columnar', 'Columnar', 'Normal Duct',\n",
       "       'Columnar', 'Columnar', 'Columnar', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Columnar',\n",
       "       'Normal Duct', 'Columnar', 'Normal Duct', \"Don't know\", 'ADH',\n",
       "       \"Don't know\", \"Don't know\", 'Columnar', 'Normal Duct', 'Columnar',\n",
       "       'Columnar', 'Columnar', 'Columnar', 'ADH', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Columnar', 'Flat Epithelial', 'Columnar',\n",
       "       'Columnar', 'Columnar', 'Flat Epithelial', 'Normal Duct',\n",
       "       'Columnar', 'Normal Duct', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', \"Don't know\", 'Columnar', 'Normal Duct',\n",
       "       'Normal Duct', 'Other', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct', 'Normal Duct',\n",
       "       'Normal Duct', 'Normal Duct', 'Normal Duct'], dtype=object)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(os.path.join(input_dir, feature_fnames[1]))\n",
    "data['imageName'] = [str(a)[1:-1] for a in list(data.imageName)]\n",
    "data_label_indx = [list(reduced_gt.Image).index(a) for a in list(data.imageName)]\n",
    "data['Score.1'] = reduced_gt.iloc[data_label_indx]['Score.1'].as_matrix()\n",
    "data['Score.2'] = reduced_gt.iloc[data_label_indx]['Score.2'].as_matrix()\n",
    "data['Score.3'] = reduced_gt.iloc[data_label_indx]['Score.3'].as_matrix()\n",
    "data['ConsensusLabel'] = reduced_gt.iloc[data_label_indx]['ConsensusLabel'].as_matrix()\n",
    "\n",
    "train_indx = data['train/test'].isin([1])\n",
    "test_indx = data['train/test'].isin([0])\n",
    "X_train = data.loc[train_indx, data.columns[2:]].as_matrix()\n",
    "X_test =  data.loc[test_indx, data.columns[2:]].as_matrix()\n",
    "\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "y_test = dict()\n",
    "y_test[1] = data.loc[test_indx,'ConsensusLabel'].as_matrix()\n",
    "\n",
    "y_train = dict()\n",
    "y_train[1] = data.loc[train_indx,'Score.1'].as_matrix()\n",
    "y_train[2] = data.loc[train_indx,'Score.2'].as_matrix()\n",
    "y_train[3] = data.loc[train_indx,'Score.3'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = read_data(input_dir, feature_fnames[0], gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = read_data(input_dir, feature_fnames[0], gt)\n",
    "ADH_map = {0:0, 1:0, 2:0, 3:1}\n",
    "y_train = [ADH_map[a] for a in y_train]\n",
    "y_test = [ADH_map[a] for a in y_test]\n",
    "#malig_map = {0:0, 1:0, 2:1, 3:1}\n",
    "#y_train = [malig_map[a] for a in y_train]\n",
    "#y_test = [malig_map[a] for a in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ADH': 28}, {'Columnar': 223}, {'Flat Epithelial': 136}, {'Normal Duct': 1134}, {'Other': 162}, {\"Don't know\": 76}]\n",
      "[{'ADH': 190}, {'Columnar': 287}, {'Flat Epithelial': 180}, {'Normal Duct': 812}, {'Other': 150}, {\"Don't know\": 128}]\n"
     ]
    }
   ],
   "source": [
    "olga_score = gt['Score.3']\n",
    "print([{a:sum(olga_score == a)} for a in ['ADH', 'Columnar', 'Flat Epithelial', 'Normal Duct', 'Other', \"Don't know\"]])\n",
    "jeff_score = gt['Score.1']\n",
    "print([{a:sum(jeff_score == a)} for a in ['ADH', 'Columnar', 'Flat Epithelial', 'Normal Duct', 'Other', \"Don't know\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build cross validation to find the optimal settings for parameters\n",
    "def RF_classifier(X_train, y_train, X_test, y_test):\n",
    "    tuned_parameters = [{'n_estimators':[2, 10, 50, 100], \n",
    "                        'max_features':['auto','log2'],\n",
    "                        'max_depth':[5,10,None],\n",
    "                       'class_weight':['balanced','balanced_subsample']}]\n",
    "\n",
    "    scores = ['f1','precision','recall']\n",
    "    scores = ['recall']\n",
    "    for score in scores:\n",
    "        print('Tuning parameter for %s' %score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(RandomForestClassifier(n_estimators=10),tuned_parameters,\n",
    "                           cv = 6, scoring= '%s_macro' %score, n_jobs = 5)\n",
    "        #clf.fit(X_train,toBin(y_train))\n",
    "        clf.fit(X_train,y_train)\n",
    "        #clf.fit(np.vstack([X_train,X_val]),toBin(np.vstack([y_train,y_val])))\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        best_params = clf.best_params_\n",
    "        print()\n",
    "        #print(\"Grid scores on development set:\")\n",
    "        #print()\n",
    "        #means = clf.cv_results_['mean_test_score']\n",
    "        #stds = clf.cv_results_['std_test_score']\n",
    "        #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        #          % (mean, std * 2, params))\n",
    "        #print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"Training result\")\n",
    "        y_true, y_pred = y_train, clf.predict(X_train)\n",
    "        #y_true, y_pred = toBin(y_val), clf.predict(X_val)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('Accuracy = ', metrics.accuracy_score(y_true,y_pred))\n",
    "\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        #y_true, y_pred = toBin(y_test), clf.predict(X_test)\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        #y_true, y_pred = toBin(y_val), clf.predict(X_val)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('Accuracy = ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADHFeatures_maxCooc10_k90_onlynuclei.xls',\n",
       " 'ADHFeatures_maxCooc10_k95.xls',\n",
       " 'ADHFeatures_maxCooc10_k90.xls',\n",
       " 'ADHFeatures_maxCooc5_k90.xls',\n",
       " 'ADHFeatures_maxCooc10_k95_onlynuclei.xls',\n",
       " 'ADHFeatures_maxCooc5_k95.xls']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADHFeatures_maxCooc10_k90_onlynuclei.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 10, 'max_depth': 5, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.66      0.78      1022\n",
      "          1       0.24      0.74      0.36       152\n",
      "\n",
      "avg / total       0.85      0.67      0.72      1174\n",
      "\n",
      "Accuracy =  0.667802385009\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.67      0.77       257\n",
      "          1       0.16      0.42      0.23        38\n",
      "\n",
      "avg / total       0.79      0.64      0.70       295\n",
      "\n",
      "Accuracy =  0.640677966102\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 50, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.62      0.73       878\n",
      "          1       0.41      0.80      0.54       296\n",
      "\n",
      "avg / total       0.78      0.66      0.69      1174\n",
      "\n",
      "Accuracy =  0.663543441227\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.61      0.69       221\n",
      "          1       0.31      0.53      0.39        74\n",
      "\n",
      "avg / total       0.67      0.59      0.62       295\n",
      "\n",
      "Accuracy =  0.589830508475\n",
      "ADHFeatures_maxCooc10_k95.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 50, 'max_depth': 5, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.80      0.87      1022\n",
      "          1       0.37      0.81      0.51       152\n",
      "\n",
      "avg / total       0.89      0.80      0.83      1174\n",
      "\n",
      "Accuracy =  0.798977853492\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.81      0.85       257\n",
      "          1       0.23      0.39      0.29        38\n",
      "\n",
      "avg / total       0.81      0.75      0.78       295\n",
      "\n",
      "Accuracy =  0.752542372881\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'n_estimators': 100, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.75      0.82       878\n",
      "          1       0.52      0.78      0.62       296\n",
      "\n",
      "avg / total       0.81      0.76      0.77      1174\n",
      "\n",
      "Accuracy =  0.760647359455\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.73      0.76       221\n",
      "          1       0.36      0.46      0.40        74\n",
      "\n",
      "avg / total       0.69      0.66      0.67       295\n",
      "\n",
      "Accuracy =  0.661016949153\n",
      "ADHFeatures_maxCooc10_k90.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 50, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.79      0.87      1022\n",
      "          1       0.36      0.81      0.50       152\n",
      "\n",
      "avg / total       0.89      0.79      0.82      1174\n",
      "\n",
      "Accuracy =  0.792163543441\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.83      0.86       257\n",
      "          1       0.24      0.37      0.29        38\n",
      "\n",
      "avg / total       0.81      0.77      0.79       295\n",
      "\n",
      "Accuracy =  0.769491525424\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'n_estimators': 100, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.77      0.84       878\n",
      "          1       0.54      0.82      0.65       296\n",
      "\n",
      "avg / total       0.83      0.78      0.79      1174\n",
      "\n",
      "Accuracy =  0.781942078365\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.75      0.79       221\n",
      "          1       0.42      0.54      0.47        74\n",
      "\n",
      "avg / total       0.73      0.70      0.71       295\n",
      "\n",
      "Accuracy =  0.698305084746\n",
      "ADHFeatures_maxCooc5_k90.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'n_estimators': 2, 'max_depth': 5, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.77      0.83      1022\n",
      "          1       0.25      0.53      0.34       152\n",
      "\n",
      "avg / total       0.83      0.73      0.77      1174\n",
      "\n",
      "Accuracy =  0.734241908007\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.72      0.80       257\n",
      "          1       0.19      0.45      0.27        38\n",
      "\n",
      "avg / total       0.81      0.68      0.73       295\n",
      "\n",
      "Accuracy =  0.684745762712\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 50, 'max_depth': 5, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.78      0.84       878\n",
      "          1       0.53      0.73      0.62       296\n",
      "\n",
      "avg / total       0.81      0.77      0.78      1174\n",
      "\n",
      "Accuracy =  0.771720613288\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.68      0.72       221\n",
      "          1       0.27      0.35      0.31        74\n",
      "\n",
      "avg / total       0.64      0.60      0.62       295\n",
      "\n",
      "Accuracy =  0.6\n",
      "ADHFeatures_maxCooc10_k95_onlynuclei.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'n_estimators': 50, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.75      0.84      1022\n",
      "          1       0.30      0.73      0.43       152\n",
      "\n",
      "avg / total       0.86      0.74      0.78      1174\n",
      "\n",
      "Accuracy =  0.744463373083\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.80      0.85       257\n",
      "          1       0.24      0.42      0.30        38\n",
      "\n",
      "avg / total       0.82      0.75      0.78       295\n",
      "\n",
      "Accuracy =  0.749152542373\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 100, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.76      0.82       878\n",
      "          1       0.51      0.74      0.60       296\n",
      "\n",
      "avg / total       0.80      0.75      0.77      1174\n",
      "\n",
      "Accuracy =  0.752981260647\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.81      0.82       221\n",
      "          1       0.47      0.49      0.48        74\n",
      "\n",
      "avg / total       0.74      0.73      0.73       295\n",
      "\n",
      "Accuracy =  0.732203389831\n",
      "ADHFeatures_maxCooc5_k95.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'n_estimators': 2, 'max_depth': 5, 'class_weight': 'balanced'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.67      0.77      1022\n",
      "          1       0.20      0.55      0.29       152\n",
      "\n",
      "avg / total       0.82      0.65      0.71      1174\n",
      "\n",
      "Accuracy =  0.65332197615\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.66      0.76       257\n",
      "          1       0.16      0.45      0.24        38\n",
      "\n",
      "avg / total       0.80      0.63      0.69       295\n",
      "\n",
      "Accuracy =  0.633898305085\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "Train on P 1 . Test on P 1\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 10, 'max_depth': 5, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "Training result\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.81      0.83       878\n",
      "          1       0.50      0.56      0.53       296\n",
      "\n",
      "avg / total       0.76      0.75      0.75      1174\n",
      "\n",
      "Accuracy =  0.749574105622\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.72      0.74       221\n",
      "          1       0.28      0.32      0.30        74\n",
      "\n",
      "avg / total       0.64      0.62      0.63       295\n",
      "\n",
      "Accuracy =  0.620338983051\n"
     ]
    }
   ],
   "source": [
    "ADH_map = {'Normal Duct':0, 'Columnar':0, 'Flat Epithelial':0, 'ADH':1}\n",
    "malig_map = {'Normal Duct':0, 'Columnar':0, 'Flat Epithelial':1, 'ADH':1}\n",
    "\n",
    "for i in xrange(len(feature_fnames)):\n",
    "    print(feature_fnames[i])\n",
    "    X_train, y_train, X_test, y_test = read_data(input_dir, feature_fnames[i], gt)\n",
    "    for dict_map in [ADH_map, malig_map]:\n",
    "        print(dict_map)\n",
    "        #for j,k in product([1,2],[1,2]):\n",
    "        for j,k in zip([1],[1]):\n",
    "            print('Train on P', str(j), '. Test on P', str(k))\n",
    "            y_train_new = [dict_map[a] for a in y_train[j]]\n",
    "            y_test_new = [dict_map[b] for b in y_test[k]]\n",
    "            RF_classifier(X_train, y_train_new, X_test, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.71      0.79       257\n",
      "          1       0.18      0.42      0.25        38\n",
      "\n",
      "avg / total       0.80      0.67      0.72       295\n",
      "\n",
      "0.671186440678\n"
     ]
    }
   ],
   "source": [
    "#{'max_features': 'auto', 'n_estimators': 10, 'max_depth': 10, 'class_weight': 'balanced_subsample'}\n",
    "clf = RandomForestClassifier(n_estimators=best_params['n_estimators'], max_features=best_params['max_features'],\n",
    "                            max_depth=best_params['max_depth'],class_weight=best_params['class_weight'])\n",
    "clf.fit(X_train,y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true is  [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0]  y_pred is  [1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1\n",
      " 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1\n",
      " 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1\n",
      " 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 1 0 0 0]\n",
      "accuracy is  0.643939393939\n"
     ]
    }
   ],
   "source": [
    "print('y_true is ',y_true, ' y_pred is ', y_pred)\n",
    "print('accuracy is ', metrics.accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.78      0.80       216\n",
      "          1       0.16      0.19      0.17        48\n",
      "\n",
      "avg / total       0.69      0.67      0.68       264\n",
      "\n",
      "0.674242424242\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_features='auto',\n",
    "                            max_depth=5,class_weight='balanced_subsample')\n",
    "clf.fit(np.vstack([X_train,X_val]),toBin(np.vstack([y_train,y_val])))\n",
    "y_true, y_pred = toBin(y_test), clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = read_data(input_dir, feature_fnames[0], gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning parameter for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 50, 'max_depth': 10, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.57      0.59       163\n",
      "          1       0.22      0.14      0.17        58\n",
      "          2       0.10      0.17      0.12        36\n",
      "          3       0.17      0.21      0.19        38\n",
      "\n",
      "avg / total       0.42      0.39      0.40       295\n",
      "\n",
      "\n",
      "Tuning parameter for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'n_estimators': 10, 'max_depth': 10, 'class_weight': 'balanced_subsample'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.64      0.64       163\n",
      "          1       0.26      0.16      0.20        58\n",
      "          2       0.12      0.17      0.14        36\n",
      "          3       0.24      0.29      0.27        38\n",
      "\n",
      "avg / total       0.45      0.44      0.44       295\n",
      "\n",
      "\n",
      "Tuning parameter for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'log2', 'n_estimators': 2, 'max_depth': 10, 'class_weight': 'balanced'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.47      0.53       163\n",
      "          1       0.23      0.12      0.16        58\n",
      "          2       0.10      0.14      0.11        36\n",
      "          3       0.16      0.37      0.22        38\n",
      "\n",
      "avg / total       0.42      0.35      0.37       295\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build cross validation to find the optimal settings for parameters\n",
    "tuned_parameters = [{'n_estimators':[2, 10, 50, 100], \n",
    "                    'max_features':['auto','log2'],\n",
    "                    'max_depth':[5,10,None],\n",
    "                   'class_weight':['balanced','balanced_subsample']}]\n",
    "\n",
    "scores = ['f1','precision','recall']\n",
    "\n",
    "for score in scores:\n",
    "    print('Tuning parameter for %s' %score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(RandomForestClassifier(n_estimators=10),tuned_parameters,\n",
    "                       cv = 5, scoring= '%s_macro' %score, n_jobs = 5)\n",
    "    clf.fit(X_train,y_train)\n",
    "    #clf.fit(np.vstack([X_train,X_val]),np.vstack([y_train,y_val]))\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    #print(\"Grid scores on development set:\")\n",
    "    #print()\n",
    "    #means = clf.cv_results_['mean_test_score']\n",
    "    #stds = clf.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "    #          % (mean, std * 2, params))\n",
    "    #print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    #y_true, y_pred = y_val, clf.predict(X_val)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.62      0.62       163\n",
      "          1       0.19      0.10      0.13        58\n",
      "          2       0.16      0.25      0.20        36\n",
      "          3       0.19      0.21      0.20        38\n",
      "\n",
      "avg / total       0.42      0.42      0.42       295\n",
      "\n",
      "0.420338983051\n"
     ]
    }
   ],
   "source": [
    "#{'max_features': 'auto', 'n_estimators': 10, 'max_depth': 10, 'class_weight': 'balanced_subsample'}\n",
    "clf = RandomForestClassifier(n_estimators=10, max_features='auto',\n",
    "                            max_depth=10,class_weight='balanced_subsample')\n",
    "#clf.fit(np.vstack([X_train,X_val]),np.vstack([y_train,y_val]))\n",
    "clf.fit(X_train,y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.73      0.59       115\n",
      "          1       0.14      0.01      0.03        71\n",
      "          2       0.00      0.00      0.00        30\n",
      "          3       0.50      0.04      0.08        48\n",
      "\n",
      "avg / total       0.35      0.33      0.28       264\n",
      "\n",
      "0.329545454545\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, max_features='auto',\n",
    "                            max_depth=None,class_weight='balanced')\n",
    "clf.fit(np.vstack([X_train,X_val]),np.vstack([y_train,y_val]))\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning parameter for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       216\n",
      "          1       0.00      0.00      0.00        48\n",
      "\n",
      "avg / total       0.67      0.82      0.74       264\n",
      "\n",
      "\n",
      "Tuning parameter for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90       216\n",
      "          1       0.00      0.00      0.00        48\n",
      "\n",
      "avg / total       0.67      0.82      0.74       264\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100]}]\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3,1e-4],\n",
    "#                      'C': [1, 100,1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print('Tuning parameter for %s' %score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=3,\n",
    "                       scoring='%s_macro' % score,n_jobs = 4)\n",
    "    \n",
    "    clf.fit(X_train,toBin(y_train))\n",
    "    \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    #print(\"Grid scores on development set:\")\n",
    "    #print()\n",
    "    #means = clf.cv_results_['mean_test_score']\n",
    "    #stds = clf.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "    #          % (mean, std * 2, params))\n",
    "    #print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = toBin(y_test), clf.predict(X_test)\n",
    "    #y_true, y_pred = toBin(y_val), clf.predict(X_val)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.99      0.82       186\n",
      "          1       0.33      0.01      0.02        78\n",
      "\n",
      "avg / total       0.60      0.70      0.59       264\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-004ac3508fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoBin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf',gamma=1e-4, C=10)\n",
    "clf.fit(np.vstack([X_train,X_val]),toBin(np.vstack([y_train,y_val])))\n",
    "y_true, y_pred = toBin(y_test), clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning parameter for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.143 (+/-0.001) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.143 (+/-0.000) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.411 (+/-0.036) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.439 (+/-0.086) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.424 (+/-0.026) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.413 (+/-0.064) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.97      0.79        78\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.40      0.11      0.17        18\n",
      "          3       0.20      0.08      0.11        13\n",
      "\n",
      "avg / total       0.50      0.64      0.53       124\n",
      "\n",
      "\n",
      "Tuning parameter for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.250 (+/-0.001) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.250 (+/-0.000) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.368 (+/-0.038) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.328 (+/-0.049) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.401 (+/-0.002) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.355 (+/-0.043) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.78        78\n",
      "          1       0.00      0.00      0.00        15\n",
      "          2       0.14      0.11      0.12        18\n",
      "          3       0.27      0.31      0.29        13\n",
      "\n",
      "avg / total       0.50      0.58      0.54       124\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3,1e-4],\n",
    "                     'C': [1, 100,1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print('Tuning parameter for %s' %score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=3,\n",
    "                       scoring='%s_macro' % score,n_jobs = 8)\n",
    "    \n",
    "    clf.fit(X_train,np.argmax(y_train,axis = 1))\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = np.argmax(y_val,axis = 1), clf.predict(X_val)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.90      0.63       115\n",
      "          1       0.46      0.08      0.14        71\n",
      "          2       0.30      0.12      0.18        48\n",
      "          3       0.24      0.13      0.17        30\n",
      "\n",
      "avg / total       0.42      0.45      0.37       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf',gamma=1e-3, C=100)\n",
    "clf.fit(X_train,np.argmax(y_train,axis =1))\n",
    "y_true, y_pred = np.argmax(y_test,axis=1), clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPL classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "tuned_parameters = [{'hidden_layer_size'= [(100,),(10,)] , \n",
    "                     'alpha'=[1e-4,1e-2,1],\n",
    "                    'learning_rate'=['constant','adaptive']}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print('Tuning parameter for %s' %score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(MLPClassifier(alpha=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    \n",
    "    clf.fit(X_train,np.argmax(y_train,axis = 1))\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = np.argmax(y_val,axis = 1), clf.predict(X_val)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classification using color stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_fname = 'PospectorImages_clusterRatios.csv'\n",
    "data_imnames = []\n",
    "cs_data = []\n",
    "\n",
    "with open(os.path.join(input_dir,data_fname)) as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    feat_indx = np.nonzero([not f_csv.fieldnames[j] in ['FileName'] \n",
    "                            for j in xrange(len(f_csv.fieldnames))])[0]\n",
    "    feat_names = [f_csv.fieldnames[feat_indx[j]] for j in xrange(len(feat_indx))]\n",
    "    for row in f_csv:\n",
    "        data_imnames.append(row['FileName'])\n",
    "        cs_data.append([float(row[feat_names[j]]) for j in xrange(len(feat_indx))])\n",
    "\n",
    "cs_data = np.vstack(cs_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1759, 8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_id = [data_imnames[j] == im_names[j].replace('.jpg','') for j in xrange(len(im_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I will have the match the image name with labels\n",
    "# data_imlabels = []\n",
    "# for fname in data_imnames:\n",
    "#     indx = im_names.index((fname + '.jpg'))\n",
    "#     data_imlabels.append(labels[indx])\n",
    "data_imlabels = [labels[im_names.index(fname + '.jpg')] for fname in data_imnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelmap = {'Normal_Duct':0, 'Columnar':1, 'Flat_Epithelial':2, 'ADH':3}\n",
    "n_classes = len(labelmap)\n",
    "\n",
    "def read_data_list(input_path, list_fname):\n",
    "    \"\"\"\n",
    "    Read <train_data_dir>/TRAIN which containing paths and labels in\n",
    "    the format label, channel1 file, channel2 file, channel3 \n",
    "    Returns:\n",
    "        List with all filenames in file image_list_file\n",
    "    \"\"\"\n",
    "    image_list_file = os.path.join(input_path,list_fname)\n",
    "    f = open(image_list_file, 'r') #this can read files from the cloud\n",
    "    filenames = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    n_classes = len(labelmap)    \n",
    "    \n",
    "    for line in f:\n",
    "        fname, label = line.rstrip().split(' ')\n",
    "        dir_name, fname = fname.rstrip().split('/')\n",
    "        indx = data_imnames.index(fname.replace('_boundary_2ndPass_normalized_masked.jpg', ''))\n",
    "        data.append(cs_data[indx,:])\n",
    "        #convert labels into onehot encoding\n",
    "        onehot = np.zeros(n_classes)\n",
    "        onehot[labelmap[label]] = 1.0\n",
    "        labels.append(onehot)\n",
    "        #create absolute paths for image files\n",
    "        filenames.append(os.path.join(input_path, fname))\n",
    "    \n",
    "    data = np.vstack(data)\n",
    "    labels = np.vstack(labels)\n",
    "    labels_coded = np.argmax(labels, axis = 1)\n",
    "    return data, labels, labels_coded\n",
    "\n",
    "def toBin(labels):\n",
    "    coded_labels = np.argmax(labels,axis = 1)\n",
    "    return np.array([int(coded_labels[i] >2) for i in xrange(len(coded_labels))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = '/home/lun5/ADH/input'\n",
    "# read train/val list, # load up the PMI features\n",
    "X_train, y_train,y_train_coded = read_data_list(input_dir,'train_cs.txt')\n",
    "X_val, y_val,y_val_coded = read_data_list(input_dir,'val_cs.txt')\n",
    "X_test, y_test,y_test_coded = read_data_list(input_dir,'test_cs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132, 132, 132, 132]\n"
     ]
    }
   ],
   "source": [
    "population = [np.sum(y_train_coded  == j) for j in xrange(4)]\n",
    "sample_indices = [np.random.choice(np.nonzero(y_train_coded == i)[0],\n",
    "                                 size = np.sum(y_train_coded == np.argmin(population)), replace = False)\n",
    "                  for i in xrange(4)]\n",
    "sample_indices = np.hstack(sample_indices)\n",
    "X_train, y_train, y_train_coded = X_train[sample_indices,:],y_train[sample_indices,:],y_train_coded[sample_indices] \n",
    "print([np.sum(y_train_coded  == j) for j in xrange(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86, 18, 23, 19]\n",
      "[18, 18, 18, 18]\n"
     ]
    }
   ],
   "source": [
    "population = [np.sum(y_val_coded  == j) for j in xrange(4)]\n",
    "print(population)\n",
    "sample_indices = [np.random.choice(np.nonzero(y_val_coded == i)[0],\n",
    "                                 size = np.sum(y_val_coded == np.argmin(population)),\n",
    "                                   replace = False)\n",
    "                  for i in xrange(4)]\n",
    "sample_indices = np.hstack(sample_indices)\n",
    "X_val, y_val, y_val_coded = X_val[sample_indices,:],y_val[sample_indices,:],y_val_coded[sample_indices] \n",
    "print([np.sum(y_val_coded  == j) for j in xrange(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158, 49, 25, 36]\n",
      "[25, 25, 25, 25]\n"
     ]
    }
   ],
   "source": [
    "population = [np.sum(y_test_coded  == j) for j in xrange(4)]\n",
    "print(population)\n",
    "sample_indices = [np.random.choice(np.nonzero(y_test_coded == i)[0],\n",
    "                                 size = np.sum(y_test_coded == np.argmin(population)),\n",
    "                                   replace = False)\n",
    "                  for i in xrange(4)]\n",
    "sample_indices = np.hstack(sample_indices)\n",
    "X_test, y_test, y_test_coded = X_test[sample_indices,:],y_test[sample_indices,:],y_test_coded[sample_indices] \n",
    "print([np.sum(y_test_coded  == j) for j in xrange(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test imbalanced learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.27      0.79      0.41      0.35      0.13       257\n",
      "          1       0.14      0.79      0.27      0.23      0.35      0.11        38\n",
      "\n",
      "avg / total       0.80      0.34      0.72      0.39      0.35      0.13       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "pipeline = make_pipeline(NearMiss(version=2, random_state=RANDOM_STATE),\n",
    "                         LinearSVC(random_state=RANDOM_STATE))\n",
    "pipeline.fit(X_train, y_train_new)\n",
    "\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(y_test_new, pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/matplotlib/axes/_axes.py:531: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAAK9CAYAAADfSAZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xd4VFX+x/H3SaP3Jr0LiKAYQETAAoiFFXTXiqsCIuq6\n2F11f7q76Kpr17WjKNZVdhWsKE2KglQVEem9GgKhhISU8/vjzAyTIZ1M7mTm83qePGZm7p37vZMY\n5jPnnO811lpEREREREQkPOK8LkBERERERCSaKXSJiIiIiIiEkUKXiIiIiIhIGCl0iYiIiIiIhJFC\nl4iIiIiISBgpdImIiIiIiISRQpeIiIiIiEgYKXSJiIiIiIiEkUKXiIiIiIhIGCl0iYgUkzFmizHm\n1aDb/Y0xucaY3sXYd64x5usyruchY0xWWT6nlJwxpq3v9+DKEmw7pjxqExGRyKDQJSJRxRgz2Rhz\n0BhTrZBt3jXGZBpj6pTw6W0x7yvuvkUyxlQzxvzNGNOngOfMLc3zlgVjTCVjzB3GmO+NMXuNMYeM\nMb8aY54zxrTzqi6P5Pn5GmMuMMbcH44DGWNaGWMmGGPW+F7zbcaYWaHH8wX9XGPMLwU8z7m+x3ON\nMRfm8/iJvv9XthpjMnwfOrxljOkUtE180HMU9pVjjOkdFDoL2ub2Yr4GccaYkcaYb4wxqb7/n9cb\nY143xnQrYJ8xvuPMKeDx/M5lrzFmhjHm3KDtKpXgnHsW53xEJPoleF2AiEgZexcYDFwEvBP6oDGm\nCnAh8IW1ds+xHMhaO90YU8Vae/hYnqcI1YG/AVnA3JDH/gaMDeOxC2SMqQ9MBboCn+Je64NAB+AK\nYASu9qhnrV2bz+/BYGAk8GBZHssY0x5YBOwDxgMbgcZAMnBXyPEscAjoYIw52Vr7Q8jTDfM9Xjmf\n41yC+5n+BrwGbABaA9cBlxhjLrHWfmatzTHGXBWy+wjgDOBqwATdvxKo7fv+beCrfE5xcYEnf6S2\nKsBkoD/wDfAQkOqr71LgGmNME2vtrpBdrwTWA72NMS2ttRsLOMQU3LkboBVwI/CpMeYca+1M4DAQ\nes7XAb2B4eQ95zVFnY+IxAaFLhGJNp8AB3BvsI4KXcBQoCounB2zMAcuyPsGLvTYuXg30vUO0BkY\naq39NPgB34jLQ2VxEGNMAoC1Nrssni9c8vk9KPDndozuBJKAU6212/Ic0AXhUCtx4fcK4IegbasA\nQ4DPgd+HPE974E3fvv2stXuDHnsW+BZ41xjTxVq7yVr7Xsj+fX37vR9ajDHGH7oWh+5XAk/jAtef\nrbUvhjz/33GvkQm5vz3QE/eBy5u4vw+PFPD8vwbXZoyZDPwE3ALMtNZaIPSczwJ65XfOIiKg6YUi\nEmWstRnAR0D/At6EXgnsx43OAGCM+Ysx5ltjzG5jTLoxZqExZmhRxzIFrOkyxtxojFnre655oY/7\ntqlkjHnQGLPYN4XpgG+qVN+gbdoC23AjFg8FTVu6z/f4UWu6jDEJxk1HXOubErbOGDPWGJMYst0W\nY8xHxph+xpgFxk1TW2OKty6pN3AO8Epo4AIXQKy1dwdtn+96NmPMO8aY1cHn6zu/W4wxtxtj1uJG\nYk4zxmQbY+7N5zlO8O1zfdB9tY2b4rjJ9xqsMsbcWYzzetYYsyPkvpd8z39D0H1NfPeNDKn7St/t\nt4HrgeDpakeFc2PMaN/P6ZAxZr4pYFpciDbAptDABWCtTSlgn/eBy0PuG4oLbxM5OiD+BTf6dV1w\n4PIdYzdu5KcGLtyUK2NMc9wI4hehgQvAOo9ba3eGPDQMSAG+AP7nu10s1tqfgb1A21IXLiIxT6FL\nRKLRu0AibqpRgHFruM4BPrLWZgY9NAY3ren/gHtxo0f/M8acU4xjha7lGQ28AGzGTfeahwt4TUL2\nqw1cC0wH7gb+DhwHfG2M6ezbZgfwJ9yb4om4KU1XAZOCjh26VuxN3LTD74HbgDm+8wod9bO4qYD/\nwU2nuh1IAyb4RgUKc6Fv//xGEvNT0Hq2/OoHGAWMBl4G7gDW4qZWXprPtpfjpl7+F8AYUxV3zpcB\nbwB/xv0MHjPGPFZEnXOABsaY44Pu6wPkAH2D7uvnq3t2Ac/zAjAD93s0DPczuzpkm2uAW4EXgftx\nb+j/Z4wp6t/ljUArY0y/IrYL9h7Q3ORdF3gF8DVuWl6owcAaa+2C/J7MN8Vui2+70qpmjKmXz1d8\nEftdgHvvUtzfPb8rgYm+0eH3gU7GmJOKs6Pv70ZN4JimI4tIbNP0QhGJRjOA7bg3WsGfhl+K+7sX\nOrWwTXAIM8a8APyICy3F7jjoG016CFgI9LfW5vjuXwm8hAsPfr8BrYOnzRljxgGrgZuBG621B40x\nH+HexP9Y1HQsY8wp/nO21t7su/slY8xu4BZjzOnW2m+DdukI9LbWfu/b/yNgE25dyn2FHMrfSGFZ\nYfUcg8ZA25BpbR8AzxtjjrfWrgra9lJghrXWHx7uBloAJ1lrN/juG2eM2Yl7DZ6y1uYZzQoyBxdw\n+wKrfG+2T8AF3uDQ1QfYZa1dffRTgLV2vm8EL98pdj5NgXbW2gO+81uLC44DKPx37llcYJppjPkB\nmAXMBKb6Rnnzq2elb9srgbnGmHrAII4Oghhj6gINKThQ+v0EnGeMqVzQcYvwEPDP0FKBHsCSQvYr\n8e+eMeZUoB1uhAzca7YDF4h/zGeXyr7XyODWif2TIx98iIiUika6RCTq+D7N/g9uWlqLoIeuBHbi\nQlnw9sGBqzZuFGoucEoJD30qUA94yR+4fMbjpjTmqdEfuIxTBzc6t6gUx/U7H/fG9emQ+5/EvWm8\nIOT+n/yBy1fTTlzoa1PEcWq6zW16Kessyoeh09pwgSQXN4IFgDHmZOB43M/a7w+45gr7g0dQgGm4\n1zc4POXhO/81uJEsfNtm4l6/ZsaYlkH3hzY1Kan3/IHLxx/4Cn3trbXLgG640avWuHVGk4Gdxpjh\nhR0P+INvJOkS3Hl9ks92NXz/3Z/PY8H8j9codKuCvYQLmMFfA3HryApTs5j1BRsGbLXWzgH3iwt8\niAuv+RmN+1BkF27EuC/wiLX23yU4pohIHgpdIhKt3sW9ifWvs2mKG6F43/emK8AYc6FvTc0h3HSr\nXbgpbrVKeMyWuNCTp2OZtTYL1/0tD2PMcGPMMtwb4N2+455biuMGHz/bWhs8ooa1divuTWrLkO03\n5fMce4CiWunvw2XFqqWssygbQu+w1v6GC1PBUwwvw3WSmxR0X3vctLffQr6m4H42DYs49hyOBLM+\nwAJcEE4D+vpC+Ym+7Y7F5pDb/qlrRV7GwFq7ylr7R6A+cBJuVDIHeM0Yc0YBu70P1MWNcF0JfGKt\nPZTPdsUNU8UNZwVZZa2dkc/XQQBjTE1jTKOgL38Djn3FrA/f88Tjfmdm+tbetTVureQCoKkx5sx8\ndvsIFwLPB/6B+ztSpZTnKSICKHSJSJSy1i4BfuXIp9n+BhH5dR37GPfm8QbgPNwbrg8I499IY8y1\nwOvACtzarkG+484K53FD5BRwf1Gd9371/bdLMY9T0Jqugtbv5BcGwI1onWCMOcF3+w/A19batKBt\nDC5ghY6i+EdSggNafuYCLY0xzXDha44vpH/ru326b7tjDV2lfe0DfKOlP1trH8WNXgU+ZMhn2624\nc7sb19o83+6dvmmau3CXAihMV2BjKacWFscLuCnC/q8PffeX9HdvIC5oD8ON4vq/3sX9XubXUGOz\nLwBOsdb+A/ea3WaMCR0pFhEpNoUuEYlm7wInGmO64MLXamtt6HWALsZdX+pca+0Ea+1X1toZlO7v\n40bcG988jSh8a71ahWz7e2CltfZSa+171tqpvuOGfqJekosqbwQSfJ/kBx+/CW5koKDrEpXUp7jz\nDL1WUUH2cOT6TMFCR96K8hGQDVxmjEnGNZ8IXTO1DqhWwCjKDF/4KIw/TJ2Hm+bpvz0bN+2wLy6g\nh17zKlSpLoZ9DBb5/tu4kG3ew53DbgpfN/Y50N4UcGFf3wcVzQjqABoGD5M3MN/lu/8L3Gtb3N+9\nq3AdQP+Qz9eHwO9NSGfPfLyIG30NXYMmIlJsCl0iEs38UwzHAieTf8ezHNxaocCoizGmDfC7Uhzv\ne9z0xBtCurBdx9HToY4a6TDGnI5rJBDsoO+/+YWWUF/gzvfWkPvvwL1R/bwYz1Eka+1c3Bqp0caY\nozrYGdcOP7hT4Fqgs2/dmn+bU4BeJTzuHt9xL/N9HeLodUkf4qYBnp1PXbWL6o5nrV2DG+m5Hfdv\n5He+h+bguj0OBb4LnaKaj4O4lvFlOgXTGNPX+K5dFsI/CvNrPo/5fYjrknlzyJrD0HN5DDfldVzw\nz8x3/Pq4ELIft9YtLKy1K0LC8o+++zfi1kieH9zGP6i+OGPMXb4piVVx1yL7xFr7sbX2o+Av33nU\npogujL61l08BXYwx55fxqYpIjFD3QhGJWtbaDcaY73BvvI66oKnP57iW8V8ZY97HjRTchFvQ3zmf\n7UMFpoNZa7OMuzDw87g1JB/guqZdjRuBCfYZcKGvY+CXuFGb0cAvQKWg5zxojFkFXGGMWYcbNfrJ\nWrsin/NdYox5F7jJ1zxiDnAa7tP+D0M6Fx6rq4CvgEnGmE9xre/TcY0tLsc1FPFfq+t1XMOHr40x\nb+Ba418P/EzJ18p8gGuLPxr40r8GKMi/cIH5S9+xluIuDtwVN6rZlCPrggoyBzcSsiSo2cUiXMhr\nD0woRp3+EdXnjTHTgCxrbVl0v7sP6Or7vVmG+/1LBv6IW7tWYLMHX3OSsfk8ZEK2W+lryvEWsMwY\n8zpupKcNrgNgbeBSa21+awKLq7sxJr+pfWuCm7sU4FZcE5EXjDF/wP0/vBc3cnoJ7ndwAnARUI38\nG4aAmzKaipti+HERxxyPC6z34D7cEBEpEYUuEYl27+KCx/fW2tDgg7V2qjFmFC4gPIMLR3fgRjVC\nQ1d+15XKc9ta+5IxBtyFYx/HTUMbjAsDNmi714wxDXENOwbhwtbluDATOq1rBK5V+NO4C9rej1sL\ndtTxcevDVuOuA3Uxbj3Mg76vos4l33PKdwNrdxljeuHa21+Gm3qVhGvOMRn3Wvq3XW6MuRrXlOBJ\nYDlu7dHwfM61sLrArcnKxL2Z/k/og76Q2gf4Ky44XYNrgrEKd72yA6H75GMObvpnYN2WL1B/j5ue\nl996rtCaP8St/7oUF7pzOdJyvKBzLOrcwf0cr/DVMQyoips+9zbwT2ttaIOO4kxzPGoba+0Hxphf\ncCHjOlyITgGm4jr5FTaiVtRx/Wup8gtdr+NGjAve2dp0Y8wg3O/P1bj/H6riftdnAJf7fj+vxP28\nZxTwPLnGmC9wXR1r4kYn8/0Z+I75IvBXY0xva+13odvkt5+IiJ8peoaEiIiIiIiIlFbErOkyxvzJ\nGLPeGHPI17o5dF1D6PZJxph/GmM2GGMyjDHrfN3A/I/PNMbk5vMVzoW/IiIiIiIieUTE9EJjzGW4\nKSfX466dcRtufcXx1tqUAnabCDTATS9Yi1uHERwiL8JNdfGrj7vy/IeIiIiIiIiUk4iYXmiMmY9b\nb3GL77bBXTjyOWvtY/lsfy5uQXwb38Lg4hzjVtwi2MYFXBBSRERERESkzHk+vdB3fYxkXOcrAHyt\neKfhFr/n53e4TlJ/McZsMcasNMY8boypXMihRgDvK3CJiIiIiEh5ioTphfVx18fZGXL/Tlz3sPy0\nwV2gMgN3zZT6wEtAXVw72zx8F3jsjJuKWCBfi+VBuNa4GcU9ARERERERiTr+AZ0frLXpx/JEkRC6\nSiMO1373Sv81VIwxtwMTjTE3WWszQ7YfCSyz1i6mcINw7aVFRERERETAzcpbcixPEAmhKwXIARqF\n3N8I2FHAPtuBrUEXrQR3zRoDNMM11gDAd0X6y3DXZynKBoB33nmHTp06Fad2KabbbruNp59+2usy\noo5e1/DQ6xoeel3DQ69reOh1DQ+9ruGh1zU8rrvuOpYuXVomz+V56PJdcHIx0B/fVeN9jTT6A88V\nsNu3uIsZVg0a6uuAG/3aErLtpbguhsUZwcoA6NSpE6ecckqJzkMKV6tWLb2mYaDXNTz0uoaHXtfw\n0OsaHnpdw0Ova3jodQ2PGjVqlNlzed5Iw+cpYJQx5mpjTEfgZdzV5d8EMMY8YoyZELT9e8Bu4A1j\nTCdjTD/gMeD1AqYWTrLW7gn3SYiIiIiIiITyfKQLwFr7oTGmPjAWN63wB2CQtfY33ybHAc2Dtj9o\njBkI/BtYiAtgHwD3Bz+vMeZ4oDcwMOwnISIiIiIiko+ICF0A1toXgRcLeOyoroPW2lW4xheFPecq\nXGdEERERERERT0TK9EKJcldccYXXJUQlva7hodc1PPS6hode1/DQ6xoeel3DQ69reAwaVOj4TokY\ndx1iATDGnAIsXrx4sRYjioiIiIjEsCVLlpCcnAyQbK09ppbxGukSEREREREJI4UuERERERGRMFLo\nEhERERERCSOFLhERERERkTBS6BIREREREQkjhS4REREREZEwUugSEREREREJI4UuERERERGRMFLo\nEhERERERCSOFLhERERERkTBS6BIREREREQkjhS4REREREZEwUugSEREREREJI4UuERERERGRMFLo\nEhERERERCSOFLhERERERkTBS6BIREREREQkjhS4REREREZEwUugSEREREREJI4UuERERERGRMFLo\nEhERERERCSOFLhERERERkTBS6BIREREREQkjhS4REREREZEwUugSEREREREJI4UuERERERGRMFLo\nEhERERERCSOFLhERERERkTBS6BIREREREQkjhS4REREREZEwUugSEREREREJI4UuERERERGRMFLo\nEhERERERCSOFLhERERERkTBS6BIREREREQkjhS4REREREZEwUugSEREREREJI4UuERERERGRMFLo\nkrDbvz/T6xJERERERDyj0CVh9fTT86hV61GGDfvI61JERERERDyh0CVhY63liSfmYS28994y9u7N\n8LokEREREZFyp9AlYbNiRQrbtu0Puv2bh9WIiIiIiHhDoUvCZtq0dXlu//KLQpeIiIiIxB6FLgmb\nqVPzhq7lyxW6RERERCT2KHRJWGRl5fDNNxvy3KeRLhERERGJRQpdEhbff7+VAwcO57lPoUtERERE\nYpFCl4TF1Klrj7pv8+Z97Nuna3aJiIiISGxR6JKwmDZtfeD7885rF/heHQxFREREJNYodEmZS0vL\n4PvvtwDQsWN9zjmnbeAxTTEUERERkVij0CVlbtasjeTkWAAGDmxD584NAo+pg6GIiIiIxBqFLilz\nweu5BgxowwknHAldGukSERERkVij0CVlzn99rvh4w5lntqJJkxrUrFkJUOgSERERkdij0CVlavPm\nNFau3A1Ar17NqFmzEsaYwBTDjRvTjmolLyIiIiISzRS6pExNm7Yu8P2AAW0C3wdPMVQHQxERERGJ\nJQpdUqb8UwvBNdHw07ouEREREYlVCl1SZnJzbWCkq0aNJHr2bBp4TB0MRURERCRWKXRJmVm2bCe/\n/ZYOwJlntiIxMT7wmEa6RERERCRWKXRJmQlezxU8tRCgWbOa1KiRBGikS0RERERii0KXlJng9VzB\nTTQAjDGB0a4NG/Zy8KA6GIqIiIhIbFDokjKRkZHN7NkbAWjatAYdO9Y/apvgKYa//ppSbrWJiIiI\niHhJoUvKxLx5mzl0KBtwo1zGmKO2UTMNEREREYlFCl1SJgpqFR9MzTREREREJBYpdEmZKOiiyMEU\nukREREQkFil0yTFLTT3EokXbAOjSpSGNGlXPd7sWLWpRvbo6GIqIiIhIbFHokmM2Y8Z6rHXfFzS1\nEFwHw06dXION9ev3kJ6eVR7liYiIiIh4SqFLjllxphb6+acYWgsrV6qDoYiIiIhEP4UuOWb+JhpJ\nSfH069ey0G3VwVBEREREYo1ClxyTdev2sG7dHgB6925OtWpJhW6vZhoiIiIiEmsUuuSY5J1a2LrI\n7RW6RERERCTWKHTJMcl7fa62RW7fsmVtqlZNBDS9UERERERig0KXlFpOTi4zZqwHoHbtyiQnNy5y\nn7i4Ix0M163bw6FD6mAoIiIiItFNoUtKbenSHaSmHgLg7LNbEx9fvF8n/xTD3FzLqlW7w1afiIiI\niEgkUOiSUgtez1XY9blCqYOhiIiIiMQShS4pteD1XEVdnyuYmmmIiIiISCxR6JJSSU/PYu7cTQC0\nalWbtm3rFHvf4NClkS4RERERiXYKXVIqc+du4vDhHMC1ijfGFHvfVq1qU6VKAqCRLhERERGJfgpd\nUipTp64NfF+cVvHB4uPj6NjRdTBcsyaVzMzsMq1NRERERCSSKHRJqUyb5lrFG+M6F5ZUcAfDlSvV\nwVBEREREopdCl5TYrl0H+eGHHQB069aY+vWrlvg5gjsYaoqhiIiIiEQzhS4psenTS9cqPpg6GIqI\niIhIrFDokhILvj5XSVrFB+vcuWHge3UwFBEREZFoptAlJWKtDVyfq3LlBPr0aVGq52ndujaVKsUD\nGukSERERkeim0CUlsnp1Kps37wOgb98WVK6cUKrnCe5guHr17kD7eRERERGRaKPQJSUS3Cq+tFML\n/fxTDHNyLKtWqYOhiIiIiEQnhS4pEf/UQih9Ew2/E06oH/heUwxFREREJFopdEmxZWfnMnPmBgDq\n16/KSScdd0zPpw6GIiIiIhILFLqk2BYu3Mq+fZkA9O/fmrg4c0zPpw6GIiIiIhILFLqk2IJbxR/r\n1EKANm3qkJSkDoYiIiIiEt0UuqTYgtdzHWsTDYCEhDg6dKgHwKpVu8nKUgdDEREREYk+Cl1SLPv3\nZzJv3hYA2revS8uWtcvkef1TDLOzc1m9OrVMnlNEREREJJIodEmxzJ69kezsXKBsphb6qYOhiIiI\niEQ7hS4plrKeWuinDoYiIiIiEu0UuqRY/E004uIMZ53VusyeVx0MRURERCTaKXRJkbZt2x8IRD16\nNKF27cpl9txt29YhMdH9GmqkS0RERESikUKXFKmsW8UHS0yM5/jjXQfDlStT1MFQRERERKKOQpcU\nKW/oalvmz++fYpiVlcvatXvK/PlFRERERLyk0CWFstYGQle1aon06tWszI+hDoYiIiIiEs0UuqRQ\nv/zyG9u3HwDgjDNakZQUX+bHyNtMY1eZP7+IiIiIiJcUuqRQeVvFl13XwmB528anhOUYIiIiIiJe\nUeiSQgWHrnCs5wJo164uCQnqYCgiIiIi0UmhSwp0+HAOs2ZtAOC446rTuXODwncopaSkIx0Mf/01\nhezs3LAcR0RERETECwpdUqD587dw8GAWAAMGtMEYE7Zj+acYHj6cw7p16mAoIiIiItFDoUsKFM7r\nc4VSB0MRERERiVYKXVKg4PVc/fuHp4mGnzoYioiIiEi0UuiSfO3dm8GCBVsBN/WvadOaYT2eOhiK\niIiISLRS6JJ8ffPNBnJzLRD+qYUA7dvXJT7erRnT9EIRERERiSYKXZKvqVPXBr4fMCD8oatSpQTa\ntz/SwTAnRx0MRURERCQ6KHRJvqZNWw9AQkIcZ5zRslyO6Z9imJGRzfr1e8vlmCIiIiIi4abQJUfZ\ntCmNVat2A9CrVzNq1KhULsdVB0MRERERiUYKXXKU4KmF5bGey08dDEVEREQkGil0yVH8UwuhfEOX\nOhiKiIiISDSKmNBljPmTMWa9MeaQMWa+MaZHEdsnGWP+aYzZYIzJMMasM8ZcG7JNLWPMC8aYbb5t\nfjXGnBvWE6ngcnNt4KLINWtWokePpuV27OOPr0dcnOtgqJEuEREREYkWCV4XAGCMuQx4ErgeWADc\nBnxljDneWlvQkMdEoAEwHFgLNCYoRBpjEoFpwA7gYmAb0BJQh4ZC/PTTTlJS0gE466xWJCSUXy6v\nXDmBdu3qsmrVblascB0M4+Mj5nMBEREREZFSiYjQhQtZr1hr3wIwxtwAXACMAB4L3dg3WtUXaGOt\n9YeoTSGbjQRqA72stTkFbCMhyrtVfKgTTmjAqlW7ycjIZuPGNNq0qVPuNYiIiIiIlCXPhxF8I1LJ\nwHT/fdZaixulOq2A3X4HLAL+YozZYoxZaYx53BhTOWSbecCLxpgdxphlxph7jTGen3Mkmzp1XeD7\n8lzP5de585F1XZpiKCIiIiLRIBICSH0gHtgZcv9O4LgC9mmDG+nqDAwFbgH+ALwQss0luHM8DxgL\n3AH8tawKjzYZGdnMmeMGA5s3r8nxx9cr9xryNtNQ23gRERERqfgiZXphScUBucCV1toDAMaY24GJ\nxpibrLWZvm12Atf7Rs6WGmOaAXcCDxb25Lfddhu1atXKc98VV1zBFVdcUfZnEkG+/XYTGRnZgJta\naIwp9xrUwVBEREREytv777/P+++/n+e+tLS0Mnv+SAhdKUAO0Cjk/ka4Jhj52Q5s9QcunxWAAZrh\nGmtsBw77AlfwNscZYxKstdkFFfT0009zyimnlOwsooDXUwsBOnRwHQxzc62mF4qIiIhIuchvgGXJ\nkiUkJyeXyfN7Pr3QWpsFLAb6++8zboilP/BdAbt9CzQxxlQNuq8DbvRrS9A27UL26wBsLyxwxTJ/\nq3iA/v29CV1VqiQGmmesWJFCbq4tYg8RERERkcjmeejyeQoYZYy52hjTEXgZqAq8CWCMecQYMyFo\n+/eA3cAbxphOxph+uC6Hr/umFgK8BNQ1xjxnjGlvjLkAuBd4vnxOqWLZvTudJUu2A3DSSY1o2LCa\nZ7X4pximp2exaVPZDeuKiIiIiHghIkKXtfZD3FqrscBSoCswyFrr76RwHNA8aPuDwEBcS/iFwNvA\nZFxDDf82W4BBQHfgR+AZ4GngX2E+nQppxoz1+CdiejW10E8dDEVEREQkmkTCmi4ArLUvAi8W8Njw\nfO5bhQtVhT3n90DvMikwygWv5/Li+lzBQjsYXnDB8R5WIyIiIiJybCJipEu8Za0NhK6kpHj69m3p\naT3qYCgiIiIi0UShS1i3bg8bNuwF4PTTm1O1aqKn9XTsWB9/t3pNLxQRERGRik6hSyKiVXywqlUT\nad3adTBhnkMHAAAgAElEQVT85ZffyNv1X0RERESkYlHokjyt4gcObOthJUf4pxgePJjF5s37PK5G\nRERERKT0FLpiXE5OLjNmrAegTp3KdOt2nMcVOepgKCJStP37M0lNPeR1GSIiUgSFrhi3ePF29uzJ\nANwFkePjI+NXIrSDoYiI5LV8+S5atnyGJk2e5OWXF3ldjoiIFCIy3mGLZ4KnFg4Y0NrDSvIKDl3L\nlyt0iYgEy8rK4eqrJ7FnTwaZmTnceOPnjB79KYcP53hdmoiI5EOhK8blbaIRGeu5ADp1qh/4XiNd\nIiJ5PfLIXJYs2Z7nvldfXcLZZ09g584DHlUlIiIFUeiKYQcPHua77zYD0KZNHdq0qeNxRUdUq5ZE\nq1a1AXUwFBEJtnTpdh58cDYA8fGG++/vR6VK8QB8++1mkpNfZdGibV6WKCIiIRS6YticOZsCU1Ei\naWqhn3+K4f79h9myRR0MRUQyM7O55ppJZGfnAnDvvX0YO/Ys5s4dQbNmNQHYunU/ffqM5+23f/Sy\nVBERCaLQFcOmTl0b+D6Sphb6BXcw1BRDERF48MHZLFvmOrqedFIj7r//DAC6d2/CokWjOP305gBk\nZro1X3fc8VUgoImIiHcUumLYtGmuVbwxcNZZrTytJT/qYCgicsTChVt59NG5ACQmxjFhwlCSkuID\njzdqVJ0ZM65h9OjkwH1PPTWf889/V23lRUQ8ptAVo3buPMBPP+0EIDm5CfXqVfW4oqPlvVaXQpeI\nxK6MDDetMCfHrW994IEzOOmko6+rmJQUz8svD+ally4gIcH9Ez916jp69BjHzz/rmociIl5R6IpR\n06evD3w/cGAbDyspWMeO6mAoIgJw//0zWLEiBYDk5Mbcc0+fQre/4YbuzJhxNQ0bVgNg3bo99Or1\nGh99tCLstYqIyNEUumJUcKv4AQMiM3TVqFGJFi1qAepgKCKx67vvNvPkk/MAN5I1YcLQwChWYfr2\nbcmiRaM45ZTGABw8mMXvf/8hf/vbTHJz9fdURKQ8KXTFIGttoIlGlSoJgYXXkcg/xTAtLZNt2/Z7\nXI2ISPlKT8/i2msn4f/M6cEHz6Jz54bF3r9581rMnTucYcO6BO4bO3Y2F130Afv2ZZZ1uSIiUgCF\nrhi0cuVutm51AaZfv5ZUqpTgcUUFUzMNEYll9947jdWrUwE47bRm3HHHaSV+jipVEnn77Yt44omB\nxMUZAD75ZCW9er3G6tW7y7ReERHJn0JXDApuFR+pUwv9FLpEJFZ9880GnntuAQCVKyfw5ptDiY8v\n3T/bxhjuuKM3X345jNq1KwOwYkUKPXu+xpQpa8qsZhERyZ9CVwzyt4qHyG2i4acOhiISi/bvz2T4\n8MmB24880p/jj693zM97zjltWbhwVOADrb17M7jggvd4/PFvtW5WRCSMFLpiTFZWDjNnutDVoEFV\nunRp5HFFhevUSSNdIhJ77r57Khs27AXcNPAxY04ts+du164u8+ePZOjQjgDk5lruvnsaw4Z9RHp6\nVpkdR0REjlDoijELFmxl//7DgJta6J/fH6lq1qxEs2Y1AXUwFJHYMHXqWl5+eTEA1aol8sYbQ8r8\nb3WNGpX43/8u5e9/PyNw3/vv/0yfPuPZtCmtTI8lIiIKXTFn2rQjreIjfWqhn3+K4Z49GezYccDj\nakREwictLYMRIz4J3H788YG0aVMnLMeKizP87W9n8vHHl1G9ehIAS5fuoHv3V5k9e2NYjikiEqsU\numJMRbg+Vyg10xCRWHHbbV+xZcs+wP2NvuGG7mE/5tChHZk/fyRt27pw99tv6fTv/xYvvbRQswtE\nRMqIQlcM2bcvk/nztwDQoUM9mjev5XFFxRMcutRMQ0Si1WefreKNN34AoEaNJF5//UKMKZ8p4J07\nN2TBglGcc05bALKzc7nppi8YPfozMjOzy6UGEZFoptAVQ2bN2kBOjvvUsqKMckHeDoYa6RKRaJSa\neojrr/80cPvppwfRokX5fjBWt24VPv/8Su6888i1wMaNW8LZZ7+lqd0iIsdIoSuGBE8trCjruUAd\nDEUk+o0Z8yXbt7tgc/757RkxopsndSQkxPH44+fwzjsXUblyAgDffbeZ7t1fZeHCrZ7UJCISDRS6\nYoi/iUZ8vOHMM1t5W0wJ1K5dmSZNagBueqHWGIhINPn44xW8++4ywP29Gzfud+U2rbAgw4Z1Ze7c\n4YHusVu37qdv3zd4660fPa1LRKSiUuiKEVu27GPFihQAevZsSq1alT2uqGT8UwxTUw+xa9dBj6sR\nESkbv/12kNGjPwvc/ve/zwt8yOS15OQmLFo0ij59WgCQmZnDNddM4rbbppCdnetxdSIiFYtCV4yY\nPr1iTi30UwdDEYlGf/rTF/z2WzoAQ4Z0YNiwLh5XlFejRtWZPv1qbrghOXDfM898z7nnvsPu3eke\nViYiUrEodMWIitgqPlhwMw11MBSRaPDBBz8zceIvANSrV4VXXhns+bTC/CQlxfPSS4N55ZXBJCa6\ntw3Tp6+nR49xLFu20+PqREQqBoWuGGCtDaznql49iV69mnlcUclppEtEosmOHQe46aYvArdffPEC\nGjWq7mFFRbv++mRmzLiGhg2rAbB+/V5OO+11/ve/XzyuTEQk8il0xYCff97Fzp1uHdSZZ7YiMTHe\n44pKTqFLRKKFtZbRoz8jNfUQAJde2plLL+3scVXF06dPCxYtGkVycmMADh7M4g9/mMgDD8wkN1dN\njkRECqLQFQPyTi1s7WElpVenThUaN3afAmt6oYhUZG+//ROffLISgIYNq/HCC+d7XFHJNG9eizlz\nhnPVVV0D9z344GyGDv0P+/ZleliZiEjkUuiKAf6phQADB7b1sJJj4x/tSklJ57ff1MFQRCqerVv3\nMWbMl4Hbr7wymPr1q3pYUelUqZLIW28N5cknzyEuzq1D+/TTVfTq9RqrVu32uDoRkcij0BXlMjOz\nmTVrIwBNmtSgU6f6HldUeppiKCIVmbWW6677lLQ0Nxp01VVdGTq0o8dVlZ4xhttvP40pU4ZRp467\nDMmKFSn07DmOKVPWeFydiEhkUeiKcvPmbSE9PQtwXQsjsTNWcamDoYhUZK+/vjQQRpo0qcFzz53r\ncUVlY+DAtixcOCrwNzotLZPzz3+Xf/1rri5mLyLio9AV5fJOLax4reKDaaRLRCqqjRv3cvvtXwVu\njxv3O+rUqeJhRWWrbdu6zJs3kosuciN31sI990znyis/CnzwJyISyxS6olxwE43+/StmEw0/hS4R\nqYhycy0jRnzC/v2HARgx4mTOP7+9x1WVvRo1KvHf/17KP/5xZuC+//znZ/r0Gc/GjXu9K0xEJAIo\ndEWxPXsOsWjRNgBOPLEhjRvX8LiiY1OvXlUaNXLXh9H0QhGpKF5+eREzZqwHoHnzmjz11CCPKwqf\nuDjDAw+cwaRJl1G9ehIAS5fuoHv3ccyatcHb4kREPKTQFcVmztwQuG5KRW0VH8o/2rVr10FSUtI9\nrkZEpHBr16Zy111TA7fHjx9CrVqVPayofAwZ0pH580fSrl1dwHWdHTDgbV54YYHWeYlITFLoimJT\np64NfF+RW8UHC55iuGKFRrtEJHLl5lqGD58cWNN0443dGTCgYq+tLYnOnRuyYMF1nHOO+/cnOzuX\nm2/+klGjPiUzM9vj6kREypdCVxSbNs1NZ0lMjKNfv5YeV1M21MFQRCqKZ5+dz5w5mwBo3bo2jz02\n0OOKyl+dOlX44osrueuu3oH7Xn99KWedNYHt2/d7WJmISPlS6IpSGzbsZc2aVABOO615YG59Radm\nGiJSEaxcmcJ9980I3H7jjSFR83e4pOLj43jssYG8++7FVK6cALjLmXTvPo4FC7Z6XJ2ISPlQ6IpS\n0dQqPlhw6NJIl4hEopycXK69djIZGW4K3S23nMoZZ7TytqgIcOWVXZg7dzjNm9cEYNu2/fTr9wYT\nJvzgcWUiIuGn0BWlglvFR9MaggYNqtGgQVVAI10iEpmeeOI75s/fAkD79nV5+OH+HlcUOZKTm7Bo\n0fX07dsCgMzMHK69djK33jqF7Oxcj6sTEQkfha4olJtrmT7dha5atSrRvXsTjysqW/7Rrh07DpCa\nesjjakREjvj551088MA3gGufPmHCUKpWTfS2qAjTsGE1pk27mhtv7B6479lnv2fQoHfYvVtdaUUk\nOil0RaEfftjB7t0ujJx9dmsSEqLrx6x1XSISibKycrjmmkkcPpwDwB13nMZppzX3uKrIlJQUz4sv\nXsCrrw4mMdH9GzVjxnp69BjHTz/t9Lg6EZGyF13vxgXI2yo+mqYW+gV3MFToEpFI8eijc1myZDvg\nPhwaO/YsjyuKfKNGJTNz5jWBC9+vX7+X0057nf/+9xePKxMRKVsKXVHI3yoeoquJhp9GukQk0vzw\nww7Gjp0NQHy8m1bo79QnhTv99BYsWnR9YCp8enoWl1wykf/7vxnk5upCyiISHRS6osyhQ1nMmbMR\ngBYtatGuXV2PKyp7nTs3DHyvDoYi4rXDh920Qn8jiHvv7RN1a2nDrVmzmsyefS1//GPXwH3//Occ\nhgz5D2lpGR5WJiJSNhS6oszcuZvIzHTrCQYObIMxxuOKyl6DBlWpV68KoJEuEfHe2LGzAuuQunZt\nxP33n+FxRRVTlSqJTJgwlKeeOoe4OPdv12efraJXr9dZtWq3x9WJiBwbha4oE63X5wpmjAlMMdy2\nbT979+pTUBHxxsKFW3n00bkAJCTEMWHCUJKS4j2uquIyxnDbbafx1VdXUadOZQB+/TWFnj3H8cUX\nqz2uTkSk9BS6okzw9bnOPru1h5WEl5ppiIjXMjKyueaaSeTkuHVHDzzQj5NPPs7jqqLDgAFtWLhw\nFCee6KaTp6VlMnjwezz66Fys1TovEal4FLqiSEpKOkuX7gCgW7fjaNCgmscVhY+aaYiI1x54YCYr\nVqQAkJzcmHvu6eNxRdGlbdu6zJs3kosv7gSAtXDvvdO54or/kZ6e5XF1IiIlo9AVRfwXRIbobBUf\nTKFLRLz03XebeeKJ7wB3zakJE4aSmKhphWWtevUkJk68hLFjzwzc98EHyzn99PFs2LDXs7pEREpK\noSuKBE8tjNb1XH7qYCgiXklPz+Laayfhn+U2duyZef4mSdmKizPcf/8ZTJ58OTVqJAGuRX+PHuP4\n5psN3hYnIlJMCl1RwlobCF2VKsXTp08LjysKr0aNqgUWWWukS0TK0333TWf16lQAevVqxp139va4\nothw4YUdmD//usClUFJS0hkw4C2ef36B1nlVAJmZ2SxYsJVZszbo5yUxSaErSqxZk8qmTWkA9OnT\ngipVEj2uKLyCOxhu2bKPffsyPa5IRGLBrFkbePbZ7wGoXDmBN98cQny8/iktLyec0IAFC67j3HPb\nAZCTY/nzn7/kuus+ITMz2+PqxC8nJ5eff97F+PFLufHGz+je/VVq1HiEU099jTPPnMA990zzukSR\ncpfgdQFSNmJpaqFf584N+PbbzYAb7erVq5nHFYlINDtw4DDDh08O3H7kkf506FDfw4piU506Vfjs\nsyu4777pPPaYW1c3fvwP/PJLCh99dCmNG9fwuMLYYq1l3bo9LFy4jYULt7Jw4TaWLNnOwYMFNzt5\n8sl5XHVVV7p0aVSOlYp4S6ErSgRfnyvam2j4hTbTUOgSkXC6666vWb/eNW/o27cFY8ac6nFFsSs+\nPo5//WsgJ598HCNGfEJGRjbz52+he/dxfPTRpZx6qv49CJdt2/YHwtXChdtYtGgbqamHCt3HGOjQ\noT716lXh2283B0YoZ868BmNMOVUu4i2FriiQnZ3LjBnrAahXrwrdujX2uKLyERy6li/f5WElIhLt\npk5dy8svLwagatVE3nhjCHFxerPotSuu6EKHDvW56KIP2LQpjW3b9tOv35u88spgrr32ZK/Lq/BS\nUw+xaNG2PCFr27b9Re7XsmUtevRoSo8eTejRownJyU2oWbMSGRnZnHjii6xdu4dZszbywQfLufzy\nE8vhTES8p9AVBRYv3kZamlvT1L9/m5h5IxDcLeyXX1I8rEREollaWgYjR34SuP344wNp27auhxVJ\nsFNOaczChaO45JKJzJ69kcOHcxg+fDJLl27niSfOUSv/Yjp48DBLl+7IE7DWrEktcr+GDasFwlWP\nHk3p3r0JDRvmf53QypUTePbZcxk8+H0A7rjjawYPPp7q1ZPK9FxEIpFCVxQIXs81YEBrDyspX40b\nV6dWrUqkpWWqg6GIhM3tt3/F5s37AOjfvzU33NDd44okVMOG1Zg27Y/ceusUXnxxEQDPPbeAZct2\n8eGHl1C/flWPK4wshw/nsGzZzjzrsJYv/43c3MK7CtasWYnk5MaBgNWzZ1OaN69ZoimCF1xwPIMH\nH89nn61i27b9PPTQbB59dMCxnpJIxFPoigJ5m2i09bCS8uXvYDhv3hY2bUpj//5MatSo5HVZIhJF\nPv98FePH/wBAjRpJvP76hTEzm6CiSUyM54UXLqBbt8bcdNPnZGXlMnPmBnr0GMekSZdx0knHeV2i\nJ3Jyclm5cneeEawff9xBZmZOoftVqhRPt26N84xiHX98vTL5/X/mmUF8/fVaDh/O4amn5jF8+Mlq\nSiNRT6Grgjtw4DDz5rkOfu3a1aVVq9oeV1S+Ond2oQtgxYoUevZs6nFFIhItUlMPMWrUp4HbTz01\niJYtY+tvbEV03XWncMIJDbj44g/YufMgGzbspXfv8bz55hAuuaSz1+WFlbWWjRvTWLBgayBkLV68\nnQMHDhe6X3y84cQTGwbCVY8eTTjxxIZhm5rZtm1d7r67Nw89NIesrFzGjJnClCnD1FRDoppCVwU3\ne/ZGsrJygdiaWugX2sFQoUtEysqYMV+yffsBAM47rx0jR3bzuCIprt69m7No0fVcfPEHLFy4jfT0\nLC699L/cd98OHnzw7KgZrdy580CeKYILF24jJSW9yP3at6/rmx7oQtbJJx9H1arle33Pe+/ty1tv\n/cSmTWl8/fVaJk9eydChHcu1BpHypNBVwQW3io+lqYV+wc001MFQRMrKxx+v4N13lwFQu3Zlxo37\nnT6Fr2CaNavJ7NnDGT36M95660cAHn54Lj/+uJN3372YWrUqe1xhyaSlZfg6CW4LBC3/WsPCNGtW\n86hGF7Vre3/uVasm8tRT5/CHP0wE4NZbpzBoUFuqVCnf8CdSXhS6Kjj/eq64OMNZZ7XytBYv5B3p\nUgdDETl2KSnp3HDD54Hbzz13Lk2b1vSwIimtypUTePPNIXTrdhx33vk1OTmWzz9fzamnvsbkyZdH\n7DqiQ4eyjuokuGrV7iL3q1evSp5W7T16NOW446qXQ8Wlc/HFnRgwoA3Tpq1j48Y0/vWvb/n738/0\nuiyRsFDoqsC2b9/Pzz+70Z3u3ZtQp04Vjysqf02b1qBmzUrs26cOhiJSNm666XN27ToIwJAhHbjq\nqq4eVyTHwhjDrbf2okuXhlx66X9JTT3EypW76dnzNd5///ecf357T+vLysph+fLf8gSsZct2kpNT\neCfBatUSSU5uEpgi2KNHE1q1ql2hRmSNMTz33Ll07foy2dm5PProXK655iRat67jdWkiZU6hqwKb\nPn194PuBA9t4WIl3/B0M58/fwoYNezlw4LCu9yEipfbBBz8zceIvANStW4WXXx5cod7ESsH692/D\nwoWjGDLkP/z88y727ctk8OD3+Oc/z+aee/qUy885N9eyevXuPOuwli7dQUZGdqH7JSXFc9JJjfI0\nuujYsT7x8XFhrzncOnVqwK23nsoTT8wjMzOH22//mo8/vszrskTKnEJXBZb3+lyxGboATjihPvPn\nuw6Gv/6aQvfuTTyuSEQqoh07DnDTTV8Ebr/44vkRPTVLSq5NmzrMmzeSa6+dxP/+twJr4b77ZvDD\nDzsZP/5CqlUruw/trLVs3rwvzwjW4sXbSEvLLHS/uDj3YWLwFMEuXRpSqVL0vmW7//4zeOedZezY\ncYBJk35lypQ1nHtuO6/LEilT0ft/cJSz1gaaaFStmshppzXzuCLvhHYwVOgSkZKy1nLDDZ+RmnoI\ngEsuOYHLLjvR46okHKpXT2LixEv45z/ncP/9MwH48MPlrFyZwqRJl5f60ispKel5AtbChVvZufNg\nkfu1aVOHnj2PrMPq1q1xzM3YqFmzEo8/PpA//vFjwHUOXbbsxqgOmhJ79NtcQa1YkcK2bfsB6Nev\nZUz/YVIHQxE5Vu+88xOTJ68EoGHDarz44gUeVyThZIzh//6vH127NuKqqz5i//7D/PjjTrp3f5WJ\nEy/hrLMKvwTL/v2ZLF68PU/I2rBhb5HHbdy4ep5GF927N6FevapldVoV2rBhXXjllcXMnbuJ1atT\neeaZ+fzlL328LkukzMTuO/UKburUtYHvY3U9l586GIrIsdi6dR9//vOXgdsvv3wB9evrjXAsuPDC\nDnz//XUMGfIfVq9OZffuQwwc+DZPPz2Im2/uiTGGjIxsfvxxR54RrF9/TcEW3ueC2rUr55ki2KNH\nE3XBLIQxhn//+zySk18lN9fy4IOzGTasK82a6TWT6KDQVUFNm6YmGn7Nm9ekevUkDhw4rA6GIlIi\n1lquu+7TwDqbYcO6cNFFnTyuSspTp04NWLBgFFdc8T+mTFlDTo5lzJgpfPLJKlJTD7Fs2U6ysnIL\nfY4qVRJITm6SJ2S1bVtHTVhK6OSTj+PGG7vzwgsLOXgwi7vumsr77//e67JEyoRCVwWUlZXDN99s\nAKBRo2qceGLDwneIcv4OhgsWbGX9+j2kp2dRtaourigiRRs/filTpqwB3NSvf//7PI8rEi/Url2Z\nzz67gr/+dQb/+te3AIF106ESEuLo2rVRnoB1wgkNSEio+J0EI8HYsWfxwQfLSUlJ5z//+ZnRo5M5\n88xWXpclcswUuiqg77/fyoEDhwHXtVCfpBEIXda6DoannNLY65JEJMJt3LiX2277KnD7tdcujMnr\nHYoTHx/Ho48O4OSTj2PEiMkcOpSNMdCxY/0867BOOuk4KlfW26dwqVu3Co880p9Roz4F4M9//pIl\nS64nMTHe48pEjo3+alRAweu5YrlVfLATTqgf+H758l0KXSJSqNxcy8iRn7B/v/sAa8SIkz2/SK5E\nhssvP5G+fVuwYcNeunRpRM2albwuKeaMGNGNV19dzMKF2/j55128+OJCbrmll9dliRwTjYVXQMHX\n54r19Vx+wR0Mta5LRIry8suLAheYb968Jk89NcjjiiSSNG1ak9NPb6HA5ZG4OMPzz58fuP3AA9+w\nc+cBDysSOXYKXRVMWloGCxZsBaBTp/rqhOSjDoYiUlxr16Zy111TA7dff/1CatWq7GFFIhKqZ8+m\njBzZDYB9+zK5557pHlckcmwUuiqYb77ZQE6O61OrqYVHtGhRK9A8Q9fqEpGC5OZahg+fTHp6FgA3\n3JDMwIFtPa5KRPLzyCP9qV3bfSDy5ps/MG/eZo8rEik9ha4KJribkqYWHhEXZwKjXevW7eHQoSyP\nKxKRSPTcc98zZ84mAFq3rs3jj5/jcUUiUpAGDarx4INnBW7ffPOX5OQU3r5fJFIpdFUw/vVc8fGG\nM85o5W0xEcYfuqyFlSt3e1yNiESalStTuPfeI1OU3nhjCNWrJ3lYkYgU5YYbutO1ayMAlizZzmuv\nLfG4IpHSUeiqQDZvTguEiV69mmmBb4jQDoYiIn45Oblce+1kMjKyARgzpqc+uBKpABIS4nj++SPX\nz7vvvhns3p3uYUUipaPQVYFoamHh1MFQRAryxBPfMX/+FgDat6/LI48M8LgiESmuvn1bcuWVXQBI\nTT3E/ffP9LgikZJT6KpAglvFq4nG0dTBUETys3z5Lh544BvArf98882hgcY7IlIxPP74wMB04Jdf\nXsSSJds9rkikZBS6KojcXBsY6apRI4mePZt6XFHkadWqNlWquOt9a3qhiABkZeVwzTWTOHw4B4A7\n7jiN3r2be1yViJRUkyY1eOCBfoBbu33zzV+Qm2s9rkqk+BS6Kohly3by229uDvOZZ7YiMTHe44oi\nT1ycoVMnN9q1du2ewNoNEYldjz46l8WL3SfinTrVZ+zYs4rYQ0Qi1S239KJDh3oAzJu3hXfe+cnj\nikSKT6GrggieWqj1XAXzTzHMzbWsWqUOhiKx7IcfdjB27GzAdXydMGEolSsneFyViJRWUlI8zz13\npKnG3XdPJS0tw8OKRIpPoauCyNtEQxfyLEjnzkfWdWmKoUjsOnzYTSvMznbX9Lnnnj706KFp2SIV\n3TnntOXiizsBsHPnQf7xj1keVyRSPApdFUBGRjazZ28EoGnTGoGhdTla3mYa6mAoEqsefHAWP/20\nE4CuXRvxwANneFyRiJSVp546JzBq/dxz3+tDVqkQFLoqgHnzNnPokFufNHBgW4wxHlcUudTBUEQW\nLtzKI4/MBdw1fiZMGEpSktbBikSLli1rc999fQDIybH8+c9fYq2aakhkU+iqAPK2im/tYSWRr3Xr\n2oFPv/TJl0jsycjI5pprJpGT496A3X9/P04++TiPqxKRsnbXXafTpk0dAGbO3MDEib94XJFI4RS6\nKgBdn6v44uPj6NixPgBr1qSSmakOhiKx5IEHZrJihRvlTk5uzL339vG4IhEJh8qVE3jmmUGB23fc\n8TUHDhz2sCKRwil0RbjU1EMsXrwNcOsSGjWq7nFFkc8/xTAnRx0MRWLJd99t5oknvgNcl7MJE4bq\n8hoiUWzw4OM5//z2AGzZso+HH57jcUUiBVPoinAzZqzHP01ZUwuLJ7iDoZppiMSG9PQsrr12UuDv\n5dixZ9K5c0NPaxKR8DLG8MwzgwJrNp944jt92CoRS6ErwqlVfMmpg6FI7LnvvumsXp0KQK9ezbjz\nzt4eVyQi5aF9+3rceedpAGRl5XLLLVPUVEMikkJXhPOv50pKiqdv3xYeV1MxBIeu5csVukSi3axZ\nG5vxuSgAACAASURBVHj22e8Bt87jzTeHEB+vf95EYsV99/WlWbOaAEyZsoZPP13lcUUiR9O/ShFs\n3bo9rFu3B4DevZtTrVqSxxVVDG3a1KFSJTfVQCNdItHtwIHDDB8+OXD74YfPpkOH+h5WJCLlrVq1\nJJ588pzA7VtvncKhQ1keViRyNIWuCJZ3aqG6FhZXQkJc4E3X6tWpHD6c43FFIhIud989lfXr9wLQ\nt28Lbrmll8cViYgXLrnkBM46qxUA69fvDTTVEYkUCl0RTK3iS88/xTA7O5fVq7WoViQaTZu2jpde\nWgRA1aqJvPHGEOLidPF4kVhkjOHf/z6P+Hj3N+Dhh+eyYcNej6sSOUKhK0Ll5OQyY8Z6AGrXrkxy\ncmOPK6pY1MFQJLqlpWUwYsSRaYWPPTaAtm3reliRiHitc+eGjBlzKuAulH7HHV97XJHIEQpdEWrp\n0h2kph4C4OyzW2tReAmpg6FIdLv99q/YvHkf4P5G3nhjD48rEpFI8Le/nUGjRtUA+OijFXz99VqP\nKxJx9E4+Qk2deuSPhNZzlVzwSJc6GIpEly++WM348T8AUKNGEuPHX6hphSICQK1alXnssYGB22PG\nfKm13RIRFLoi1LRp6wPfK3SVXNu2dUlMdL/eGukSiR579hxi1KhPA7efemoQLVvW9rAiEYk0V13V\nld69mwOwcuVunn12vscViSh0RaT09Czmzt0EQKtWtWnTpo7HFVU8wR0MV63aTVaWPuUSiQZjxkxh\n27b9AJx7bjtGjuzmcUUiEmni4gzPP38exjcAPnbsbLZu3edtURLzFLoi0Ny5mwJD4QMHtsEYTZsp\nDf8Uw6ysXNasSfW4GhE5VpMm/co77/wEQK1alRg37nf6+ygi+erWrTE33NAdcNfzu/vuaR5XJLFO\noSsCBa/nUqv40lMzDZHokZKSzujRnwVuP/fceTRrVtPDikQk0j300NnUq1cFgPfeW8bs2Rs9rkhi\nmUJXBPJfn8sY6N+/tcfVVFwKXSLR409/+oJduw4CcOGFHfjjH7t6XJGIRLq6davw8MP9A7dvvvkL\nsrNzPaxIYplCV4TZtesgP/64E4BTTmlMvXpVPa6o4lIHQ5Ho8OGHy/nww+WAexP1yiuDNa1QRIpl\n5MhugWudLlu2i5deWuhxRRKrFLoizPTp6wLfa2rhsWnXri4JCepgKFKR7dz5/+zdd3iUVfr/8fdJ\nh9B7BwHpHVSQqoAI9rWiu65tURFZsIC6gigqKiIiRV27P1ds61pBmgiIIE2KdKT33gIJKef3xyTD\nhC8ImczkTPm8ruu5mOfJJPlkV8Lcc+7nPkfp3ft77/nYsT2oUKGIw0QiEk5iY2MYM6aH93zQoOne\nVXORgqSiK8RMnXqy6NKo+PyJj4+lTp3SgGdkrFoKRMKLtZZ77/2Offs8G8XfcEMDbr65oeNUIhJu\nWreuwp13NgPg0KE0Hn9cQzWk4KnoCiHWWu/9XElJcbRtW81xovCX02J44kQmf/yhCYYi4eSjj5by\n9derAShbtjDjxvVQW6GI+GXYsM4UK5YIwLvvLubXX7c6TiTRJmSKLmPMA8aYDcaY48aYucaYC87y\n/ARjzHPGmI3GmFRjzHpjzB0+H/+7MSbLGJOZ/WeWMeZY0H+QfFizZh9btnj2kWjfvhpJSXGOE4U/\nDdMQCU/bth2mb98fvOdvvnklZcsmO0wkIuGsfPkiPPNMJ+95nz4TycqyzvJI9AmJossYczMwAngK\naA4sASYZY8r8yad9DlwC3AnUAXoCq095ziGggs9RPbDJA0uthYHnW3RpmIZIeLDW8o9/fMvBg6kA\n3HZbY667rr7jVCIS7h544EIaNSoHwIIF23n33d8cJ5JoEhJFF9AfeNNa+6G1dhVwH3AMuOt0TzbG\nXA60B3pYa6dbazdba3+11s455anWWrvHWrs7+wjpV905rYWgIRqB4jvBUCtdIuHh3Xd/Y+LEdQBU\nrFiE117r7jiRiESCuLgYRo8++fvkscemsn//cYeJJJo4L7qMMfFAS2BazjVrrQWmAm3O8GlXAQuA\ngcaYrcaY1caY4caYpFOeVyS7/XCzMeYrY0yDYPwMgZCRkcX06RsBz70LTZtWcBsoQpx/fmliYz33\ngKjoEgl9mzYdpH//Sd7zt966ilKlCjlMJCKRpFOnGtxySyMA9u07zuDB0x0nkmjhvOgCygCxwK5T\nru/C0xJ4OjXxrHQ1BK4F/gncAIz1ec5qPCtlVwO34flZfzHGVApY8gCaP38bhw+nAdC5c01iYnSz\neCAkJMRy/vmeCYarVu0lM1MTDEVClbWWu+/+hiNHTgBw553NuOKKOo5TiUikGT68K8nJ8QC8/voC\nFi/e6TiRRINwndQQA2QBt1prjwIYYx4CPjfG9LbWpllr5wJzcz7BGDMHWAnci+fesTPq378/xYsX\nz3WtZ8+e9OzZM7A/hY/crYXnBe37RKOGDcuyatVe0tIyWb/+gLcIE5HQ8sYbC5g2bQMAVasWY+TI\nbo4TiUgkqlKlGIMGdeCxx6aRlWXp02cCs2bdqemoUW78+PGMHz8+17VDhw4F7OuHQtG1F8gEyp9y\nvTxwprcedgDbcgqubCsBA1QB/jj1E6y1GcaY34DaZws0cuRIWrRocQ7RAyf3EI1aBfq9I12DBmX5\n739XAp4WQxVdIqFn/foDPProFO/5O+9cTfHip3aMi4gERr9+rXn33cWsWbOP2bO38J//LOOvf23i\nOpY4dLoFlkWLFtGyZcuAfH3n7YXW2nRgIdA555rxvNXQGfjlDJ82G6hkjCnsc60untWv0268YIyJ\nARrjKdhCypEjacyZ44l9/vmlqFat+Fk+Q/LCd5iGJhiKhJ6sLMudd35NSko6APfe21JvPolIUCUm\nxvHaa5d7zx99dIr3Ng+RYHBedGV7BfiHMeZ2Y0w94A2gMPA+gDFmmDHmA5/nfwzsA94zxtQ3xnQA\nXgLesdamZX/OIGNMV2PMecaY5sB/gGrA2wX2U52jGTM2kZHhuddIo+IDT3t1iYS21177lZkzNwFQ\no0YJhg/v6jiRiESDbt1qc+219QDYufMozzwzw3EiiWQhUXRZaz8DHgGeAX4DmgDdfEa8VwCq+jw/\nBegKlADmA/8P+BrPQI0cJYF/AyuA74EiQJvskfQhRa2FwVWnjiYYioSqNWv28fjj3uG1vPfeNRQt\nmugwkYhEk1deuYykJM/dNqNG/arXCRI0IVF0AVhrx1lra1hrC1lr21hrF/h87E5r7aWnPH+Ntbab\ntbaItba6tXZAzipX9scfstael/31Kllrr7LWLi3In+lc5QzRiIkxdOpUw22YCJSYGEft2qUAWLlS\nEwxFQkVmZhZ33PEVqakZAPTte6F+B4pIgTrvvJI89lhbwLN9T9++E/HsXCQSWCFTdEWr7duPeN9V\nufDCypQooRvHgyGnxTA1NYONGw86TiMiACNGzPHez1q7dimef77zWT5DRCTwBgxoS40aJQCYNm2D\nd/iWSCCp6HLMt7VQo+KDR/d1iYSW5ct3M2iQZ1NSY+D9968hOTnBcSoRiUaFCsXn2qLioYcmkZJy\nwmEiiUQquhzz3Z9L93MFjyYYioSO9PRM/v73rzhxIhOAhx9uQ9u21RynEpFods01denWzfM6bMuW\nwwwb9rPjRBJpVHQ5ZK31rnQlJ8fTunUVx4kil1a6RELHiy/OZuFCz+4d9euXYejQS8/yGSIiwWWM\nYdSoy4mP97w0Hj78F9at2+84lUQSFV0OLV++h507Pfs7d+xYg4SEWMeJIlfdumWIidEEQxHXlizZ\n6R3LHBtr+OCDa72Tw0REXKpbtwwPPdQGgBMnMunX7wfHiSSSqOhyKPeoeO3PFUxJSXHUqlUS8Eww\nzMrSZCKRgnbiRCa33/4V6emeCaIDB7blggsqO04lInLSk092oFKlogB8//1avvtujeNEEilUdDnk\nez9Xly4quoItp8Xw2LF0Nm3SBEORgjZ06AyWLt0FQOPG5Rg8uKPjRCIiuRUpksCIEZd5z/v1+8G7\nrYVIfvhVdBljko0xPYwx9xlj+voegQ4YqU6cyGTGjI0AVKxYJNegBwkO3/u6NExDpGAtWLDde2N6\nXFwMH354HYmJaisUkdBz880N6dixOgB//HGAESN+cZxIIkGeiy5jTHNgHTAeGAM8CbwKPA/0C2i6\nCDZ37lZSUtIBzyqXMcZxosjnW9jqvi6RgnP06An+/vevyMz0tPUOGtSBZs0qOE4lInJ6xhhGj+5O\nbKzntdlzz81i8+ZDjlNJuPNnpWsk8C1QEjgOtAaqAwuBRwIXLbJNmfKH97FaCwuGJhiKFLyfftpI\nkyave//OtWhRkccfb+c4lYjIn2vcuDx9+lwIwPHjGTz88GTHiSTc+VN0NQNGWGuzgEwg0Vq7BRiA\nZ7VLzsHUqRu8j1V0FYy6dcuQs6Co9kKR4EpJOcGDD07gkks+YMMGzz2URYsm8MEH1xIfr0mtIhL6\nhgzpRLlyyQB88cWKXAPQRPLKn6IrHcjKfrwbyNnR8hBQNRChIt3Bg6nMm7cN8Ky+5EzJkeAqXDie\nmjVzJhju0QRDkSCZOXMTTZq8wZgx873X2rWrxqJF99KoUTmHyUREzl2JEkm8+GIX7/mDD070buou\nklf+FF2/ARdkP54BPGOMuQ3PfV2/BypYJJs+fYP3Bb9GxResnBbDlJR0tmxRf7ZIIKWknOCf/5xI\nx47vs379AQAKFYpj5MhuzJhxB7Vrl3KcUEQkb26/vSmtW1cBYNWqvYwe/avjRBKu/Cm6ngB2ZD/+\nF3AAeB0oC/QKUK6Ipv253NEEQ5HgmDVrE02bvsFrr83zXmvbtipLltxHv36tvZuTi4iEk5gYw5gx\n3b23JwwZMoMdO464DSVhKc9Fl7V2gbV2evbj3dbay621xay1La21SwIfMfLk7M8VFxdDhw7VHaeJ\nLppgKBJYx46l07//D3Ts+D5//OFZ3UpKimPEiMuYMeMOzj+/tOOEIiL507JlJXr1agl4prEOGDDV\ncSIJR35vjmyMKWeMaZ99aJOpc7Rp00HWrt0PQJs2VShaNNFxouiiCYYigTN79maaNXuDV1/9FZt9\ni2SbNlVYvPheHnqoDbGxfv8TIyISUp577lJKlkwC4KOPljJr1ibHiSTc+LNPV1FjzP8DtuG5p2sG\nsN0Y85ExpnigA0Ya39ZCTS0sePXrl9UEQ5F8On48nYcfnkT79u9530RKTIxl+PCuzJp1J3XrlnGc\nUEQksEqXLsxzz13qPe/TZyIZGVl/8hkiufnzNuTbwEXAlUCJ7ONKoBXwZuCiRaac1kLQ/VwuFC4c\nT40aJQDPSpe1mmAokhdz5myhWbM3eeWVud7VrYsuqszixffxyCMXa3VLRCJWr14tvRu7L126izff\nXOA4kYQTf/51vBK4y1o7yVp7OPuYBPwDuCqw8SJLVpZl2jTP/lzFiiVywQWVHSeKTjkthkePnmDr\n1sOO04iEh+PH03n00cm0a/cea9bsAzyrWy++2IXZs++iXj2tbolIZIuNjWHMmO7e8yefnM6ePSkO\nE0k48afo2odnT65THcIzyVDOYMmSnezdewyASy6pQVyc3hF2wXeYhloMRc7u11+30qLFv3n55Tne\n7S4uuKASixbdy4ABbbW6JSJRo23batx+e1PAs+/qE09Mc5xIwoU//1I+C7xijKmQcyH78XBgaKCC\nRSKNig8NGqYhcm5SUzMYOHAKF1/8LqtW7QUgISGWYcM688svd+f6uyQiEi1efLELRYsmAPDOO78x\nf/42x4kkHPhTdN0PtAY2G2PWGWPWAZuBi4F7jTGLco5ABo0EvvdzaYiGOyq6RM5u/vxttGjxJi+9\n9It3datly4osWtSLxx5rp5V6EYlaFSoU4emnOwFgrWeoRs7vSZEzifPjc74KeIookJqawaxZmwGo\nWrUYdepo7xpX6tdXe6HImaSlZTBkyE+5iq34+BiGDOnEgAFtVWyJiAB9+lzI22//xooVe5g3bxvv\nv7+Yu+5q7jqWhLA8F13W2qeDESTSzZ69mdTUDMDTWmhy5pZLgStSJIHq1YuzadMh7wRD/f8hAgsW\nbOeOO77K9WZEixYVef/9a2jcuLzDZCIioSU+PpbRo7vTufOHADz22FSuu64eJUsWcpxMQlV+Nkdu\nZYz5W/bRMpChIpFaC0NLTovh4cNpbNt2xHEaEbfS0jJ48skfad36bW/BFR8fw9ChlzB37t0quERE\nTuPSS8/jppsaArBnzzGeeuont4EkpPmzOXIVY8wsYB4wKvuYb4z52RhTJdABI4XvEI3OnVV0ueY7\nwVD3dUk0W7RoB61avcVzz80iM9PTTtisWQUWLOjFk092ID4+1nFCEZHQ9fLLXSlcOB6AsWPns3Tp\nLseJJFT5uzlyPFDfWlvKWlsKqJ/9td4OZLhIsW/fMRYt2gFA06blKVcu2XEi0TANiXYnTmQyePB0\nLrzwLX7/fTcAcXExPP10J+bNu4cmTbS6JSJyNlWrFufJJ9sDnv1Y+/SZgLUaqiH/lz9FV0fgfmvt\n6pwL2Y8fBDoEKlgkmTZtAzl//zQqPjT4Fl3Ll+92mESk4P322w4uuOAthg6d6V3datq0PPPn/4PB\ngztqdUtEJA8eeqgNtWuXAmDWrM2MH/+740QSivwpurbgWek6VSywPX9xIlPu/blqOUwiOXKvdO11\nmESk4Jw4kcmQIT9x4YVve1tg4uJieOqpjsyb9w+aNatwlq8gIiKnSkyM47XXLveeP/LIZI4cSXOY\nSEKRP0XXo8BoY0yrnAvZj0cBjwQqWKSw1nqHaCQkxNKuXTXHiQSgaNFEqlYtBuCdYCgSyZYs2clF\nF73N00/PICMjC4DGjcsxb949DBnSiYQErW6JiPire/fzueqqOgDs2HGUoUNnOk4kocafout9oBnw\nqzEmzRiTBvwKtADeNcbszzkCmDNsrV9/gI0bDwLQrl01782W4l7OatfBg6ns2HHUcRqR4EhPz+SZ\nZ2bQqtVbLF68E4DYWMOgQR1YsKAXzZtXdJxQRCQyjBzZjcTE2OzHc1m1Sp00cpI/myP3C3iKCJZ7\nVPx5DpPIqRo2LMukSX8AntWuSpWKOk4kEljLlu3i73//it9+2+m91qhROd5//xpatqzkMJmISOSp\nVasUAwa0ZejQmWRkZPHggxOZPPmv2gtUAP82R/4gGEEilW/Rpfu5QsupEwy1f5pEivT0TF58cTbP\nPDOD9HRPK2FsrOGxx9oxaFAHEhP9eb9NRETO5rHH2vHBB0vYvPkQU6eu53//W8Vf/lLfdSwJAX5v\njgxgjEkyxhTzPQIVLBJkZmbx448bAChVqhDNm+sm9VDSsGE572NNMJRI8fvvu2nT5h0GDZruLbga\nNCjL3Ln38Oyzl6rgEhEJosKF4xk5spv3vH//SRw7lu4wkYQKfzZHTjbGjDHG7AZSgAOnHJJt4cId\nHDyYCnh2LY+NzVeNKwFWv34Z72NNMJRwl5GRxfPPz6Jly3+zcKFnX8CYGMPjj7dj0aJetGqldkIR\nkYJw3XX1vFsEbd58iBde+NlxIgkF/lQBLwGXAvcDacA9wFN4xsXfHrho4S/3qHi1roWa4sWTqFzZ\ncx/X8uW7NcFQwtaKFXto0+Yd/vWvHzlxIhPwvKkwZ87dPP98Z61uiYgUIGMMr73Wnbg4z8vsl16a\nzfr1WpeIdv4UXVcBva21/wUygFnW2meBJ4DbAhku3OUeoqGiKxTltBgeOJDKrl0pjtOI5E1GRhYv\nvvgzzZu/yYIFnm0SY2IMAwe2ZdGie7nwwsqOE4qIRKd69crQv39rANLSMunff5LjROKaP0VXKSCn\nmjicfQ7wM9AhEKEiQUrKCWbP3gxAzZolqVmzpONEcjoNGvi2GO5xmEQkb1au3EPbtu/y2GPTvKtb\n9eqVYfbsu3jhhS4kJWl1S0TEpUGDOlCxYhEAvvlmNRMmrHWcSFzyp+haD+TMPl8F3JT9+CrgYCBC\nRYJZszZ7b2JXa2HoOnWCoUioy8zMYvjw2TRv/ibz5m0DwBh49NGLWbSoF61bV3GcUEREAIoWTeTl\nly/znv/znz+QlpbhMJG45E/R9R7QNPvxC8ADxphUYCQwPFDBwt2UKX94H6u1MHRpgqGEk1Wr9tKu\n3XsMGDCVtDTP6ladOqX5+ee7eOmlrhQqpM3XRURCSc+ejWjfvhoA69bt55VX5jhOJK7kueiy1o60\n1r6W/XgqUA+4FWhurR0V4Hxha+pUz6h4YzyTCyU0aYKhhIPMzCxGjPiFZs3eYO7crYDnd8tDD7Vm\n8eJ7ufjiqo4TiojI6RhjGDOmBzExng2Sn312Flu2HHKcSlzwZ2R8rt4Va+0ma+2X1tqlxpjWgYsW\nvnbtOsrSpbsAaNWqEqVKFXKcSM6kZMlC3n5rTTCUULRmzT46dHifRx6Z4l3dql27FLNm3cmIEd20\nuiUiEuKaNCnPAw9cAMCxY+k88sgUx4nEBX/aCycbY0qdetEY0xb4If+Rwp/vqHi1Foa+nBbDffuO\ns2fPMcdpRDwyM7MYOXIOTZu+wS+/bAE8q1v9+l3EkiX30bZtNccJRUTkXD3zzCWULVsYgM8+W86P\nP25wnEgKmj9F11w8hVfRnAvGmA7ABODpQAULZzmthaAhGuFAEwwl1Kxdu4+OHd/noYcmk5rquem6\nVq2SzJhxByNHXk7hwlrdEhEJJyVKJDFsWGfv+YMPTiQ9PdNhIilo/hRd9wCbgW+NMYnGmEuA74HB\n1tqRAU0Xhqy13iEahQrF6V6LMOA7wVDDNMSlrCzLqFFzadr0DWbP3uK93rfvhSxZch/t21d3mE5E\nRPLjzjubc8EFlQDPm7xjxsxznEgKkj+DNLKAW4B04EfgG+BxDdHwWL16H9u2HQGgQ4fqJCZqr5xQ\n5zvBUCtd4sq6dfvp1Ol9+vWbxPHjntWtmjVL8tNPf2fUqO4kJyc4TigiIvkRE2MYO7YHxjNTg6ee\n+omdO4+6DSUF5pyKLmNME98Dz8TCIUBV4CNgps/HoprvqHi1FoYHTTAUl7KyLKNH/0rTpm8wa9Zm\n7/U+fS5g6dL76NixhrtwIiISUBdcUJm7724OwJEjJxg4cKrjRFJQznUZZjFgAeNzLef8XqBX9mML\nxAYyYLiZMkVDNMJN6dKFKV8+mV27UtReKAVq/foD3HXX18yYscl7rUaNErz33jV06lTDXTAREQma\n55/vzBdfrOTgwVQ+/HAJvXq10HCkKHCu7YXnATWz/zzvNOc1ff6MWunpmfz000YAypVLpnHj8m4D\nyTnLaTHcs+cYe/akOE4jkS4ryzJ27DyaNHk9V8HVu3crli27XwWXiEgEK1s2mWefvcR73qfPRDIz\nsxwmkoJwTkVX9l5c53QEO3AomzdvG0eOnACgc+fzvBvhSejznWC4cqVaDCV4Nmw4QJcuH9Knz0RS\nUtIBqF69ONOm3c7YsVdQpIju3RIRiXT33tuKpk09b84vXryTf/97oeNEEmz+TC+UM/Ddn0v3c4UX\nTTCUYMvKsrz++nwaN36d6dM3eq/fd19Lli27n0svPc9dOBERKVBxcTGMGdPDe/7kk9PZt097hUYy\nFV0BpPu5wpcmGEowbdp0kMsu+3/07j3Bu7pVrVpxpkz5G6+/fiVFiyY6TigiIgWtXbtq/PWvnhl0\n+/cf51//+tFxIgkmFV0BcvhwGnPnbgWgbt3SVK1a3HEiyQvflS5NMJRAsdby5psLaNTodaZNO7lp\neq9eLVi27H69OSMiEuVeeqmLt6383/9eyMKF2x0nkmBR0RUgM2ZsJDPTAmotDEdlyhSmXLlkQO2F\nEhibNx+iW7ePuO++7zl61HOvZ9WqxZg06a+8+eZVFCum1S0RkWhXsWJRhgzpCIC1nqEaWVnWcSoJ\nhjwXXcaYqsaYKj7nFxpjXjXG9ApstPCi1sLwl7PatWtXivqqxW/WWt56ayGNGo3L9Xvhnnuas2zZ\n/Vx2WS2H6UREJNT07XuRd8/QuXO38uGHSxwnkmDwZ6XrY+ASAGNMBWAKcCHwnDFmcACzhZWcIRqx\nsUbjnsOUJhhKfm3Zcoju3f9Dr17feSeZVqlSjIkTb+Ott66mePEkxwlFRCTUxMfH8tpr3b3nAwdO\n5eDBVIeJJBj8KboaAfOyH98E/G6tvRi4DbgjQLnCytath70v0i+6qIpeWIUp32EaajGUvLDW8s47\ni2jU6HUmTfrDe/2uu5rx++/3c/nltR2mExGRUNelS01uuKEBALt3pzBkyE9uA0nA+VN0xQNp2Y+7\nAN9kP14FVAxEqHDjOyq+SxeNfQ5XuYdpaIKhnJutWw/To8fH3HPPtxw+7PnVWKlSUb7//lbeeeca\nvQkjIiLnZMSIyyhUKA6AMWPmsWzZLseJJJD8KbqWA/cZY9oDXYEfsq9XAvYFKlg4yb0/l+7XCFe5\n9+pS0SV/zlrLe+/9RqNG4/jhh3Xe63fc0Yzly3vTo8f5DtOJiEi4qVatOE880R6AzEzLgw9OxFoN\n1YgU/hRdA4F7gZ+A8dbanLv9ruZk22HUsNZ6i64iRRK46KLKjhOJv8qVS6ZMmcKAVrrkz23bdpgr\nrxzPXXd9w6FDntWtihWL8N13PXnvvWsoUUKrWyIiknePPHIxNWuWBGDGjE18+ulyx4kkUPJcdFlr\nfwLKAGWstXf5fOjfwH0ByhU2fv99N7t2pQDQqVMN4uNjHSeS/MhZ7dqx4ygHDhx3nEZCjbWWDz9c\nQqNGrzNhwlrv9b/9rQnLl/fmiivqOEwnIiLhLikpjlGjLveeP/zwZO+2IxLe/Nqny1qbaa09cMq1\njdbaqJs+4DsSWvtzhT/fCYZa7RJf27cf4eqrP+Hvf//KO1WqQoUifPPNLXz44XWULFnIcUIREYkE\nV15Zhyuu8LSob99+hGefnek4kQTCORddxpjpxpgfc45ghgon2p8rsvhOMFTRJeBZ3froo6U0e29X\nAgAAIABJREFUajSO775b471+222NWb68N1ddVddhOhERiUSvvno5CQme7qlXXpnD6tXayibc5WWl\n633gA58j6qWlZTBz5ibAM60sZ2M7CV+aYCi+du48yrXXfsrf/vY/DhzwrG6VL5/MV1/dzEcf/YVS\npbS6JSIigVe7dikeffRiANLTs+jb9wcN1Qhz51x0WWs/8D2CGSpczJmzlWPH0gHPKpcxxnEiyS9N\nMBTwrG59/PEyGjYcxzffrPZe79mzEcuX9+aaa+o5TCciItHg8cfbUbVqMQAmT/6Dr79efZbPkFDm\n1z1dAMaYBGNMFWNMNd8jkOFC3ZQpJzdB1f1ckaF8+WTv6oVWuqLTrl1Huf76z7jtti/Zv98zTKVc\nuWS+/PImPv74ekqXLuw4oYiIRIPk5AReeaWb97x//0kcP57uMJHkR56LLmNMHWPMLOA4sAnYkH1s\nzP4zakydevLH1f1ckcEY413t2rbtCIcOpTpOJAVp5co9NGw4jv/9b5X32s03N2T58t5cd119h8lE\nRCQaXX99fTp3Pg+AjRsP8tJLsx0nEn/5s9L1HpAFXAm0BFpkH82z/4wKBw4cZ8GC7QA0alSOChWK\nOE4kgaIJhtFryJAZ7NvnWd0qW7YwX3xxI598coN3/zYREZGCZIzhtde6Exfnecn+wguz2bDhwFk+\nS0KRP0VXM+Bea+1Ea+1ia+0S3yPQAUPV9Okbycry3NCo1sLIogmG0enIkTS+/dbTL1+mTGGWL+/N\n9dc3cJxKRESiXYMGZfnnPy8CIDU1g4cemuw4kfjDn6JrBZ7NkaOa7/1cai2MLJpgGJ2+/no1x49n\nAHDjjQ0oWzbZcSIRERGPwYM7eruqvvpqFT/8sM5xIskrf4qugcBLxphOxpjSxphivkegA4aqnP25\n4uNj6NixuuM0EkgNG2qCYTQaP/537+OePRs5TCIiIpJbsWKJDB/e1Xvet+9E0tIyHCaSvPKn6JoK\ntAamAbuBA9nHwew/I96GDQf44w/Pj3rxxVVJTk5wnEgCqUKFIpQokQRopSta7Nt3jMmTPavXVaoU\no23bqBrEKiIiYeC22xrTtm1VANau3c+rr851nEjywp+i65Ls49JTjpxrEW/q1PXex2otjDy+Ewy3\nbDnM4cNpjhNJsH3xxQoyMrIAuOWWhsTEaM89EREJLcYYxozp4f03aujQmWzdethxKjlXeS66rLUz\n/uwIRshQ4zsqXkM0IpNvi+HKlVrtinS5WwsbO0wiIiJyZs2aVeC++1oCkJKSzqOPTnGcSM6VX5sj\nG2PaG2M+Msb8YoypnH3tb8aYdoGNF3qysizTpnlWuooXT6Rly0qOE0kwaJhG9Ni27TAzZ24CoE6d\n0jRvXsFxIhERkTMbOvRSSpcuBMAnn/zOTz9tdBtIzok/myNfD0zCszlyCyAx+0PFgScCFy00/fbb\nDu8+Ppdeep533wSJLCq6osenny7HenZ/4NZbG2GMWgtFRCR0lSpViGHDOnvPH3xwIunpmQ4Tybnw\np2J4ErjPWvsPIN3n+myiYHNk3/u51FoYuTTBMHqotVBERMLNXXc1p1UrT7fV77/vZty4+Y4Tydn4\nU3TVBWae5vohoET+4oS+nFHxoCEakaxSpaIUK+ZZxNVKV+Rau3YfCxZsB6BFi4rUqVPacSIREZGz\ni42NYcyY7t7zwYN/Yteuow4Tydn4U3TtBGqf5no7YP1prkeM48fT+fnnzQBUr16c2rVLOU4kweI7\nwXDTpkMcPXrCcSIJBu3NJSIi4eqii6pw113NADh8OI2BA6c6TiR/xp+i6y1glDHmIsAClYwxtwEv\nA68HMlyo+fnnzaSleXpmu3SpqXs/IpwmGEY2a22uouvmmxs6TCMiIpJ3w4Z1oXhxT2fOBx8sYfbs\nzY4TyZn4U3S9AHyMZ3PkInhaDd8G3rTWjg5gtpDj21qo+7kin4ZpRLYlS3axatVeANq3r0bVqsUd\nJxIREcmbcuWSefbZk9vk9u49wbvvpIQWf/bpstba54BSQCOgNVDWWjso0OFCje8Qjc6dVXRFOt+i\nS8M0Is/48cu8j9VaKCIi4er++1t5tztZunQXY8fOc5xITsfveefW2hPW2hXW2nnW2oi/c2/PnhR+\n+20nAM2bV6BMmcKOE0mw+bYXaqUrsmRlWT75ZDkAsbGGG25o4DiRiIiIf2JjYxg7tof3fPDgn9ix\n44jDRHI6/uzTlWyMGZq9MfI6Y8x63yMYIUPBjz9u8D5Wa2F0qFKlGEWKJAAquiLNnDlb2Lz5EACX\nXVaLsmWTHScSERHxX5s2Vbn77uaAZ6jGo49OcZxITuXPStfbwN3ALGAMMOqUIyJpVHz08Z1guGHD\nQVJSNMEwUmhqoYiIRJphwzpTsmQSAP/5zzJmzNjoNpDk4k/R1R240Vo70Fr7qrV2lO8R6IChwFrr\nLboSE2Np166a40RSUHxbDHOGLkh4y8jI4rPPPK2FSUlxXHttPceJRERE8q9s2WSGDevsPX/ggQmk\np2c6TCS+/Cm6DgD7Ax0klK1bt9/bitS+fXUKFYp3nEgKiiYYRp5p09azZ88xAK68sg5FiyY6TiQi\nIhIY99zTglatKgGeIWCvvfar40SSw5+iaxDwjDEmaiZJ5G4tPM9hEilovitdmmAYGdRaKCIikSo2\nNoZx43qQs5XskCEz2LbtsNtQApxj0WWM+c0Ys8gYswh4COgG7DLGLMu57vPxiOM7Kr5r11oOk0hB\n00pXZElNzeB//1sFQLFiifTocb7jRCIiIoF1wQWV6dWrJQBHj57g4YcnO04kAHHn+LyvgpoihGVk\nZHknF5YuXYhmzSo4TiQFqWrV4iQnx5OSkq6iKwJMmLCWw4fTALjuunokJZ3rr0AREZHw8fzznfni\nixXs23ecTz9dzj/+0UJ7zDp2Tq84rLVPBztIqFqwYDuHDnlepHXuXJOYGOM4kRSkmBjPBMP587ez\nfv0Bjh1Lp3Bh3dMXrnxbC2+9tbHDJCIiIsFTqlQhXnyxC/fc8y3gGaqxdOn9JCTEOk4WvfzeHNkY\n09IY89fso3kgQ4WS3K2FeocgGuW0GFoLq1drgmG4Onw4je++WwNAuXLJXHqp7s8UEZHIdeedzWnT\npgoAq1fv45VX5jhOFN382Ry5nDHmR2A+8Fr2sdAYM80YU/bPPzv8aH8u0X1dkeGrr1aRmpoBwI03\nNiAuzu/3nEREREJeTIxh7Nge3i6toUNneqdxS8Hz51XHaKAo0NBaW8paWwpoBBTDU4BFjKNHTzBn\nzhYAatcuRY0aJRwnEhc0wTAyaGqhiIhEm+bNK9K7dysAjh1Lp3//SY4TRS9/iq7Lgd7W2pU5F6y1\nK4AH8GycHDFmztxEenoWoNbCaKaVrvC3Z08KU6b8AUC1asVp06aq40QiIiIFY+jQSylXLhmAL79c\nyQ8/rHOcKDr5U3TFAOmnuZ7u59cLWTkv0kCthdGsevUS3uEZWukKT198sYLMTAvALbc01EAcERGJ\nGiVKJDF8eFfv+YMPTvS220vB8adI+hEYZYyplHPBGFMZGAlMC1SwUDB1qmdUfEyM4ZJLajjNIu7E\nxBjq1y8DwPr1Bzh+/HTvOUgoy91aqKmFIiISXf72tya0a1cNgHXr9vPyy784ThR9/Cm6+uC5f2uj\nMeYPY8wfwIbsaw8GMpxLO3Yc4fffdwPQqlUlSpYs5DiRuJTTYpiVZVmzZp/jNJIXW7YcYtaszQDU\nq1eGpk3LO04kIiJSsIwxjBvXg9hYT6fHc8/NYsOGA45TRZc8F13W2i1AC+AK4NXso4e1toW1dmuA\n8zkzbdoG72PdzyW+93WpxTC8fPrpcu/jW29thDFqLRQRkejTuHF5+va9CIDU1Az69dNQjYLk1z1Y\n1mOKtXZ09jE10MFc8x0Vr6JLfCcYaphGeFFroYiIiMeQIZ2oWLEIAN98s9q7f6UE3zkXXcaYS40x\nK4wxxU7zseLGmOXGmG6BjeeGtdY7RKNw4Xhat67iOJG4pgmG4Wn16r0sWrQD8LQJ165dynEiERER\nd4oVS2TEiMu85337TtS96gUkLytd/YC3rLWHT/2AtfYQ8CYRck/Xhg0H2bHjKAAdO1YnMTHOcSJx\nrUaNEiQlef47UHth+NDeXCIiIrndcksj74C4DRsO8sILPzvNEy3yUnQ1BX74k49PBprkL05omDv3\n5K1pGhUvALGxMd4JhuvW7SctTaNWQ5211lt0GQM339zQcSIRERH3jDGMGdODuDhPGfDii7NZt26/\n41SRLy9FV3lOvz9Xjgyg7J98PGzMm7fN+1j3c0kOTTAML7/9ttP7/1OHDtWpXPn/dEaLiIhEpQYN\nytK/f2sA0tIy6dt3ItZax6kiW16Krm3An/XnNAF25C9OaFiwYDsA5csn06hROcdpJFRogmF4GT9+\nmfexWgtFRERyGzy4I5UrFwVg4sR1fPXVKseJIlteiq4JwFBjTNKpHzDGFAKeBr4LVDCXcm4o7NKl\npsZLi5cmGIaPrCzLJ594RsXHxcVwww0NHCcSEREJLUWKJDBy5MkZeP36TSIl5YTDRJEtL0XXs0Ap\nYI0xZoAx5prsYyCwOvtjzwUjpCtqLRRfmmAYPmbP3szWrZ6ZP9261aJ06cKOE4mIiISeG25o4H29\nu3nzIZ57bpbjRJHrnIsua+0u4GLgd2AY8L/s4/nsa+2ynxMxNERDfNWsWZLExFhA7YWhTlMLRURE\nzs4Yw+jR3YmP95QEL7/8C6tX73WcKjLlaXNka+0ma20PoAxwEdAaKGOt7WGt3RCMgK7Ur19GN95L\nLrGxMdSr55lguHbtPk6cyHScSE4nPT2Tzz7ztBYWKhTHNdfUc5xIREQkdNWtW4ZHH70YgPT0LPr0\n0VCNYMhT0ZXDWnvAWjvfWjvPWnsg0KFCgVoL5XRyWgwzMy1r12qCYSiaOnU9+/YdB+Cqq+pSpEiC\n40QiIiKh7Ykn2lOtWnHA8+/oF1+scJwo8vhVdEUDtRbK6fgO01CLYWhSa6GIiEjeJCcnMGrU5d7z\n/v0nceRImsNEkUdF12nExBg6darhOoaEIA3TCG3Hj6fzv/95Rt4WL55I9+61HScSEREJD9dcU9f7\n7+a2bUcYOnSm40SRRUXXaTRuXJ6iRRNdx5AQpL26Qtv336/l6FHPuNu//KU+iYlxjhOJiIiEh5yh\nGjlDw0aOnMvy5bsdp4ocIVN0GWMeMMZsMMYcN8bMNcZccJbnJxhjnjPGbDTGpBpj1htj7jjDc28x\nxmQZY748lywXXVTZj59AokGtWqVISPD8MtJKV+hRa6GIiIj/atUqxcCBbQHIyNBQjUAKiaLLGHMz\nMAJ4CmgOLAEmGWPK/MmnfQ5cAtwJ1AF64tkv7NSvXQMYDpzzGmnr1lXO9akSZeLiYqhbtzQAa9bs\nIz1dEwxDxaFDqXz//RoAypdP5pJLznOcSEREJPw89lg7zjuvBAA//bQx1xua4r+QKLqA/sCb1toP\nrbWrgPuAY8Bdp3uyMeZyoD3Qw1o73Vq72Vr7q7V2zinPiwE+AgYD5zzS3ndYgsipcloMMzKyWLt2\nv+M0kuN//1tFWpqnCL7ppobExYXKrzcREZHwUahQPKNHd/eeP/zwZA4f1lCN/HL+qsQYEw+0BKbl\nXLOedcypQJszfNpVwAJgoDFmqzFmtTFmuDEm6ZTnPQXssta+l5dMcXGxeXm6RBnfolwthqFDrYUi\nIiKBccUVdbj66roA7Nx5lKeemu44UfhzXnTh2Wg5Fth1yvVdQIUzfE5NPCtdDYFrgX8CNwBjc55g\njGmHp/XwngDnlSinCYahZ/fuFKZNWw9AjRol1CIsIiKST6NGXU5Skmcg1ejR81i69NSX6pIX4Tra\nKwbIAm611h4FMMY8BHxujOkNxAMfAv/wZ/Pm/v37U7x48VzXevbsSc+ePfMdXMKfJhiGns8/X05m\npudG31tuaYgxxnEiERGR8FajRgn+9a/2DBo0ncxMywMPTGDmzDsi9t/Y8ePHM378+FzXDh06FLCv\nb1xPJMluLzwGXG+t/cbn+vtAcWvtdaf5nPeBi621dXyu1QOW4xmqUQRYBGQCOf9l5KzqZQJ1rbX/\n5x4vY0wLYOHChQtp0aJF/n84iUjp6ZkkJz9PenoWjRqVY9my+11Hinrt2r3L7NlbAFiy5D6aNCnv\nOJGIiEj4S0vLoFGj11m3znMP+wcfXMvttzd1nKrgLFq0iJYtWwK0tNYuys/Xct5eaK1NBxYCnXOu\nGU8J3Rn45QyfNhuoZIwp7HOtLp7Vr63AKqAx0Axomn18A/yY/XhLYH8KiSbx8bHUqeOZYLh69V4y\nMrIcJ4pumzcf8hZcDRqUpXHjco4TiYiIRIbExDjGjDk5VOPRR6dw8GCqw0Thy3nRle0V4B/GmNuz\nV6zeAAoD7wMYY4YZYz7wef7HwD7gPWNMfWNMB+Al4B1rbVr2scL3AA4CR6y1K621GQX5w0nkyWkx\nTE/P8r77I2588knuARqR2vYgIiLiQrdutbn++vqA5x7qQYN+dJwoPIVE0WWt/Qx4BHgG+A1oAnSz\n1ubcMFMBqOrz/BSgK1ACmA/8P+BrPAM1RIJOEwxDh6YWioiIBNfIkd0oXDgegHHjFrBo0Q7HicJP\nSBRdANbacdbaGtbaQtbaNtbaBT4fu9Nae+kpz19jre1mrS1ira1urR1grT3jJgLZX+MvwfwZJHpo\ngmFoWLlyD4sX7wTgwgsrU6tWKceJREREIk/VqsUZPLgDAFlZnqEaWVlu50KEm5ApukTCScOGJ+8b\n0gRDd7TKJSIiUjD6929DvXplAJg7dyvvvfeb40ThRUWXiB9q1y5FXJznr49Wutyw1nqLLmPgppsa\nOk4kIiISuRISYnMN1Rg4cCr79x93mCi8qOgS8UNCQiznn+9pZdMEQzcWLtzhHWLSqVMNKlUq6jiR\niIhIZOvcuSY33+x5k3PfvuM88cQ0x4nCh4ouET/ltBimpWWyfn2e9+CWfBo/fpn3sVoLRURECsaI\nEZdRpEgCAP/+90Lmz9/mOFF4UNEl4qcGDcp4H6vFsGBlZVk+/XQ5APHxMVx/fQPHiURERKJD5crF\nGDKkIwDWQu/eE8jMVMfP2ajoEvGT7wTD5ct3O0wSfWbN2sS2bUcAuPzy2pQqVchxIhERkejRt+9F\n3u1zFizYzltvLXKcKPSp6BLxk+8EwxUr9jpMEn00tVBERMSd+PhYxo7t4T1/4olp7NmT4jBR6FPR\nJeKn888vRWysAdReWJBOnMjk889XAFC4cDxXX13XcSIREZHo07FjDf761yYAHDiQymOPTXWcKLSp\n6BLxU2JiHLVreyYYrlq1V/3MBWTKlD+8I2qvvrouyckJjhOJiIhEp+HDu1KsWCIA7767mDlztjhO\nFLpUdInkQ06LYWpqBhs2HHScJjqotVBERCQ0VKhQhKFDL/Ge9+49QdvonIGKLpF80ATDgnXsWDpf\nfbUKgBIlkujWrZbjRCIiItGtd+8LaNq0PACLF+/kjTcWOE4UmlR0ieSDJhgWrO++W0NKSjoA119f\nn8TEOMeJREREoltcXAzjxl3hPX/yyR/Zteuow0ShSUWXSD5ogmHBUmuhiIhI6Ln44qrceWczAA4d\nSmPAAA3VOJWKLpF8qFOnNDExmmBYEA4eTGXChLWAp4e8U6cabgOJiIiI1wsvdKFEiSQAPvxwCbNm\nbXKcKLSo6BLJh6SkOGrVKgnAypV7yMqyjhNFri+/XMmJE5kA3HxzQ2Jj9etLREQkVJQrl8zzz1/q\nPe/dewLp6ZkOE4UWvWoRyaecFsPjxzPYuFETDINFrYUiIiKhrVevlrRsWRGA33/fzZgx8xwnCh0q\nukTySRMMg2/nzqP8+OMGAGrWLMmFF1Z2nEhEREROFRvrGaphPHde8NRTP7F9+xG3oUKEii6RfNIE\nw+D7/PPl3tbNW25piMn5bS4iIiIh5cILK3PPPS0AOHLkBI88MtlxotCgoksknzTBMPhytxY2dphE\nREREzmbYsM6UKlUI8PwbPn36BseJ3FPRJZJPdetqgmEwbdx4kDlztgLQqFE5GjUqd5bPEBEREZdK\nly7MCy909p4/8MAE7zCsaKWiSySfChWKp2ZNzwTDFSs0wTDQPvlEAzRERETCzd13t/Deg71y5V5G\njZrrOJFbKrpEAiDnvq5jx9LZvPmQ4zSRRVMLRUREwk9MjGHcuB7eoRpPPz2DrVsPuw3lkIoukQDQ\nBMPgWL58N0uX7gKgdesqnHdeSceJRERE5Fy1bFmJ++9vBUBKSjoPPTTJcSJ3VHSJBIDvMA1NMAwc\nrXKJiIiEt2efvZSyZQsD8PnnK5g8+Q/HidxQ0SUSAL5j4zXBMDCstd6iKybGcNNNDR0nEhERkbwq\nWbIQL73U1Xv+4IMTSUvLcJjIDRVdIgFQr14Zb8+yVroCY/787axffwCASy6pQYUKRdwGEhEREb/c\nfntTLr64KgBr1uxjxIg5jhMVPBVdIgFQuHC8936jFSv2YK0mGObX+PHLvI/VWigiIhK+coZq5Gyx\n8+yzM9m06aDjVAVLRZdIgOS0GKakpLNlS/RO5wmEzMwsPv10OQDx8TH85S/1HScSERGR/GjatAJ9\n+lwAwPHjGfTrF11DNVR0iQSI7wRDtRjmz8yZm9ix4ygA3bufT8mShRwnEhERkfx65plLKF8+GYCv\nvlrFhAlrHScqOCq6RALEd4Khxsbnj+/UwltvVWuhiIhIJChePImXX77Me/7ggxNJTY2OoRoqukQC\nJPcEQxVd/jpxIpMvvlgBQHJyPFddVddxIhEREQmU225rTIcO1QFYv/4AL774s+NEBUNFl0iA1Kvn\n216oostfkyat48CBVACuuaYehQvHO04kIiIigWKMYezYHsTGeoZqDBv2s3dacSRT0SUSIEWKJFCj\nRglAEwzzQxsii4iIRLZGjcrRr19rANLSMunbd2LEv25S0SUSQDkthkeOnGDbtiOO04SflJQTfP31\nagBKlkzisstqOU4kIiIiwfDUUx2pVKkoAN9/v5Zvv13jOFFwqegSCSBNMMyfb79dw7Fj6QDccEMD\nEhJiHScSERGRYChaNJFXXjk5VKNv34ne1wCRSEWXSABpgmH+qLVQREQketx0U0M6dz4PgE2bDjFs\n2CzHiYJHRZdIAGmCof8OHDjOxIme/ToqVSrqnWwkIiIikckYw5gxPYiP95QkL730C2vX7nOcKjhU\ndIkEUP36mmDor//+dyXp6VkA3HxzQ2Jj9etJREQk0tWrV4aHH24DeLaN6dMnModq6FWNSAAVLZpI\ntWrFAU0wzCu1FoqIiESnJ5/sQNWqxQCYPPkPvvxypeNEgaeiSyTAcloMDx1KY8eOo47ThIcdO44w\nffoGAGrVKkmrVpUcJxIREZGCkpycwKuvXu4979dvEikpJxwmCjwVXSIB1rDhyfu6NMHw3Hz22XJy\nFgV79myEMcZtIBERESlQ111Xj27dPFvFbN16mKFDZzpOFFgqukQCTMM08i53a2Fjh0lERETEBWMM\no0d3924XM2LEHFaujJzXUSq6RALMt+jSMI2zW7/+AL/+ug2AJk3K5/rfT0RERKLH+eeXZsCAiwHI\nyMiKqKEaKrpEAkwrXXnzyScaoCEiIiIejz/enho1SgDw448b+Oyz5Y4TBYaKLpEAK1YskSpVPBN4\nNMHw7HxbC2+5RUWXiIhINCtcOJ5Ro04O1XjoockcOZLmMFFgqOgSCYKc1a4DB1LZuVMTDM9k2bJd\n/P67Z9jIxRdX9b6zJSIiItHr6qvrcuWVdQDYvv0ITz89w3Gi/FPRJRIEvhMM1WJ4ZtqbS0RERE5n\n1KjLSUqKA+DVV+d636QNVyq6RIJA93WdnbXWez9XTIzhxhsbOE4kIiIioaJmzZI8/ng7ADIzLQ88\nMCGsb9lQ0SUSBJpgeHa//rqNDRsOAtC583mUL1/EcSIREREJJQMGtKVWrZIAzJy5if/8Z5njRP5T\n0SUSBFrpOrvx40/+4lRroYiIiJwqKSmO0aO7e88feWQyhw6lOkzkPxVdIkFQokQSlSoVBTwrXeG8\nHB4MmZlZfPbZCgASEmK57rr6jhOJiIhIKOre/XyuvbYeALt2pTB48HTHifyjokskSHJWu/bvP87u\n3SmO04SWn37a6J3q2KPH+ZQokeQ4kYiIiISqV1/tRqFCnqEaY8bMZ8mSnY4T5Z2KLpEg0QTDM/Od\nWnjrrWotFBERkTOrXr0ETz7ZAYCsLEvv3hPIygqvLiIVXSJBovu6Ti8tLYMvvvC0FhYpkuDdh0NE\nRETkTB5+uA116pQG4JdftvDBB4sdJ8obFV0iQaIJhqf3ww/rOHTIs7P8tdfWo1CheMeJREREJNQl\nJsYxZszJoRoDBkzlwIHjDhPljYoukSDRStfpaUNkERER8UfXrrW8+3ru3XuMf/3rR8eJzp2KLpEg\nKVWqEBUqePaeUtHlcfToCb75ZjUApUsXomvXmo4TiYiISDh55ZVuJCd7umTeeGMBCxdud5zo3Kjo\nEgminGEae/YcY88eTTD85pvVHD+eAcANNzQgPj7WcSIREREJJ1WqFOOppzoCYC1hM1RDRZdIEKnF\nMDe1FoqIiEh+9evX2vsaa968bbzzziLHic5ORZdIEGmYxkn79h3jhx/WAVC5clHat6/uOJGIiIiE\no/j4WMaO7eE9f+yxaezde8xhorNT0SUSRNqr66T//nclGRlZANxySyNiYozjRCIiIhKuOnWqwa23\nNgZg//7jPPHENMeJ/pyKLpEgUnvhSWotFBERkUB6+eWuFC2aAMDbby/i11+3Ok50Ziq6RIKodOnC\nlCuXDER3e+G2bYeZMWMjAOefX4oWLSq6DSQiIiJhr2LFojzzzCXAyaEamZlZjlOdnooukSDLaTHc\nvTsl5PuNg+Wzz5ZjswcL9ezZCGPUWigiIiL516fPhTRuXA6ARYt28OabCx0nOj0VXSI7I88DAAAg\nAElEQVRB5ttiuHJldK525W4tbOwwiYiIiESSuLiYXEM1/vWvH9m9O/S26VHRJRJk0T7BcN26/cyf\n79m4sFmzCtSrV8ZxIhEREYkk7dtX5/bbmwJw8GAqAwdOdZzo/1LRJRJk0T7B8JNPNEBDREREguul\nl7pQvHgiAO+/v5jZszc7TpSbii6RIIvmCYbWWj7+eJn3/JZbVHSJiIhI4JUvX4Rnn73Ue9679wTv\nVjWhQEWXSJCVLZtMmTKFgehrL1y6dBcrV+4FoF27alSrVtxxIhEREYlU99/fiubNKwCe1yDjxs13\nnOgkFV0iBSCnxXDnzqPs33/ccZqCo725REREpKDExuYeqjFo0HR27DjiMNFJKrpECkA0TjC01nrv\n54qNNdx4YwPHiURERCTStWlTlbvvbg7A4cNpDBgQGkM1VHSJFIBonGA4Z85WNm06BECXLjUpWzbZ\ncSIRERGJBsOGdaZkySQAPvpoKTNmbHQbCBVdIgUiGicYjh9/coCGWgtFRESkoJQtm8ywYZ295w88\nMIH09EyHiVR0iRSIaJtgmJGRxWefrQAgMTGW666r7ziRiIiIRJN77mlBq1aVAE+X0Wuv/eo0j4ou\nkQJQrlwypUsXAqKjvXD69A3e3eCvuKIOxYolOk4kIiIi0SQ2NoZx43pgjOd8yJAZbNt22FkeFV0i\nBcAY413t2r79CAcPpjpOFFy+UwtvvVWthSIiIlLwLrigMr16tQTg6NETPPzwZGdZVHSJFJBoaTFM\nTc3gv/9dCUDRogn06HG+40QiIiISrZ5/vrN3v9RPP13OtGnrneRQ0SVSQKJlmMbEiWs5fDgNgOuu\nq0+hQvGOE4mIiEi0KlWqEC++2MV73qfPRE6cKPihGiq6RApItKx0aUNkERERCSV33NGMNm2qALBq\n1V5eeWVOgWdQ0SVSQKJhr64jR9L49ts1AJQpU5jOnc9znEhERESiXUyMYezYHsTEeKZqDB06k82b\nDxVshgL9biJRrEKFIt6N+iJ1pevrr1eTmpoBwI03NiA+PtZxIhERERFo3rwivXu3AuDYsXT6959U\noN9fRZdIAfGdYLh162HvfU+RRK2FIiIiEqqGDr2UcuWSAfjyy5X88MO6AvveKrpEClAk39e1d+8x\nJk/+A4AqVYrRtm01x4lERERETipRIonhw7t6zx98cKK3QyfYVHSJFKBInmD4xRcryMjIAjyrXDl9\n0yIiIiKh4m9/a0K7dp43htet28/LL/9SIN9XRZdIAYrklS61FoqIiEioM8YwblwPYmM9bw4/99ws\nNmw4EPTvq6JLpABF6gTDrVsPM2vWJgDq1i1Ns2YVHCcSEREROb3GjcvTt+9FAKSmZtCvX/CHaqjo\nEilAlSoVpXjxRCCyVro+/fR3rPU87tmzEcaotVBERERC15AhnahYsQgA33yzmu++WxPU76eiS6QA\n+U4w3Lz5EEeORMYEw9ythY0dJhERERE5u2LFEhkx4jLved++Ezl+PD1o309Fl0gB820xXLlyr8Mk\ngbF27T4WLtwBQIsWFalTp7TjRCIiIiJnd8stjbjkkhoAbNhwkBde+Dlo30tFl0gBi7QJhhqgISIi\nIuHIGMOYMT2Ii/OURC++OJt16/YH5Xup6BIpYJE0wdBay8cfL/Oe33xzQ4dpRERERPKmQYOy9O/f\nGoC0tEz69p2IzblRPYBUdIkUsIYNy3kfh/sEw8WLd7J69T4AOnSoTtWqxR0nEhEREcmbwYM7Urly\nUQAmTlzH11+vDvj3UNElUsAqVy5K0aIJQPivdKm1UERERMJdkSIJjBzZzXv+z3/+QErKiYB+DxVd\nIgXMd4Lhxo0HOXo0sH+pC0pWluWTTzxFV1xcDDfc0MBxIhERERH/3HBDA7p2rQl4Jkw///ysgH59\nFV0iDvgO01i1KjwnGP7yyxa2bDkMQNeuNSlTprDjRCIiIiL+McYwenR34uM95dHw4b+wceOBgH19\nFV0iDkTCMI3x408O0FBroYiIiIS7unXL8OijF///9u48yq6yzPf496lKKiOZiIQpSELIQEAUEMEW\nIzKjTCKQgFfAoS/X9rYLpVVsvLZTO7WC2k6r24tjQggNAi0QBrkqAkYIICYhkIEhQMIQCJlTqXrv\nH/tUPClTU+rs2uecfD9r1VpV++zhOXtVKue333c/G4Dm5la+9rV7K7ZvQ5dUgPLQtWDBCwVWsnO2\nbm1lzpyFAAwc2I8zz5xccEWSJEm995nPHMN++2WNwebNW1Gx/Rq6pAKUdzBcuLD2phfeddcyXnxx\nAwDvfvdEdtttQMEVSZIk9d6QIU18+9snV3y/hi6pAGPHDmPo0NrtYDhzpl0LJUlSfTrjjEmceuqB\nFd2noUsqQEQwZcpoAJYvf4UNG5oLrqj7Nm5s5oYbFgEwbNiAiv9RkiRJKlJE8J3vnMxll721Yvs0\ndEkFaZtimFJtdTC85ZYnWLs2a3P/nvdMYeDAfgVXJEmSVFkHHDCKGTMOqdj+DF1SQQ46aPS272tp\niqEPRJYkSeoZQ5dUkFrsYPjaa5v57/9+HIA99hjCO985ruCKJEmSqp+hSypILXYw/NWvHmPz5hYA\nzjnnIPr180+IJElSV/zEJBVkv/2GM3hwf6B2phc6tVCSJKnnDF1SQRoa/trBcOnS1WzcWN0dDF98\ncT133LEUyALj0UePLbgiSZKk2mDokgpU3sFw8eKXC66mc3PmLKSlJQHZKFdDQxRckSRJUm0wdEkF\nqqUOhk4tlCRJ2jmGLqlAtdLB8Omn13DPPU8DMGXKaN7whjEFVyRJklQ7DF1SgWqlg+Hs2duPckU4\ntVCSJKm7DF1SgfbffwSDBvUDqnt64fZTCyv3dHZJkqRdgaFLKlDWwTCbYrhkyWo2bdpacEV/a/Hi\nl3jooZUAHHHE3kyYMKrgiiRJkmqLoUsqWNt9Xa2ticcfr74OhjbQkCRJ6p2qCV0R8Q8RsTwiNkbE\n/RHx5i7Wb4qIL0fEkxGxKSKWRcRFZa+fFRF/iohXImJdRDwUEe/L/Y1IPVTewbDammmklLaFrgg4\n77ypBVckSZJUe/oVXQBARJwHfBP4e2AecCkwNyImppQ66i4wB3gdcDGwFNiL7UPky8CXgMeALcBp\nwNURsSqldEcub0TaCds306iu+7rmz39+2+jbtGn7s88+wwquSJIkqfZURegiC1k/Sin9DCAiLgHe\nBXwA+Hr7lSPiZOAYYHxK6dXS4qfL10kp/a7dZt+JiAuBtwGGLlWN8rbx1dbB0KmFkiRJvVf49MKI\n6A8cDtzVtiyllIA7gaM72Ow04AHgUxGxIiIWR8Q3ImJgJ8c5DpgI/LZixUsVMG7cCAYOzK5/VNP0\nwtbWxOzZCwDo16+Bs8+eUnBFkiRJtakaRrpGA43AqnbLVwGTOthmPNlI1ybgzNI+fgCMAj7YtlJE\nDAOeBQYAW4GPpJR+U8nipd5qbGxg8uTRPPzwSpYsWc3mzVsZMKD4f5r33PM0K1a8BsBJJx3A7rsP\nLrgiSZKk2lT8J7ud0wC0AuenlNYBRMTHgTkR8ZGU0ubSemuBQ4GhwHHAlRGxbAdTD7dz6aWXMnz4\n8O2WzZgxgxkzZlT4bUiZgw56HQ8/vJKWlsQTT6zm4IP36HqjnM2a9ei2751aKEmS6tmsWbOYNWvW\ndsvWrFlTsf1XQ+h6CWgBxrRbPgZY2cE2zwPPtgWukkVAAPuSNdZom6a4rPT6nyPiIOByoNPQdeWV\nV3LYYYf15D1IvdK+g2HRoau5uYU5cxYCMGhQP844Y3Kh9UiSJOVpRwMs8+fP5/DDD6/I/gu/pyul\n1Aw8SDYSBUBEROnnezvY7A/A3hFRPt9pEtno14pODtdANtVQqirV1sHwzjuX8fLLGwE47bRJDB3a\nVHBFkiRJtavw0FXyLeDDEfH+iJgM/BAYDPwEICK+EhE/LVt/JllL+KsjYkpEvJ2sy+GP26YWRsSn\nI+L4iBgXEZMj4hPA+4Cf993bkrqn2joYzpxp10JJkqRKqYbphaSUro2I0cAXyKYVPgyclFJqu+S/\nJzC2bP31EXEC8F3gT2QBbDbw2bLdDgG+RzbdcCPZ87ouSCldl/PbkXps/PiRNDU1smVLS+EdDDds\naOZXv3oMgOHDB3DKKRMKrUeSJKnWVUXoAkgpfR/4fgevXbyDZY8DJ3Wyv8+yfQiTqla/flkHwz//\neRVPPLGaLVtaaGpqLKSWX//6cdat2wLA2WdPqYpOipIkSbWsWqYXSru8timGW7e2smTJ6sLq2P6B\nyIcUVockSVK9MHRJVaJ9B8MirFmziVtueQKAMWOGcOyx+xdShyRJUj0xdElVoho6GN5ww2Ns3twC\nwLnnTqWx0T8RkiRJveUnKqlKVEMHw+2nFtq1UJIkqRIMXVKVmDBhFP37Z/8ki5heuGrVOu66K3uW\n+P77j+Coo/bt8xokSZLqkaFLqhL9+jUwaVJ2X9fjj79Mc3NLnx5/zpyFtLQkAKZPn0r2jHJJkiT1\nlqFLqiJtUwybm/u+g2H51MLzz7droSRJUqUYuqQqMnVq+X1dfddM46mnXuXee5/ZVsMhh4zps2NL\nkiTVO0OXVEW2b6bRd6HrmmtsoCFJkpQXQ5dURcpD14IFfRe6yqcWTp9u6JIkSaokQ5dURQ48cBT9\n+mX/LPtqpGvRohd55JFVABx55D4ccMCoPjmuJEnSrsLQJVWR/v0bmThxdwAWL36ZrVtbcz+mz+aS\nJEnKl6FLqjJtUwy3bGlh6dJ8OximlLaFrgg499ypuR5PkiRpV2TokqpMX3YwfOCB57a1pn/HO/Zn\n7713y/V4kiRJuyJDl1Rl+rKDoc/mkiRJyp+hS6oyfdXBsKWlldmzFwDQv38DZ589JbdjSZIk7coM\nXVKVmThxdxobA8h3pOv3v3+a555bC8DJJ09g5MhBuR1LkiRpV2bokqpMU1MjBx6YdTB87LGXaGnJ\np4PhrFmPbvveroWSJEn5MXRJVahtiuHmzS0sW/ZKxfe/ZUsL1123CIDBg/tz+umTKn4MSZIkZQxd\nUhXKu4PhHXcsZfXqjQCcfvokhgxpqvgxJEmSlDF0SVUo7w6GM2f6QGRJkqS+YuiSqlCeHQw3bGjm\nxhsfA2DkyIGcfPKEiu5fkiRJ2zN0SVVo0qTdaWjIp4PhzTcvZv36ZgDOPnsKTU2NFd2/JEmStmfo\nkqrQgAH9mDBhFACLFlW2g2H5A5FnzPCByJIkSXkzdElVqq2ZxqZNW3nyyVcrss9XX93ErbcuAWCv\nvYYybdrrK7JfSZIkdczQJVWpPJppXH/9IrZsaQHg3HOn0tjonwBJkqS8+YlLqlJ5NNPYfmqhXQsl\nSZL6gqFLqlKVflbXypXr+M1vlgMwfvxIjjxyn17vU5IkSV0zdElVauLEynYwvPbaBbS2JgCmT59K\nRPR6n5IkSeqaoUuqUoMG9Wf8+JFA1sGwLTDtrPKpheefb9dCSZKkvmLokqpY2xTDDRuaeeqpne9g\nuHz5K9x//woADjlkD6ZO3aMi9UmSJKlrhi6pilWqg+E119hAQ5IkqSiGLqmKVaqDYfnUwunTDV2S\nJEl9ydAlVbFKdDBcsOAFHn30BQCOOmpfxo0bWZHaJEmS1D2GLqmKTZo0mrYmgzsbunw2lyRJUrEM\nXVIVGzy4/7aRqYULX+xxB8OU0rbQ1dAQnHvu1IrXKEmSpM4ZuqQq1zbFcP36Zp55Zk2Ptp0371mW\nLXsFgGOP3Z899xxa6fIkSZLUBUOXVOV608HQZ3NJkiQVz9AlVbmd7WDY0tLK7NkLAGhqauQ975lS\n8dokSZLUNUOXVOV2toPhb3/7FCtXrgPglFMmMGLEwIrXJkmSpK4ZuqQqN3ny6G3f92Ska9asR7d9\nb9dCSZKk4hi6pCo3ZEgT48aNALKRrpS67mC4ZUsL//Vfi0rb9+e00yblWqMkSZI6ZuiSakDbfV3r\n1m1hxYrXulx/7twlvPLKJgDOOGMygwf3z7U+SZIkdczQJdWAnjbTmDnTByJLkiRVC0OXVAN60kxj\n/fot3HTTYgBGjhzIiScekGttkiRJ6pyhS6oBPXlW1003LWbDhmYAzjnnIJqaGnOtTZIkSZ0zdEk1\nYMqU7k8vLH8g8owZPhBZkiSpaIYuqQYMHdrE618/HOi8g+Hq1Ru57bYlAOy9924cc8x+fVajJEmS\ndszQJdWItimGr722meeeW7vDda6/fhHNza0AnHfeVBob/ScuSZJUND+RSTWiOx0Mt59aaNdCSZKk\namDokmpEVx0Mn39+LXffvRyAAw4YyRFH7N1ntUmSJKljhi6pRnTVwXD27AW03eo1Y8bBRERflSZJ\nkqROGLqkGtFVB8PyqYXnn2/XQkmSpGph6JJqxLBhAxg7dhjwtx0Mly5dzbx5zwJw6KFjtgtokiRJ\nKpahS6ohbVMMX311EytXrtu2/JprbKAhSZJUrQxdUg3pqINh+dTC6dMNXZIkSdXE0CXVkB11MHz0\n0VXbAthb3zqW179+RCG1SZIkaccMXVIN2VEHQ5/NJUmSVN0MXVINaT+9MKW0LXQ1NATnnHNQUaVJ\nkiSpA4YuqYYMHz6QffbZDYAFC17g/vtX8OSTrwJw3HHjGDNmaJHlSZIkaQcMXVKNaRvteuWVTVx1\n1R+3LffZXJIkSdXJ0CXVmPJmGtdeuwCAAQMaOeusyUWVJEmSpE4YuqQaU35fV5tTTz2Q4cMHFlCN\nJEmSumLokmrMjkKXXQslSZKql6FLqjHtQ9fQoU28+90TC6pGkiRJXTF0STVm5MhB7LXXX7sUnnnm\nZAYN6l9gRZIkSeqMoUuqQeWjXU4tlCRJqm6GLqkGXXzxG2loCI48ch9OOGF80eVIkiSpE/2KLkBS\nz11wwRs45ZQDGTFiIA0NUXQ5kiRJ6oShS6pRo0YNKroESZIkdYPTCyVJkiQpR4YuSZIkScqRoUuS\nJEmScmTokiRJkqQcGbokSZIkKUeGLkmSJEnKkaFLkiRJknJk6JIkSZKkHBm6JEmSJClHhi5JkiRJ\nypGhS5IkSZJyZOiSJEmSpBwZuiRJkiQpR4YuSZIkScqRoUuSJEmScmTokiRJkqQcGbokSZIkKUeG\nLkmSJEnKkaFLkiRJknJk6JIkSZKkHBm6JEmSJClHhi5JkiRJypGhS5IkSZJyZOiSJEmSpBwZuiRJ\nkiQpR4YuSZIkScqRoUuSJEmScmTokiRJkqQcGbokSZIkKUeGLkmSJEnKkaFLkiRJknJk6JIkSZKk\nHBm6JEmSJClHhi5JkiRJypGhS5IkSZJyZOiSJEmSpBwZuiRJkiQpR4YuSZIkScqRoUuSJEmScmTo\nkiRJkqQcGbokSZIkKUeGLkmSJEnKkaFLfWLWrFlFl1CXPK/58Lzmw/OaD89rPjyv+fC85sPzmo/b\nbrutYvuqmtAVEf8QEcsjYmNE3B8Rb+5i/aaI+HJEPBkRmyJiWURcVPb6hyLidxGxuvR1R1f7VH78\nY5APz2s+PK/58Lzmw/OaD89rPjyv+fC85mPu3LkV21dVhK6IOA/4JvA54E3AI8DciBjdyWZzgGOB\ni4GJwAxgcdnr04CZwDuAo4BngNsjYq9K1y9JkiRJHelXdAEllwI/Sin9DCAiLgHeBXwA+Hr7lSPi\nZOAYYHxK6dXS4qfL10kp/Y9223wIOBs4DvhFpd+AJEmSJO1I4SNdEdEfOBy4q21ZSikBdwJHd7DZ\nacADwKciYkVELI6Ib0TEwE4ONQToD6yuTOWSJEmS1LVqGOkaDTQCq9otXwVM6mCb8WQjXZuAM0v7\n+AEwCvhgB9t8DXiWLMx1ZCDAokWLulO3emDNmjXMnz+/6DLqjuc1H57XfHhe8+F5zYfnNR+e13x4\nXvOxdu3aiu0rskGl4pTusXoWODql9Mey5V8D3p5S+pvRroiYC7wNGJNSWldadhbZfV5DUkqb263/\naeAyYFpKaUEntZwP/LL370qSJElSnTg8pdSrVFsNI10vAS3AmHbLxwArO9jmeeDZtsBVsggIYF9g\nadvCiLgM+CRwXGeBq2QucAHwJNkomiRJkqRdU9utS4/1dkeFh66UUnNEPEjW4OImgIiI0s/f6WCz\nPwDvjYjBKaUNpWWTgFZgRdtKEfFJ4HLgxJTSQ92o5WWyjoeSJEmSVBGFN9Io+Rbw4Yh4f0RMBn4I\nDAZ+AhARX4mIn5atPxN4Gbg6IqZExNvJuhz+uG1qYUR8CvgCWQfEpyNiTOlrSJ+9K0mSJEm7vMJH\nugBSSteWnsn1BbJphQ8DJ6WUXiytsicwtmz99RFxAvBd4E9kAWw28Nmy3V5C1q3wunaH+3zpOJIk\nSZKUu8IbaUiSJElSPauW6YWSJEmSVJcMXUBEHBMRN0XEsxHRGhGnF11TrYuIyyNiXkS8FhGrIuKG\niJhYdF21LiIuiYhHImJN6eveiDi56LrqTUR8uvS34FtF11LrIuJzpXNZ/rWw6LrqQUTsHRE/j4iX\nImJD6W/DYUXXVcsiYvkOfl9bI+K7RddWyyKiISK+GBHLSr+rSyLiiqLrqgcRMTQiroqIJ0vn9p6I\nOKLoumpJd3JARHwhIp4rneM7ImJCT49j6MoMIbuP7COA8y0r4xiye+7eAhxPdn/d7RExqNCqat8z\nwKeAw4DDgd8AN0bElEKrqiMR8Wbg74FHiq6ljvyF7H7dPUtfbyu2nNoXESPIOvluBk4CpgCfAF4p\nsq46cAR//T3dEziB7HPBtUUWVQc+DfxPss9Zk8ke5fPJiPhooVXVhx+Tdfy+ADgYuAO4s/QcXHVP\npzmg1Jzvo2SfDY4E1gNzI6KpJwfxnq52IqIVODOldFPRtdSTUqOUF8geeH1P0fXUk4h4GbgspXR1\n0bXUuogYCjwI/C+yxjwPpZQ+XmxVtS0iPgeckVJyBKaCIuKrwNEppWlF11LPIuIq4NSUkjM1eiEi\nbgZWppQ+XLbsOmBDSun9xVVW2yJiILAWOC2ldFvZ8geAW1JK/6ew4mrUjnJARDwHfCOldGXp52HA\nKuDClFK3L8g40qW+MoLs6sHqogupF6XpGtPJHq9wX9H11InvATenlH5TdCF15sDStI2lEfGLiBjb\n9SbqwmnAAxFxbWkK9/yI+FDRRdWTiOhPNnrw46JrqQP3AsdFxIEAEXEo8HfALYVWVfv6AY1kI97l\nNuKMgoqIiHFko953tS1LKb0G/BE4uif7qoqW8apvpYddXwXck1LyXo5eioiDyUJW2xWus1JKvX5S\n+q6uFGDfSDa9SJVzP3ARsBjYC/gX4HcRcXBKaX2BddW68WQjst8Evkw25eU7EbE5pfTzQiurH2cB\nw4GfdrWiuvRVYBjwWES0kF30/+eU0jXFllXbUkrrIuI+4LMR8RjZ6Mv5ZGHgiUKLqx97kg0arGq3\nfFXptW4zdKkvfB84iOyqlnrvMeBQsg8D7wV+FhFvN3jtvIjYl+zCwPEppeai66knKaW5ZT/+JSLm\nAU8B5wJOid15DcC8lFLb8ykfKV2QuQQwdFXGB4BbU0oriy6kDpxHFgamAwvJLnB9OyKe8yJBr70P\n+L/As8BWYD4wk+y+b1URpxcqVxHx78CpwDtSSs8XXU89SCltTSktSyk9lFL6Z7KGDx8ruq4adzjw\nOmB+RDRHRDMwDfhYRGwpjdaqAlJKa4DHgR53ftJ2ngcWtVu2CNivgFrqTkTsR9YE6j+KrqVOfB34\nakppTkppQUrpl8CVwOUF11XzUkrLU0rHkjWDGJtSOgpoApYVW1ndWAkEWTOocmNKr3WboUu5KQWu\nM4BjU0pPF11PHWsABhRdRI27EziE7OrroaWvB4BfAIcmOw5VTKlZyQSy0KCd9wdgUrtlk8hGEdV7\nHyCbPuQ9R5UxGGhpt6wVP4dWTEppY0ppVUSMJOto+quia6oHKaXlZOHquLZlpUYabyG7V7HbnF4I\nRMQQsg8BbVezx5du8lydUnqmuMpqV0R8H5gBnA6sj4i2KwRrUkqbiqustkXEvwK3Ak8Du5Hd5D0N\nOLHIumpd6d6i7e43jIj1wMsppfajCeqBiPgGcDNZGNgH+DzQDMwqsq46cCXwh4i4nKyd+VuADwEf\n7nQrdak0sn0R8JOUUmvB5dSLm4ErImIFsIDssSeXAv9ZaFV1ICJOJPv8uhg4kGxUcSHwkwLLqind\nyAFXkf3+LgGeBL4IrABu7MlxDF2ZI4C7yW6US2Q3JkN28+wHiiqqxl1Cdi7/X7vlFwM/6/Nq6sce\nZL+XewFrgD8DJ9ptLxeOblXGvmT3F+wOvAjcAxyVUnq50KpqXErpgYg4i6xBwWeB5cDHbExQEccD\nY/Gew0r6KNkH1e+R/T/2HPCD0jL1znDgK2QXtVYD1wFXpJTajyyqY53mgJTS1yNiMPAjsm7cvwdO\nSSlt6clBfE6XJEmSJOXIubSSJEmSlCNDlyRJkiTlyNAlSZIkSTkydEmSJElSjgxdkiRJkpQjQ5ck\nSZIk5cjQJUmSJEk5MnRJkiRJUo4MXZIkSZKUI0OXJEmSJOXI0CVJ6lMRcXdEfKugY18YEat7uM3V\nEXF9F+ssj4h/7F11kqR6ZeiSJO1KrgEmFl2EJGnX0q/oAiRJ6isppc3A5qLr6I6I6J9Sai66DklS\n7znSJUkqVES8KyJejYgZXax3dUTcEBGfiIjnIuKliPj3iGgsW6cpIv4tIlZExLqIuC8ippW9fmFE\nvNJuv1dExKpSDT+MiH+NiId2cPwOj1syLCJmlo67IiI+0m77sRFxY0SsjYg1ETE7IvYoe/1zEfFQ\nRHwwIpYBG0vL3xsRf46IDaVj3x4Rg7pzbiVJ1cHQJUkqTEScD/wSmJFSmtWNTY4FxgPvAN4PXFT6\navM94C3AucAhwBzg1og4oGydVHb8C4DPAP8EHAE8C3ykfJ2Sd3ZxXIDLgIeANwJfBb4dEceVjhPA\nTcAI4Bjg+NL+rmm3jwnAe4CzgDdGxJ7ATOA/gcnANOB6IHZwbiRJVSpSav//ihXgTFcAAAMhSURB\nVCRJ+YmIu8nCyRLgS8DpKaV7urHd1WSh44BU+s8rImYDLSml8yNiP2ApMDaltLJsuzuAP6aUroiI\nC4ErU0qjSq/dB8xLKX2sbP3fA0NSSod157iln5cDC1NK7yrbzyxgt5TSuyPiBODXwP4ppedKr08B\nFgBvTik9GBGfAy4H9k4prS6t8ybggdJ2z3T/LEuSqokjXZKkIpwDfAs4oTuBq8yCtP3VwueBtil6\nBwONwOOlKXxrI2It8HbgAHZsEvCndsvm9fC4be7bwc9TSt9PBp5pC1wAKaVFwKtl6wA81Ra4Sh4B\n7gL+EhHXRsSHImJEB+9FklSlbKQhSSrCfOAw4IPAgz3Yrn1jicRfLyAOBbaW9tvabr11O1Fjd49b\nSeu3O0hKrcCJEXE0cCLwv4EvRcRbUkpP5XB8SVIOHOmSJBVhKdn9WWdExHcrtM+HyEa6xqSUlrX7\neqGDbRYDb263rP3P3XXUDn5eVPp+ETA2IvZpezEiDiK7x2tBVztOKd2XUvo88CayAHjWTtYoSSqA\nI12SpEKklJZExLHA3RGxNaV0aS/390REzAR+FhFtTS32IGuC8UhK6dYdbPZd4D8i4kHgXmA68Aay\nUNhTf1c67o1ko1LvBU4t1XZnRPwF+GVEXAr0J2v6cXdK6W86JbaJiCOB44DbgRfIgtxoYOFO1CdJ\nKoihS5LU17bdG5VSerzU4a8teP1TL/d9EXAF8G/APsBLwP3AzTssJKWZETEO+AYwELgW+Ak9H+1K\nwDfJOiD+C7AGuDSldGfZOqeThbzfkk1/vBX4xy72+xrZPWkfA4YBTwEfTynd3sP6JEkFsnuhJEll\nIuJ24PmU0oVF1yJJqg+OdEmSdlmlhwxfAswlG32aQTad7/gi65Ik1RdHuiRJVaHU3j3xtw/+TcAp\nKaU/5HDMgWRTD99INr1wMfDFlNKNlT6WJGnXZeiSJFWFiBjfycvPppQ291kxkiRVkKFLkiRJknLk\nc7okSZIkKUeGLkmSJEnKkaFLkiRJknJk6JIkSZKkHBm6JEmSJClHhi5JkiRJypGhS5IkSZJy9P8B\nrwzepHE727AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb6641702d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import datasets, metrics, tree\n",
    "\n",
    "from imblearn import over_sampling\n",
    "from imblearn import pipeline as pl\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "LW = 2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.cohen_kappa_score)\n",
    "\n",
    "# Generate the dataset\n",
    "X, y = datasets.make_classification(n_classes=2, class_sep=2,\n",
    "                                    weights=[0.1, 0.9], n_informative=10,\n",
    "                                    n_redundant=1, flip_y=0, n_features=20,\n",
    "                                    n_clusters_per_class=4, n_samples=5000,\n",
    "                                    random_state=RANDOM_STATE)\n",
    "\n",
    "smote = over_sampling.SMOTE(random_state=RANDOM_STATE)\n",
    "cart = tree.DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "pipeline = pl.make_pipeline(smote, cart)\n",
    "\n",
    "param_range = range(1, 11)\n",
    "#train_scores, test_scores = ms.validation_curve(\n",
    "#    pipeline, X, y, param_name=\"smote__k_neighbors\", param_range=param_range,\n",
    "#    cv=3, scoring=scorer, n_jobs=1)\n",
    "\n",
    "clf = GridSearchCV(pipeline,param_grid={\"smote__k_neighbors\":param_range}\n",
    "                           cv = 6, scoring='%s_macro' %score, n_jobs = 5)\n",
    "clf.fit(X_train,y_train_new)\n",
    "print(classification_report_imbalanced(y_test_new, clf.predict(X_test)))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SMOTE-CART\")\n",
    "plt.xlabel(\"k_neighbors\")\n",
    "plt.ylabel(\"Cohen's kappa\")\n",
    "plt.plot(param_range, test_scores_mean, color=\"navy\", lw=LW)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2,  0.4,  0.6,  0.8])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.2,1,step=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature name:  ADHFeatures_maxCooc10_k90_onlynuclei.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "{'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__n_estimators': 10, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 4, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.95      0.57      0.82      0.71      0.46      0.22      1022\n",
      "          1       0.22      0.82      0.57      0.35      0.46      0.19       152\n",
      "\n",
      "avg / total       0.86      0.60      0.78      0.66      0.46      0.22      1174\n",
      "\n",
      "Accuracy =  0.600511073254\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.89      0.60      0.53      0.71      0.38      0.15       257\n",
      "          1       0.16      0.53      0.60      0.25      0.38      0.13        38\n",
      "\n",
      "avg / total       0.80      0.59      0.54      0.65      0.38      0.15       295\n",
      "\n",
      "Accuracy =  0.586440677966\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "{'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__n_estimators': 10, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 1, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.61      0.81      0.73      0.61      0.39       878\n",
      "          1       0.41      0.81      0.61      0.55      0.61      0.35       296\n",
      "\n",
      "avg / total       0.78      0.66      0.76      0.68      0.61      0.38      1174\n",
      "\n",
      "Accuracy =  0.660988074957\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.80      0.60      0.55      0.68      0.50      0.26       221\n",
      "          1       0.32      0.55      0.60      0.40      0.50      0.24        74\n",
      "\n",
      "avg / total       0.68      0.59      0.56      0.61      0.50      0.26       295\n",
      "\n",
      "Accuracy =  0.586440677966\n",
      "feature name:  ADHFeatures_maxCooc10_k95.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "{'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 5, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.96      0.77      0.76      0.85      0.56      0.33      1022\n",
      "          1       0.33      0.76      0.77      0.46      0.56      0.29       152\n",
      "\n",
      "avg / total       0.87      0.77      0.76      0.80      0.56      0.33      1174\n",
      "\n",
      "Accuracy =  0.767461669506\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.91      0.75      0.47      0.82      0.45      0.22       257\n",
      "          1       0.22      0.47      0.75      0.30      0.45      0.19        38\n",
      "\n",
      "avg / total       0.82      0.72      0.51      0.76      0.45      0.21       295\n",
      "\n",
      "Accuracy =  0.718644067797\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "{'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 8, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.77      0.75      0.83      0.69      0.49       878\n",
      "          1       0.52      0.75      0.77      0.62      0.69      0.46       296\n",
      "\n",
      "avg / total       0.81      0.77      0.76      0.78      0.69      0.48      1174\n",
      "\n",
      "Accuracy =  0.765758091993\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.80      0.72      0.45      0.76      0.53      0.29       221\n",
      "          1       0.35      0.45      0.72      0.39      0.53      0.27        74\n",
      "\n",
      "avg / total       0.68      0.65      0.52      0.67      0.53      0.29       295\n",
      "\n",
      "Accuracy =  0.654237288136\n",
      "feature name:  ADHFeatures_maxCooc10_k90.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "{'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 6, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.95      0.74      0.75      0.83      0.53      0.30      1022\n",
      "          1       0.30      0.75      0.74      0.43      0.53      0.26       152\n",
      "\n",
      "avg / total       0.87      0.74      0.75      0.78      0.53      0.30      1174\n",
      "\n",
      "Accuracy =  0.738500851789\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.77      0.42      0.83      0.44      0.21       257\n",
      "          1       0.22      0.42      0.77      0.29      0.44      0.18        38\n",
      "\n",
      "avg / total       0.81      0.73      0.47      0.76      0.44      0.20       295\n",
      "\n",
      "Accuracy =  0.728813559322\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "{'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__n_estimators': 50, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 3, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.75      0.80      0.83      0.69      0.50       878\n",
      "          1       0.52      0.80      0.75      0.63      0.69      0.46       296\n",
      "\n",
      "avg / total       0.82      0.76      0.79      0.78      0.69      0.49      1174\n",
      "\n",
      "Accuracy =  0.764906303237\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.85      0.76      0.59      0.80      0.62      0.40       221\n",
      "          1       0.46      0.59      0.76      0.52      0.62      0.37        74\n",
      "\n",
      "avg / total       0.75      0.72      0.64      0.73      0.62      0.40       295\n",
      "\n",
      "Accuracy =  0.722033898305\n",
      "feature name:  ADHFeatures_maxCooc5_k90.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "{'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__max_depth': 10, 'smote__k_neighbors': 8, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.97      0.86      0.85      0.92      0.68      0.49      1022\n",
      "          1       0.48      0.85      0.86      0.61      0.68      0.44       152\n",
      "\n",
      "avg / total       0.91      0.86      0.85      0.88      0.68      0.48      1174\n",
      "\n",
      "Accuracy =  0.861158432709\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.88      0.81      0.24      0.84      0.37      0.14       257\n",
      "          1       0.15      0.24      0.81      0.19      0.37      0.12        38\n",
      "\n",
      "avg / total       0.78      0.73      0.31      0.76      0.37      0.14       295\n",
      "\n",
      "Accuracy =  0.732203389831\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "{'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__max_depth': 10, 'smote__k_neighbors': 6, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.98      0.90      0.94      0.94      0.87      0.77       878\n",
      "          1       0.77      0.94      0.90      0.85      0.87      0.74       296\n",
      "\n",
      "avg / total       0.93      0.91      0.93      0.92      0.87      0.76      1174\n",
      "\n",
      "Accuracy =  0.913969335605\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.77      0.77      0.31      0.77      0.49      0.25       221\n",
      "          1       0.31      0.31      0.77      0.31      0.49      0.23        74\n",
      "\n",
      "avg / total       0.65      0.65      0.43      0.65      0.49      0.24       295\n",
      "\n",
      "Accuracy =  0.654237288136\n",
      "feature name:  ADHFeatures_maxCooc10_k95_onlynuclei.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "{'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__n_estimators': 10, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 10, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.95      0.68      0.76      0.79      0.50      0.27      1022\n",
      "          1       0.26      0.76      0.68      0.39      0.50      0.23       152\n",
      "\n",
      "avg / total       0.86      0.69      0.75      0.74      0.50      0.26      1174\n",
      "\n",
      "Accuracy =  0.690800681431\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.72      0.61      0.81      0.47      0.24       257\n",
      "          1       0.24      0.61      0.72      0.35      0.47      0.21        38\n",
      "\n",
      "avg / total       0.84      0.71      0.62      0.75      0.47      0.24       295\n",
      "\n",
      "Accuracy =  0.705084745763\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "{'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__n_estimators': 50, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 6, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.89      0.75      0.73      0.82      0.67      0.46       878\n",
      "          1       0.50      0.73      0.75      0.59      0.67      0.43       296\n",
      "\n",
      "avg / total       0.79      0.75      0.74      0.76      0.67      0.45      1174\n",
      "\n",
      "Accuracy =  0.747018739353\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.82      0.81      0.47      0.82      0.62      0.39       221\n",
      "          1       0.46      0.47      0.81      0.47      0.62      0.36        74\n",
      "\n",
      "avg / total       0.73      0.73      0.56      0.73      0.62      0.39       295\n",
      "\n",
      "Accuracy =  0.728813559322\n",
      "feature name:  ADHFeatures_maxCooc5_k95.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 0}\n",
      "{'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 1, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.87      0.47      0.89      0.57      0.34      1022\n",
      "          1       0.35      0.47      0.87      0.40      0.57      0.31       152\n",
      "\n",
      "avg / total       0.84      0.82      0.53      0.83      0.57      0.34      1174\n",
      "\n",
      "Accuracy =  0.819420783646\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.88      0.82      0.21      0.85      0.36      0.14       257\n",
      "          1       0.15      0.21      0.82      0.17      0.36      0.12        38\n",
      "\n",
      "avg / total       0.78      0.74      0.29      0.76      0.36      0.14       295\n",
      "\n",
      "Accuracy =  0.742372881356\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "{'randomforestclassifier__class_weight': 'balanced_subsample', 'randomforestclassifier__n_estimators': 10, 'randomforestclassifier__max_depth': 10, 'smote__k_neighbors': 1, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.94      0.78      0.94      0.87      0.77       878\n",
      "          1       0.82      0.78      0.94      0.80      0.87      0.76       296\n",
      "\n",
      "avg / total       0.90      0.90      0.82      0.90      0.87      0.77      1174\n",
      "\n",
      "Accuracy =  0.902896081772\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.75      0.76      0.24      0.76      0.44      0.20       221\n",
      "          1       0.25      0.24      0.76      0.25      0.44      0.18        74\n",
      "\n",
      "avg / total       0.63      0.63      0.37      0.63      0.44      0.19       295\n",
      "\n",
      "Accuracy =  0.630508474576\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(len(feature_fnames)):\n",
    "    print('feature name: ', feature_fnames[i])\n",
    "    X_train, y_train, X_test, y_test = read_data(input_dir, feature_fnames[i], gt)\n",
    "    for dict_map in [ADH_map, malig_map]:\n",
    "        print(dict_map)\n",
    "        y_train_new = [dict_map[a] for a in y_train[1]]\n",
    "        y_test_new = [dict_map[b] for b in y_test[1]]\n",
    "        score = 'recall'\n",
    "\n",
    "        tuned_parameters = {'randomforestclassifier__n_estimators':[2, 10, 50, 100], \n",
    "                            'randomforestclassifier__max_features':['auto','log2'],\n",
    "                            'randomforestclassifier__max_depth':[5,10,None],\n",
    "                           'randomforestclassifier__class_weight':['balanced','balanced_subsample'],\n",
    "                           'smote__k_neighbors':param_range}#, 'smote__ratio': np.arange(0.2,1,step=0.2)}\n",
    "\n",
    "        smote = over_sampling.SMOTE(random_state=RANDOM_STATE)\n",
    "        #cart = tree.DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "        cart = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "        pipeline = pl.make_pipeline(smote, cart)\n",
    "\n",
    "        clf = GridSearchCV(pipeline,param_grid=tuned_parameters,\n",
    "                               cv = 6, scoring= '%s_macro' %score, n_jobs = 7)\n",
    "        clf.fit(X_train,y_train_new)\n",
    "        print(clf.best_params_)\n",
    "        print('Training result')\n",
    "        print(classification_report_imbalanced(y_train_new, clf.predict(X_train)))\n",
    "        print('Accuracy = ', metrics.accuracy_score(y_train_new, clf.predict(X_train)))\n",
    "        print(classification_report_imbalanced(y_test_new, clf.predict(X_test)))\n",
    "        print('Accuracy = ', metrics.accuracy_score(y_test_new, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "['ADHTestFeatures_maxCooc10_k95_ObjectFinal.xls', 'ADHTrainFeatures_maxCooc10_k90_NucleiFinal.xls', 'ADHTestFeatures_maxCooc5_k90_ObjectFinal.xls', 'ADHTestFeatures_nuc_feats_mean_std_zscore.xlsx', 'ADHTrainFeatures_nuc_feats_mean_std.xlsx', 'ADHTestFeatures_maxCooc5_k95_CombinedFinal.xls', 'ADHTrainFeatures_maxCooc5_k95_CombinedFinal.xls', 'ADHTrainFeatures_maxCooc5_k90_5NucleiCombinedFinal.xls', 'ADHTrainFeatures_maxCooc5_k95_5NucleiCombinedFinal.xls', 'ADHTrainFeatures_maxCooc5_k90_NucleiFinal.xls', 'ADHTestFeatures_maxCooc5_k95_ObjectFinal.xls', 'ADHTrainFeatures_maxCooc5_k95_NucleiFinal.xls', 'ADHTrainFeatures_maxCooc5_k90_CombinedFinal.xls', 'ADHTestFeatures_maxCooc5_k90_5NucleiFinal.xls', 'ADHTrainFeatures_nuc_feats_mean_std_zscore.xlsx', 'ADHTrainFeatures_maxCooc5_k95_5NucleiFinal.xls', 'ADHTrainFeatures_maxCooc5_k90_ObjectFinal.xls', 'ADHTestFeatures_maxCooc5_k90_5NucleiCombinedFinal.xls', 'ADHTestFeatures_maxCooc10_k90_ObjectFinal.xls', 'ADHTestFeatures_maxCooc5_k90_NucleiFinal.xls', 'ADHTrainFeatures_maxCooc10_k95_NucleiFinal.xls', 'ADHTrainFeatures_maxCooc10_k95_ObjectFinal.xls', 'ADHTestFeatures_nuc_feats_mean_std.xlsx', 'ADHTestFeatures_maxCooc5_k95_5NucleiCombinedFinal.xls', 'ADHTestFeatures_maxCooc10_k90_NucleiFinal.xls', 'ADHTrainFeatures_maxCooc10_k95_CombinedFinal.xls', 'ADHTestFeatures_maxCooc5_k95_NucleiFinal.xls', 'ADHTestFeatures_maxCooc5_k95_5NucleiFinal.xls', 'ADHTestFeatures_maxCooc10_k90_CombinedFinal.xls', 'ADHTrainFeatures_maxCooc5_k95_ObjectFinal.xls', 'ADHTestFeatures_maxCooc5_k90_CombinedFinal.xls', 'ADHTrainFeatures_maxCooc10_k90_CombinedFinal.xls', 'ADHTrainFeatures_maxCooc10_k90_ObjectFinal.xls', 'ADHTestFeatures_maxCooc10_k95_CombinedFinal.xls', 'ADHTrainFeatures_maxCooc5_k90_5NucleiFinal.xls', 'ADHTestFeatures_maxCooc10_k95_NucleiFinal.xls']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import datasets, metrics, tree\n",
    "\n",
    "from imblearn import over_sampling\n",
    "from imblearn import pipeline as pl\n",
    "import sklearn\n",
    "print(__doc__)\n",
    "\n",
    "LW = 2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.cohen_kappa_score)\n",
    "input_dir = '/home/lun5/ADH/ADH_features_5phenotypes/'\n",
    "input_dir = '/home/lun5/ADH/ADH_feature_sets/'\n",
    "\n",
    "feature_fnames = os.listdir(input_dir)\n",
    "print(feature_fnames)\n",
    "ADH_map = {'Normal Duct':0, 'Columnar':0, 'Flat epithelial':0,'Flat Epithelial':0, 'ADH':1}\n",
    "malig_map = {'Normal Duct':0, 'Columnar':0, 'Flat epithelial':1,'Flat Epithelial':1, 'ADH':1}\n",
    "fourway_map = {'Normal Duct':0, 'Columnar':1, 'Flat epithelial':2,'Flat Epithelial':2, 'ADH':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['maxCooc10_k90_NucleiFinal.xls', 'maxCooc5_k90_CombinedFinal.xls', 'maxCooc10_k90_CombinedFinal.xls', 'maxCooc5_k90_5NucleiFinal.xls', 'maxCooc5_k95_ObjectFinal.xls', 'maxCooc5_k95_5NucleiFinal.xls', 'maxCooc5_k90_NucleiFinal.xls', 'maxCooc5_k95_NucleiFinal.xls', 'maxCooc10_k95_CombinedFinal.xls', 'nuc_feats_mean_std_zscore.xlsx', 'maxCooc10_k95_NucleiFinal.xls', 'maxCooc10_k90_ObjectFinal.xls', 'maxCooc5_k90_5NucleiCombinedFinal.xls', 'maxCooc5_k90_ObjectFinal.xls', 'maxCooc5_k95_CombinedFinal.xls', 'maxCooc5_k95_5NucleiCombinedFinal.xls', 'nuc_feats_mean_std.xlsx', 'maxCooc10_k95_ObjectFinal.xls'])\n"
     ]
    }
   ],
   "source": [
    "settings = set(['_'.join(a.split('_')[1:]) for a in feature_fnames])\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = ['maxCooc10_k90_NucleiFinal.xls', 'maxCooc5_k90_CombinedFinal.xls', \n",
    "            'maxCooc10_k90_CombinedFinal.xls', 'maxCooc5_k90_5NucleiFinal.xls', \n",
    "            'maxCooc5_k95_ObjectFinal.xls', 'maxCooc5_k95_5NucleiFinal.xls', 'maxCooc5_k90_NucleiFinal.xls',\n",
    "            'maxCooc5_k95_NucleiFinal.xls', 'maxCooc10_k95_CombinedFinal.xls']\n",
    "accepted_labels = ['ADH','Flat epithelial', 'Columnar', 'Normal Duct']\n",
    "#settings = ['maxCooc5_k95_5NucleiCombinedFinal.xls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = ['maxCooc10_k95_CombinedFinal.xls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.828947368421\n",
      "roc_auc =  0.533682373473\n",
      "Threshold =  0.0\n",
      "Accuracy =  0.626644736842\n",
      "roc_auc =  0.506831214161\n",
      "[[368 205]\n",
      " [ 22  13]]\n",
      "Threshold =  0.1\n",
      "Accuracy =  0.626644736842\n",
      "roc_auc =  0.506831214161\n",
      "[[368 205]\n",
      " [ 22  13]]\n",
      "Threshold =  0.2\n",
      "Accuracy =  0.626644736842\n",
      "roc_auc =  0.506831214161\n",
      "[[368 205]\n",
      " [ 22  13]]\n",
      "Threshold =  0.3\n",
      "Accuracy =  0.626644736842\n",
      "roc_auc =  0.506831214161\n",
      "[[368 205]\n",
      " [ 22  13]]\n",
      "Threshold =  0.4\n",
      "Accuracy =  0.626644736842\n",
      "roc_auc =  0.506831214161\n",
      "[[368 205]\n",
      " [ 22  13]]\n",
      "Threshold =  0.5\n",
      "Accuracy =  0.828947368421\n",
      "roc_auc =  0.533682373473\n",
      "[[497  76]\n",
      " [ 28   7]]\n",
      "Threshold =  0.6\n",
      "Accuracy =  0.828947368421\n",
      "roc_auc =  0.533682373473\n",
      "[[497  76]\n",
      " [ 28   7]]\n",
      "Threshold =  0.7\n",
      "Accuracy =  0.828947368421\n",
      "roc_auc =  0.533682373473\n",
      "[[497  76]\n",
      " [ 28   7]]\n",
      "Threshold =  0.8\n",
      "Accuracy =  0.828947368421\n",
      "roc_auc =  0.533682373473\n",
      "[[497  76]\n",
      " [ 28   7]]\n",
      "Threshold =  0.9\n",
      "Accuracy =  0.828947368421\n",
      "roc_auc =  0.533682373473\n",
      "[[497  76]\n",
      " [ 28   7]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "y_pred_probs = clf.predict_proba(X_test)\n",
    "print('Accuracy = ', metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "print('roc_auc = ', metrics.roc_auc_score(y_test, clf.predict(X_test)))\n",
    "thres = np.arange(0,1, 0.1)\n",
    "for t in thres:\n",
    "    y_pred = y_pred_probs[:,1] > t\n",
    "    print('Threshold = ', t)\n",
    "    print('Accuracy = ', metrics.accuracy_score(y_test, y_pred))\n",
    "    print('roc_auc = ', metrics.roc_auc_score(y_test, y_pred))\n",
    "    print(sklearn.metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'imagename', u'label', u'feat.0', u'feat.1', u'feat.2',\n",
       "       u'feat.3', u'feat.4', u'feat.5', u'feat.6',\n",
       "       ...\n",
       "       u'feat.386', u'feat.387', u'feat.388', u'feat.389', u'feat.390',\n",
       "       u'feat.391', u'feat.392', u'feat.393', u'feat.394', u'feat.395'],\n",
       "      dtype='object', length=399)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "maxCooc10_k95_CombinedFinal.xls (839, 24) (608, 24)\n",
      "\n",
      "\n",
      "{'Normal Duct': 0, 'Flat Epithelial': 1, 'Columnar': 0, 'ADH': 1, 'Flat epithelial': 1}\n",
      "\n",
      "Optimized for roc_auc\n",
      "{'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'smote__k_neighbors': 8, 'svc__C': 100000.0}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.84      0.69      0.68      0.76      0.64      0.42       588\n",
      "          1       0.49      0.68      0.69      0.57      0.64      0.39       251\n",
      "\n",
      "avg / total       0.73      0.69      0.69      0.70      0.64      0.41       839\n",
      "\n",
      "Accuracy =  0.69010727056\n",
      "roc_auc =  0.687576225709\n",
      "Confusion matrix\n",
      "[[408 180]\n",
      " [ 80 171]]\n",
      "Testing result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.72      0.65      0.81      0.47      0.23       537\n",
      "          1       0.23      0.65      0.72      0.34      0.47      0.20        71\n",
      "\n",
      "avg / total       0.86      0.71      0.66      0.76      0.47      0.23       608\n",
      "\n",
      "Accuracy =  0.708881578947\n",
      "roc_auc =  0.68241666011\n",
      "Confusion matrix\n",
      "[[385 152]\n",
      " [ 25  46]]\n"
     ]
    }
   ],
   "source": [
    "param_range = range(1, 15)\n",
    "for ss in settings:\n",
    "    train_df = pd.read_excel(os.path.join(input_dir,'ADHTrainFeatures_' + ss))\n",
    "    #train_df = pd.read_csv(os.path.join(input_dir,'ADHTrainFeatures_' + ss))\n",
    "    X_train = train_df[train_df.columns[2:]].as_matrix()\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    \n",
    "    test_df = pd.read_excel(os.path.join(input_dir,'ADHTestFeatures_' + ss))\n",
    "    #test_df = pd.read_csv(os.path.join(input_dir,'ADHTestFeatures_' + ss))\n",
    "    X_test = test_df[test_df.columns[2:]].as_matrix()\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    print('\\n')\n",
    "    print(ss, X_train.shape, X_test.shape)\n",
    "    for dict_map in [malig_map]: #[fourway_map]: \n",
    "        print('\\n')\n",
    "        print(dict_map)\n",
    "        y_train = [dict_map[a] for a in list(train_df['label'])]\n",
    "        y_test = [dict_map[a] for a in list(test_df['label'])]        \n",
    "        #scores = ['precision', 'recall','f1']\n",
    "        #scores = ['accuracy', 'f1_weighted', 'roc_auc']\n",
    "        scores = ['roc_auc']\n",
    "        #scores = ['f1_micro', 'f1_macro','f1_weighted','accuracy']#,'cohen_kappa']\n",
    "        #scorers = [metrics.make_scorer(metrics.f1_score), metrics.scorer(metrics.recall_score),\n",
    "        #           metrics.make_scorer(metrics.roc_auc_score), metrics.make_scorer(metrics.cohen_kappa_score)]\n",
    "        #for score,scorer in zip(scores, scorers):\n",
    "        for score in scores:\n",
    "            print('\\nOptimized for %s' %score)\n",
    "            #tuned_parameters = {'randomforestclassifier__n_estimators':[25, 50, 100], \n",
    "            #                    'randomforestclassifier__max_features':['auto','log2'],\n",
    "            #                    'randomforestclassifier__max_depth':[5,10,None],\n",
    "            #                   'smote__k_neighbors':param_range}#, 'smote__ratio': np.arange(0.2,1,step=0.2)}\n",
    "            \n",
    "            #smote = over_sampling.SMOTE(random_state=RANDOM_STATE, kind = 'borderline1')\n",
    "            #cart = tree.DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "            #cart = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "            #pipeline = pl.make_pipeline(smote, cart)\n",
    "\n",
    "            tuned_parameters = {'svc__C': [1e3, 1e4, 1e5], \n",
    "                                'svc__gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "                                'svc__kernel':['rbf'],\n",
    "                               'smote__k_neighbors':param_range}#, 'smote__ratio': np.arange(0.2,1,step=0.2)}\n",
    "            smote = over_sampling.SMOTE(random_state=RANDOM_STATE, kind = 'borderline1')\n",
    "            cart = sklearn.svm.SVC()\n",
    "            pipeline = pl.make_pipeline(smote, cart)\n",
    "            clf = GridSearchCV(pipeline,param_grid=tuned_parameters,\n",
    "                                   cv = 3, scoring= '%s' %score, n_jobs = 7)\n",
    "            \n",
    "            #tuned_parameters = {'C':[1e3,1e4,1e5],\n",
    "            #                    'gamma':[1e-5,1e-4,1e-2],\n",
    "            #                   'kernel':['rbf']}\n",
    "            #cart = sklearn.svm.SVC(class_weight='balanced')\n",
    "            #clf = GridSearchCV(cart, param_grid = tuned_parameters,\n",
    "            #                  cv=3, scoring='%s' %score, n_jobs = 7)\n",
    "            #clf = cart\n",
    "            #tuned_parameters = {'n_estimators':[2, 10, 25, 50], \n",
    "            #                    'max_features':['auto','log2'],\n",
    "            #                    'max_depth':[5,10,None]}\n",
    "\n",
    "            #clf = GridSearchCV(RandomForestClassifier(n_estimators=10),tuned_parameters,\n",
    "            #               cv = 6, scoring= '%s' %score, n_jobs = 5)\n",
    "            clf.fit(X_train,y_train)\n",
    "            print(clf.best_params_)\n",
    "            print('Training result')\n",
    "            print(classification_report_imbalanced(y_train, clf.predict(X_train)))\n",
    "            print('Accuracy = ', metrics.accuracy_score(y_train, clf.predict(X_train)))\n",
    "            print('roc_auc = ', metrics.roc_auc_score(y_train, clf.predict(X_train)))\n",
    "            #print('F1micro = ', metrics.f1_score(y_train, clf.predict(X_train), average='micro'))\n",
    "            #print('F1macro = ', metrics.f1_score(y_train, clf.predict(X_train), average='macro'))\n",
    "            #print('F1weighted = ', metrics.f1_score(y_train, clf.predict(X_train), average='weighted'))\n",
    "            print('Confusion matrix')\n",
    "            print(metrics.confusion_matrix(y_train, clf.predict(X_train)))\n",
    "            print('Testing result')\n",
    "            print(classification_report_imbalanced(y_test, clf.predict(X_test)))\n",
    "            print('Accuracy = ', metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "            print('roc_auc = ', metrics.roc_auc_score(y_test, clf.predict(X_test)))\n",
    "            #print('F1micro = ', metrics.f1_score(y_test, clf.predict(X_test), average='micro'))\n",
    "            #print('F1macro = ', metrics.f1_score(y_test, clf.predict(X_test), average='macro'))\n",
    "            #print('F1weighted = ', metrics.f1_score(y_test, clf.predict(X_test), average='weighted'))\n",
    "            print('Confusion matrix')\n",
    "            print(metrics.confusion_matrix(y_test, clf.predict(X_test)))\n",
    "            #y_pred_probs = clf.predict_proba(X_test)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.loc[:,'y_test'] = y_test\n",
    "test_df.loc[:,'y_test_pred'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = np.asarray(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[385, 152],\n",
       "       [ 25,  46]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.asarray([int(y_pred[i] == 0 and y_test[i] == 0) for i in xrange(len(y_test))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adh04-1b_seg1.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adh04-1b_seg13.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adh04-1b_seg2.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adh04-1b_seg21.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adh04-1b_seg22.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adh04-1b_seg23.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adh04-1c_seg1.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adh05-1a_seg4.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adh06-1b_seg114.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>adh07-1a_seg243.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adh07-1c_seg3.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>adh10-1c_seg7.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>adh12-1b_seg89.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>adh13-3b_seg15.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>adh13-3b_seg20.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adh13-3b_seg22.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>adh16-1a_seg4.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>adh17-1a_seg18.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>adh19-1a_seg27.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>adh19-1a_seg37.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>adh19-1b_seg4.jpg</td>\n",
       "      <td>ADH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>adh04-1a_seg15.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>adh04-1b_seg3.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>adh07-1a_seg73.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>adh07-1a_seg89.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>adh07-1b_seg155.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>adh07-2a_seg41.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>adh08-1b_seg19.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>adh08-1c_seg45.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>adh13-1a_seg10.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>adh13-1a_seg33.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>adh15-1a_seg13.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>adh17-1a_seg14.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>adh17-1a_seg52.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>adh17-1a_seg54.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>adh17-1b_seg14.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>adh17-1b_seg20.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>adh17-1b_seg23.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>adh17-1b_seg3.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>adh17-1b_seg9.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>adh18-1a_seg183.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>adh18-1a_seg3.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>adh19-1a_seg15.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>adh22-2b_seg31.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>adh23-1a_seg13.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>adh23-1a_seg7.jpg</td>\n",
       "      <td>Flat epithelial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               imagename            label\n",
       "0      adh04-1b_seg1.jpg              ADH\n",
       "1     adh04-1b_seg13.jpg              ADH\n",
       "2      adh04-1b_seg2.jpg              ADH\n",
       "3     adh04-1b_seg21.jpg              ADH\n",
       "4     adh04-1b_seg22.jpg              ADH\n",
       "5     adh04-1b_seg23.jpg              ADH\n",
       "6      adh04-1c_seg1.jpg              ADH\n",
       "8      adh05-1a_seg4.jpg              ADH\n",
       "9    adh06-1b_seg114.jpg              ADH\n",
       "12   adh07-1a_seg243.jpg              ADH\n",
       "14     adh07-1c_seg3.jpg              ADH\n",
       "18     adh10-1c_seg7.jpg              ADH\n",
       "21    adh12-1b_seg89.jpg              ADH\n",
       "22    adh13-3b_seg15.jpg              ADH\n",
       "23    adh13-3b_seg20.jpg              ADH\n",
       "25    adh13-3b_seg22.jpg              ADH\n",
       "29     adh16-1a_seg4.jpg              ADH\n",
       "30    adh17-1a_seg18.jpg              ADH\n",
       "32    adh19-1a_seg27.jpg              ADH\n",
       "33    adh19-1a_seg37.jpg              ADH\n",
       "34     adh19-1b_seg4.jpg              ADH\n",
       "143   adh04-1a_seg15.jpg  Flat epithelial\n",
       "144    adh04-1b_seg3.jpg  Flat epithelial\n",
       "148   adh07-1a_seg73.jpg  Flat epithelial\n",
       "149   adh07-1a_seg89.jpg  Flat epithelial\n",
       "150  adh07-1b_seg155.jpg  Flat epithelial\n",
       "152   adh07-2a_seg41.jpg  Flat epithelial\n",
       "154   adh08-1b_seg19.jpg  Flat epithelial\n",
       "155   adh08-1c_seg45.jpg  Flat epithelial\n",
       "159   adh13-1a_seg10.jpg  Flat epithelial\n",
       "160   adh13-1a_seg33.jpg  Flat epithelial\n",
       "161   adh15-1a_seg13.jpg  Flat epithelial\n",
       "162   adh17-1a_seg14.jpg  Flat epithelial\n",
       "163   adh17-1a_seg52.jpg  Flat epithelial\n",
       "164   adh17-1a_seg54.jpg  Flat epithelial\n",
       "165   adh17-1b_seg14.jpg  Flat epithelial\n",
       "166   adh17-1b_seg20.jpg  Flat epithelial\n",
       "167   adh17-1b_seg23.jpg  Flat epithelial\n",
       "168    adh17-1b_seg3.jpg  Flat epithelial\n",
       "169    adh17-1b_seg9.jpg  Flat epithelial\n",
       "170  adh18-1a_seg183.jpg  Flat epithelial\n",
       "171    adh18-1a_seg3.jpg  Flat epithelial\n",
       "173   adh19-1a_seg15.jpg  Flat epithelial\n",
       "175   adh22-2b_seg31.jpg  Flat epithelial\n",
       "177   adh23-1a_seg13.jpg  Flat epithelial\n",
       "178    adh23-1a_seg7.jpg  Flat epithelial"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[[y_pred[i] == 1 and y_test[i] == 1 for i in xrange(len(y_test))],['imagename','label']] # TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.loc[[(y_pred[i] == 0 and y_test[i] == 0) for i in xrange(len(y_test))],'imagename']) # TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>adh04-1a_seg22.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>adh04-1b_seg11.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>adh04-1b_seg15.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>adh04-1b_seg17.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>adh04-1b_seg6.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>adh05-1a_seg13.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>adh05-1a_seg3.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>adh05-1a_seg39.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>adh08-1a_seg54.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>adh08-1a_seg59.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>adh08-1a_seg66.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>adh08-1b_seg16.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>adh09-1a_seg64.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>adh09-1a_seg68.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>adh09-1a_seg7.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>adh10-1b_seg7.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>adh10-1c_seg14.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>adh10-1c_seg40.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>adh11-1a_seg107.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>adh11-1a_seg22.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>adh11-1a_seg54.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>adh11-1a_seg66.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>adh11-1a_seg79.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>adh12-1b_seg100.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>adh12-1b_seg11.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>adh12-1b_seg74.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>adh13-1a_seg71.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>adh13-3b_seg23.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>adh13-3b_seg5.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>adh15-1a_seg15.jpg</td>\n",
       "      <td>Columnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>adh23-3a_seg34.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>adh23-3a_seg37.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>adh23-3a_seg38.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>adh23-3a_seg41.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>adh23-3a_seg45.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>adh23-3a_seg47.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>adh23-3a_seg57.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>adh23-3a_seg6.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>adh23-3a_seg62.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>adh23-3a_seg7.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>adh24-1a_seg1.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>adh24-1a_seg11.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>adh24-1a_seg19.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>adh24-1a_seg20.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>adh24-1a_seg22.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>adh24-1a_seg23.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>adh24-1a_seg3.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>adh24-1a_seg39.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>adh24-1a_seg4.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>adh24-1a_seg40.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>adh24-1a_seg42.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>adh24-1a_seg7.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>adh24-1a_seg8.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>adh24-1b_seg21.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>adh24-1b_seg23.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>adh24-1b_seg30.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>adh24-1b_seg36.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>adh24-1b_seg39.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>adh24-1b_seg43.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>adh24-1b_seg47.jpg</td>\n",
       "      <td>Normal Duct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               imagename        label\n",
       "39    adh04-1a_seg22.jpg     Columnar\n",
       "40    adh04-1b_seg11.jpg     Columnar\n",
       "41    adh04-1b_seg15.jpg     Columnar\n",
       "42    adh04-1b_seg17.jpg     Columnar\n",
       "44     adh04-1b_seg6.jpg     Columnar\n",
       "47    adh05-1a_seg13.jpg     Columnar\n",
       "48     adh05-1a_seg3.jpg     Columnar\n",
       "49    adh05-1a_seg39.jpg     Columnar\n",
       "50    adh08-1a_seg54.jpg     Columnar\n",
       "51    adh08-1a_seg59.jpg     Columnar\n",
       "52    adh08-1a_seg66.jpg     Columnar\n",
       "53    adh08-1b_seg16.jpg     Columnar\n",
       "55    adh09-1a_seg64.jpg     Columnar\n",
       "56    adh09-1a_seg68.jpg     Columnar\n",
       "57     adh09-1a_seg7.jpg     Columnar\n",
       "59     adh10-1b_seg7.jpg     Columnar\n",
       "60    adh10-1c_seg14.jpg     Columnar\n",
       "61    adh10-1c_seg40.jpg     Columnar\n",
       "64   adh11-1a_seg107.jpg     Columnar\n",
       "65    adh11-1a_seg22.jpg     Columnar\n",
       "66    adh11-1a_seg54.jpg     Columnar\n",
       "67    adh11-1a_seg66.jpg     Columnar\n",
       "68    adh11-1a_seg79.jpg     Columnar\n",
       "69   adh12-1b_seg100.jpg     Columnar\n",
       "70    adh12-1b_seg11.jpg     Columnar\n",
       "71    adh12-1b_seg74.jpg     Columnar\n",
       "74    adh13-1a_seg71.jpg     Columnar\n",
       "76    adh13-3b_seg23.jpg     Columnar\n",
       "77     adh13-3b_seg5.jpg     Columnar\n",
       "79    adh15-1a_seg15.jpg     Columnar\n",
       "..                   ...          ...\n",
       "575   adh23-3a_seg34.jpg  Normal Duct\n",
       "576   adh23-3a_seg37.jpg  Normal Duct\n",
       "577   adh23-3a_seg38.jpg  Normal Duct\n",
       "578   adh23-3a_seg41.jpg  Normal Duct\n",
       "579   adh23-3a_seg45.jpg  Normal Duct\n",
       "580   adh23-3a_seg47.jpg  Normal Duct\n",
       "581   adh23-3a_seg57.jpg  Normal Duct\n",
       "582    adh23-3a_seg6.jpg  Normal Duct\n",
       "583   adh23-3a_seg62.jpg  Normal Duct\n",
       "584    adh23-3a_seg7.jpg  Normal Duct\n",
       "585    adh24-1a_seg1.jpg  Normal Duct\n",
       "586   adh24-1a_seg11.jpg  Normal Duct\n",
       "588   adh24-1a_seg19.jpg  Normal Duct\n",
       "589   adh24-1a_seg20.jpg  Normal Duct\n",
       "590   adh24-1a_seg22.jpg  Normal Duct\n",
       "591   adh24-1a_seg23.jpg  Normal Duct\n",
       "592    adh24-1a_seg3.jpg  Normal Duct\n",
       "594   adh24-1a_seg39.jpg  Normal Duct\n",
       "595    adh24-1a_seg4.jpg  Normal Duct\n",
       "596   adh24-1a_seg40.jpg  Normal Duct\n",
       "597   adh24-1a_seg42.jpg  Normal Duct\n",
       "598    adh24-1a_seg7.jpg  Normal Duct\n",
       "599    adh24-1a_seg8.jpg  Normal Duct\n",
       "600   adh24-1b_seg21.jpg  Normal Duct\n",
       "601   adh24-1b_seg23.jpg  Normal Duct\n",
       "602   adh24-1b_seg30.jpg  Normal Duct\n",
       "603   adh24-1b_seg36.jpg  Normal Duct\n",
       "604   adh24-1b_seg39.jpg  Normal Duct\n",
       "605   adh24-1b_seg43.jpg  Normal Duct\n",
       "606   adh24-1b_seg47.jpg  Normal Duct\n",
       "\n",
       "[385 rows x 2 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[[y_pred[i] == 0 and y_test[i] == 0 for i in xrange(len(y_test))],['imagename','label']]  # FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_test_pred\n",
       "0         1            1\n",
       "1         1            1\n",
       "2         1            1\n",
       "3         1            1\n",
       "4         1            1\n",
       "5         1            1\n",
       "6         1            1\n",
       "7         1            0\n",
       "8         1            1\n",
       "9         1            1\n",
       "10        1            0\n",
       "11        1            0\n",
       "12        1            1\n",
       "13        1            0\n",
       "14        1            1\n",
       "15        1            0\n",
       "16        1            0\n",
       "17        1            0\n",
       "18        1            1\n",
       "19        1            0\n",
       "20        1            0\n",
       "21        1            1\n",
       "22        1            1\n",
       "23        1            1\n",
       "24        1            0\n",
       "25        1            1\n",
       "26        1            0\n",
       "27        1            0\n",
       "28        1            0\n",
       "29        1            1\n",
       "..      ...          ...\n",
       "578       0            0\n",
       "579       0            0\n",
       "580       0            0\n",
       "581       0            0\n",
       "582       0            0\n",
       "583       0            0\n",
       "584       0            0\n",
       "585       0            0\n",
       "586       0            0\n",
       "587       0            1\n",
       "588       0            0\n",
       "589       0            0\n",
       "590       0            0\n",
       "591       0            0\n",
       "592       0            0\n",
       "593       0            1\n",
       "594       0            0\n",
       "595       0            0\n",
       "596       0            0\n",
       "597       0            0\n",
       "598       0            0\n",
       "599       0            0\n",
       "600       0            0\n",
       "601       0            0\n",
       "602       0            0\n",
       "603       0            0\n",
       "604       0            0\n",
       "605       0            0\n",
       "606       0            0\n",
       "607       0            1\n",
       "\n",
       "[608 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[:,('y_test','y_test_pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  u'imagename',       u'label',    u'features',  u'Unnamed: 3',\n",
       "        u'Unnamed: 4',  u'Unnamed: 5',  u'Unnamed: 6',  u'Unnamed: 7',\n",
       "        u'Unnamed: 8',  u'Unnamed: 9', u'Unnamed: 10', u'Unnamed: 11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "nuc_feats_mean_std_zscore.csv (833, 392) (605, 392)\n",
      "\n",
      "\n",
      "{'Normal Duct': 0, 'Flat Epithelial': 1, 'Columnar': 0, 'ADH': 1, 'Flat epithelial': 1}\n",
      "\n",
      "Optimized for roc_auc\n",
      "{'randomforestclassifier__n_estimators': 25, 'randomforestclassifier__max_depth': 10, 'smote__k_neighbors': 13, 'randomforestclassifier__max_features': 'log2'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.97      1.00      0.99      0.97      0.94       585\n",
      "          1       0.94      1.00      0.97      0.97      0.97      0.93       248\n",
      "\n",
      "avg / total       0.98      0.98      0.99      0.98      0.97      0.94       833\n",
      "\n",
      "Accuracy =  0.979591836735\n",
      "roc_auc =  0.98547008547\n",
      "Confusion matrix\n",
      "[[568  17]\n",
      " [  0 248]]\n",
      "Testing result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.80      0.59      0.86      0.51      0.28       534\n",
      "          1       0.28      0.59      0.80      0.38      0.51      0.24        71\n",
      "\n",
      "avg / total       0.86      0.77      0.62      0.80      0.51      0.27       605\n",
      "\n",
      "Accuracy =  0.771900826446\n",
      "roc_auc =  0.693714722794\n",
      "Confusion matrix\n",
      "[[425 109]\n",
      " [ 29  42]]\n",
      "\n",
      "\n",
      "nuc_feats_mean_std.csv (833, 392) (605, 392)\n",
      "\n",
      "\n",
      "{'Normal Duct': 0, 'Flat Epithelial': 1, 'Columnar': 0, 'ADH': 1, 'Flat epithelial': 1}\n",
      "\n",
      "Optimized for roc_auc\n",
      "{'randomforestclassifier__n_estimators': 25, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 3, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.96      0.85      0.92      0.90      0.83      0.71       585\n",
      "          1       0.72      0.92      0.85      0.81      0.83      0.67       248\n",
      "\n",
      "avg / total       0.89      0.87      0.90      0.87      0.83      0.70       833\n",
      "\n",
      "Accuracy =  0.869147659064\n",
      "roc_auc =  0.883609043286\n",
      "Confusion matrix\n",
      "[[496  89]\n",
      " [ 20 228]]\n",
      "Testing result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.78      0.65      0.85      0.51      0.28       534\n",
      "          1       0.28      0.65      0.78      0.39      0.51      0.25        71\n",
      "\n",
      "avg / total       0.87      0.76      0.66      0.80      0.51      0.28       605\n",
      "\n",
      "Accuracy =  0.763636363636\n",
      "roc_auc =  0.713456770586\n",
      "Confusion matrix\n",
      "[[416 118]\n",
      " [ 25  46]]\n"
     ]
    }
   ],
   "source": [
    "param_range = range(1, 15)\n",
    "for ss in settings:\n",
    "    #train_df = pd.read_excel(os.path.join(input_dir,'ADHTrainFeatures_' + ss))\n",
    "    train_df = pd.read_csv(os.path.join(input_dir,'ADHTrainFeatures_' + ss))\n",
    "    \n",
    "    X_train = train_df[train_df.columns[3:]].as_matrix()\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    \n",
    "    #test_df = pd.read_excel(os.path.join(input_dir,'ADHTestFeatures_' + ss))\n",
    "    test_df = pd.read_csv(os.path.join(input_dir,'ADHTestFeatures_' + ss))\n",
    "    X_test = test_df[test_df.columns[3:]].as_matrix()\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    print('\\n')\n",
    "    print(ss, X_train.shape, X_test.shape)\n",
    "    for dict_map in [malig_map]: #[fourway_map]: \n",
    "        print('\\n')\n",
    "        print(dict_map)\n",
    "        y_train = [dict_map[a] for a in list(train_df['label'])]\n",
    "        y_test = [dict_map[a] for a in list(test_df['label'])]        \n",
    "        #scores = ['precision', 'recall','f1']\n",
    "        #scores = ['accuracy', 'f1_weighted', 'roc_auc']\n",
    "        scores = ['roc_auc']\n",
    "        #scores = ['f1_micro', 'f1_macro','f1_weighted','accuracy']#,'cohen_kappa']\n",
    "        #scorers = [metrics.make_scorer(metrics.f1_score), metrics.scorer(metrics.recall_score),\n",
    "        #           metrics.make_scorer(metrics.roc_auc_score), metrics.make_scorer(metrics.cohen_kappa_score)]\n",
    "        #for score,scorer in zip(scores, scorers):\n",
    "        for score in scores:\n",
    "            print('\\nOptimized for %s' %score)\n",
    "            tuned_parameters = {'randomforestclassifier__n_estimators':[5, 10, 25], \n",
    "                                'randomforestclassifier__max_features':['auto','log2'],\n",
    "                                'randomforestclassifier__max_depth':[5,10,None],\n",
    "                               'smote__k_neighbors':param_range}#, 'smote__ratio': np.arange(0.2,1,step=0.2)}\n",
    "            \n",
    "            smote = over_sampling.SMOTE(random_state=RANDOM_STATE, kind = 'borderline1')\n",
    "            #cart = tree.DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "            cart = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "            pipeline = pl.make_pipeline(smote, cart)\n",
    "            clf = GridSearchCV(pipeline,param_grid=tuned_parameters,\n",
    "                                   cv = 3, scoring= '%s' %score, n_jobs = 7)\n",
    "            clf.fit(X_train,y_train)\n",
    "            print(clf.best_params_)\n",
    "            print('Training result')\n",
    "            print(classification_report_imbalanced(y_train, clf.predict(X_train)))\n",
    "            print('Accuracy = ', metrics.accuracy_score(y_train, clf.predict(X_train)))\n",
    "            print('roc_auc = ', metrics.roc_auc_score(y_train, clf.predict(X_train)))\n",
    "            #print('F1micro = ', metrics.f1_score(y_train, clf.predict(X_train), average='micro'))\n",
    "            #print('F1macro = ', metrics.f1_score(y_train, clf.predict(X_train), average='macro'))\n",
    "            #print('F1weighted = ', metrics.f1_score(y_train, clf.predict(X_train), average='weighted'))\n",
    "            print('Confusion matrix')\n",
    "            print(metrics.confusion_matrix(y_train, clf.predict(X_train)))\n",
    "            print('Testing result')\n",
    "            print(classification_report_imbalanced(y_test, clf.predict(X_test)))\n",
    "            print('Accuracy = ', metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "            print('roc_auc = ', metrics.roc_auc_score(y_test, clf.predict(X_test)))\n",
    "            #print('F1micro = ', metrics.f1_score(y_test, clf.predict(X_test), average='micro'))\n",
    "            #print('F1macro = ', metrics.f1_score(y_test, clf.predict(X_test), average='macro'))\n",
    "            #print('F1weighted = ', metrics.f1_score(y_test, clf.predict(X_test), average='weighted'))\n",
    "            print('Confusion matrix')\n",
    "            print(metrics.confusion_matrix(y_test, clf.predict(X_test)))\n",
    "            #y_pred_probs = clf.predict_proba(X_test)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature name:  ADHFeatures_maxCooc10_k90_Combined.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "[5, 10, 109, 294]\n",
      "418 (418, 10) 171 (171, 10)\n",
      "{'randomforestclassifier__n_estimators': 50, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 1, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.97      1.00      0.20      0.99      0.99      0.97       403\n",
      "          1       1.00      0.20      1.00      0.33      0.99      0.97        15\n",
      "\n",
      "avg / total       0.97      0.97      0.23      0.96      0.99      0.97       418\n",
      "\n",
      "Accuracy =  0.971291866029\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.58      1.00      0.00      0.74      0.00      0.00       100\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00        71\n",
      "\n",
      "avg / total       0.34      0.58      0.42      0.43      0.00      0.00       171\n",
      "\n",
      "Accuracy =  0.584795321637\n",
      "feature name:  ADHFeatures_maxCooc10_k95_Combined.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "[5, 10, 109, 294]\n",
      "418 (418, 24) 171 (171, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/imblearn/metrics/classification.py:238: UndefinedMetricWarning: Specificity is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  warn_for)\n",
      "/home/lun5/miniconda2/envs/sql/lib/python2.7/site-packages/imblearn/metrics/classification.py:240: UndefinedMetricWarning: Sensitivity is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__n_estimators': 50, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 9, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.98      0.94      0.60      0.96      0.50      0.27       403\n",
      "          1       0.26      0.60      0.94      0.36      0.50      0.23        15\n",
      "\n",
      "avg / total       0.96      0.92      0.61      0.94      0.50      0.27       418\n",
      "\n",
      "Accuracy =  0.923444976077\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.58      0.93      0.04      0.71      0.42      0.18       100\n",
      "          1       0.30      0.04      0.93      0.07      0.42      0.17        71\n",
      "\n",
      "avg / total       0.46      0.56      0.41      0.45      0.42      0.17       171\n",
      "\n",
      "Accuracy =  0.561403508772\n",
      "feature name:  ADHFeatures_maxCooc5_k90_OnlyNuclei.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "[5, 10, 109, 294]\n",
      "418 (418, 8) 171 (171, 8)\n",
      "{'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 6, 'randomforestclassifier__max_features': 'log2'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.83      0.80      0.91      0.39      0.16       403\n",
      "          1       0.15      0.80      0.83      0.26      0.39      0.14        15\n",
      "\n",
      "avg / total       0.96      0.83      0.80      0.88      0.39      0.16       418\n",
      "\n",
      "Accuracy =  0.832535885167\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.58      0.73      0.25      0.65      0.48      0.24       100\n",
      "          1       0.40      0.25      0.73      0.31      0.48      0.23        71\n",
      "\n",
      "avg / total       0.50      0.53      0.45      0.51      0.48      0.23       171\n",
      "\n",
      "Accuracy =  0.53216374269\n",
      "feature name:  ADHFeatures_maxCooc5_k95_OnlyNuclei.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "[5, 10, 109, 294]\n",
      "418 (418, 13) 171 (171, 13)\n",
      "{'randomforestclassifier__n_estimators': 10, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 9, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.98      0.91      0.40      0.94      0.37      0.15       403\n",
      "          1       0.14      0.40      0.91      0.21      0.37      0.13        15\n",
      "\n",
      "avg / total       0.95      0.89      0.42      0.92      0.37      0.15       418\n",
      "\n",
      "Accuracy =  0.892344497608\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.65      0.92      0.31      0.76      0.69      0.47       100\n",
      "          1       0.73      0.31      0.92      0.44      0.69      0.48        71\n",
      "\n",
      "avg / total       0.69      0.67      0.56      0.63      0.69      0.48       171\n",
      "\n",
      "Accuracy =  0.666666666667\n",
      "feature name:  ADHFeatures_maxCooc10_k90_OnlyNuclei.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "[5, 10, 109, 294]\n",
      "418 (418, 13) 171 (171, 13)\n",
      "{'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__max_depth': 10, 'smote__k_neighbors': 7, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.95      0.87      0.97      0.64      0.43       403\n",
      "          1       0.41      0.87      0.95      0.55      0.64      0.38        15\n",
      "\n",
      "avg / total       0.97      0.95      0.87      0.96      0.64      0.43       418\n",
      "\n",
      "Accuracy =  0.94976076555\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.56      0.85      0.06      0.67      0.34      0.12       100\n",
      "          1       0.21      0.06      0.85      0.09      0.34      0.11        71\n",
      "\n",
      "avg / total       0.41      0.52      0.39      0.43      0.34      0.12       171\n",
      "\n",
      "Accuracy =  0.520467836257\n",
      "feature name:  ADHFeatures_maxCooc10_k95_OnlyNuclei.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "[5, 10, 109, 294]\n",
      "418 (418, 23) 171 (171, 23)\n",
      "{'randomforestclassifier__n_estimators': 10, 'randomforestclassifier__max_depth': 5, 'smote__k_neighbors': 9, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.97      0.99      0.27      0.98      0.62      0.41       403\n",
      "          1       0.40      0.27      0.99      0.32      0.62      0.37        15\n",
      "\n",
      "avg / total       0.95      0.96      0.29      0.96      0.62      0.41       418\n",
      "\n",
      "Accuracy =  0.959330143541\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.58      0.96      0.03      0.72      0.44      0.20       100\n",
      "          1       0.33      0.03      0.96      0.05      0.44      0.19        71\n",
      "\n",
      "avg / total       0.48      0.57      0.42      0.45      0.44      0.19       171\n",
      "\n",
      "Accuracy =  0.573099415205\n",
      "feature name:  ADHFeatures_maxCooc5_k90_OnlyObjects.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "[5, 10, 109, 294]\n",
      "418 (418, 3) 171 (171, 3)\n",
      "{'randomforestclassifier__n_estimators': 2, 'randomforestclassifier__max_depth': 10, 'smote__k_neighbors': 7, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.91      0.73      0.95      0.49      0.25       403\n",
      "          1       0.24      0.73      0.91      0.36      0.49      0.22        15\n",
      "\n",
      "avg / total       0.96      0.91      0.74      0.93      0.49      0.25       418\n",
      "\n",
      "Accuracy =  0.906698564593\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.56      0.82      0.08      0.66      0.37      0.14       100\n",
      "          1       0.25      0.08      0.82      0.13      0.37      0.14        71\n",
      "\n",
      "avg / total       0.43      0.51      0.39      0.44      0.37      0.14       171\n",
      "\n",
      "Accuracy =  0.514619883041\n",
      "feature name:  ADHFeatures_maxCooc5_k95_OnlyObjects.xls\n",
      "{'Normal Duct': 0, 'Columnar': 0, 'ADH': 1, 'Flat Epithelial': 1}\n",
      "[5, 10, 109, 294]\n",
      "418 (418, 7) 171 (171, 7)\n",
      "{'randomforestclassifier__n_estimators': 50, 'randomforestclassifier__max_depth': 10, 'smote__k_neighbors': 7, 'randomforestclassifier__max_features': 'auto'}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.85      1.00      0.92      0.45      0.22       403\n",
      "          1       0.20      1.00      0.85      0.33      0.45      0.18        15\n",
      "\n",
      "avg / total       0.97      0.86      0.99      0.90      0.45      0.21       418\n",
      "\n",
      "Accuracy =  0.856459330144\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.53      0.73      0.08      0.61      0.31      0.10       100\n",
      "          1       0.18      0.08      0.73      0.12      0.31      0.09        71\n",
      "\n",
      "avg / total       0.38      0.46      0.35      0.41      0.31      0.10       171\n",
      "\n",
      "Accuracy =  0.461988304094\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(len(feature_fnames)):\n",
    "    print('feature name: ', feature_fnames[i])\n",
    "    X_train, y_train, X_test, y_test = read_data(input_dir, feature_fnames[i], reduced_gt)\n",
    "    #print(len(accepted_indx))\n",
    "    #print(len(y_train[1]))\n",
    "    for dict_map in [malig_map]:\n",
    "        print(dict_map)\n",
    "        #print(len(y_train[1]), X_train.shape)\n",
    "        accepted_indx = np.nonzero(np.asarray([a in accepted_labels for a in y_train[1]]))[0]\n",
    "        y_train_new = [y_train[1][j] for j in accepted_indx]\n",
    "        print([np.sum(np.asarray([y_train_new[j] in [a] for j in \n",
    "                            xrange(len(y_train_new))])) for a in accepted_labels])\n",
    "        X_train = X_train[accepted_indx,:]\n",
    "        y_train_new = [dict_map[a] for a in y_train_new]\n",
    "        y_test_new = [dict_map[b] for b in y_test[1]]\n",
    "        score = 'recall'\n",
    "        print(len(y_train_new), X_train.shape, len(y_test_new), X_test.shape)\n",
    "        tuned_parameters = {'randomforestclassifier__n_estimators':[2, 10, 25, 50], \n",
    "                            'randomforestclassifier__max_features':['auto','log2'],\n",
    "                            'randomforestclassifier__max_depth':[5,10,None],\n",
    "                           'smote__k_neighbors':param_range}#, 'smote__ratio': np.arange(0.2,1,step=0.2)}\n",
    "\n",
    "        smote = over_sampling.SMOTE(random_state=RANDOM_STATE, kind = 'borderline1')\n",
    "        #cart = tree.DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "        cart = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "        pipeline = pl.make_pipeline(smote, cart)\n",
    "\n",
    "        clf = GridSearchCV(pipeline,param_grid=tuned_parameters,\n",
    "                               cv = 6, scoring= '%s_macro' %score, n_jobs = 7)\n",
    "        clf.fit(X_train,y_train_new)\n",
    "        print(clf.best_params_)\n",
    "        print('Training result')\n",
    "        print(classification_report_imbalanced(y_train_new, clf.predict(X_train)))\n",
    "        print('Accuracy = ', metrics.accuracy_score(y_train_new, clf.predict(X_train)))\n",
    "        print(classification_report_imbalanced(y_test_new, clf.predict(X_test)))\n",
    "        print('Accuracy = ', metrics.accuracy_score(y_test_new, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "nuc_feats_mean_std_zscore.csv (833, 392) (605, 392)\n",
      "\n",
      "\n",
      "{'Normal Duct': 0, 'Flat Epithelial': 1, 'Columnar': 0, 'ADH': 1, 'Flat epithelial': 1}\n",
      "\n",
      "Optimized for recall\n",
      "{'C': 10000.0}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      1.00      1.00      1.00      1.00       585\n",
      "          1       1.00      1.00      1.00      1.00      1.00      1.00       248\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1.00      1.00      1.00       833\n",
      "\n",
      "Accuracy =  1.0\n",
      "roc_auc =  1.0\n",
      "Confusion matrix\n",
      "[[585   0]\n",
      " [  0 248]]\n",
      "Testing result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.94      0.76      0.65      0.84      0.50      0.27       534\n",
      "          1       0.27      0.65      0.76      0.38      0.50      0.23        71\n",
      "\n",
      "avg / total       0.86      0.75      0.66      0.79      0.50      0.26       605\n",
      "\n",
      "Accuracy =  0.748760330579\n",
      "roc_auc =  0.705029804294\n",
      "Confusion matrix\n",
      "[[407 127]\n",
      " [ 25  46]]\n",
      "\n",
      "\n",
      "nuc_feats_mean_std.csv (833, 392) (605, 392)\n",
      "\n",
      "\n",
      "{'Normal Duct': 0, 'Flat Epithelial': 1, 'Columnar': 0, 'ADH': 1, 'Flat epithelial': 1}\n",
      "\n",
      "Optimized for recall\n",
      "{'C': 10000.0}\n",
      "Training result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.99      0.97      0.99      0.98      0.97       585\n",
      "          1       0.98      0.97      0.99      0.97      0.98      0.96       248\n",
      "\n",
      "avg / total       0.98      0.98      0.98      0.98      0.98      0.96       833\n",
      "\n",
      "Accuracy =  0.984393757503\n",
      "roc_auc =  0.980758891646\n",
      "Confusion matrix\n",
      "[[579   6]\n",
      " [  7 241]]\n",
      "Testing result\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.95      0.78      0.66      0.85      0.52      0.28       534\n",
      "          1       0.28      0.66      0.78      0.39      0.52      0.25        71\n",
      "\n",
      "avg / total       0.87      0.76      0.68      0.80      0.52      0.28       605\n",
      "\n",
      "Accuracy =  0.761983471074\n",
      "roc_auc =  0.718626364931\n",
      "Confusion matrix\n",
      "[[414 120]\n",
      " [ 24  47]]\n"
     ]
    }
   ],
   "source": [
    "param_range = range(1, 15)\n",
    "for ss in settings:\n",
    "    train_df = pd.read_csv(os.path.join(input_dir,'ADHTrainFeatures_' + ss))\n",
    "    #train_df = pd.read_excel(os.path.join(input_dir,'ADHTrainFeatures_' + ss))\n",
    "    X_train = train_df[train_df.columns[3:]].as_matrix()\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    \n",
    "    test_df = pd.read_csv(os.path.join(input_dir,'ADHTestFeatures_' + ss))\n",
    "    #test_df = pd.read_excel(os.path.join(input_dir,'ADHTestFeatures_' + ss))\n",
    "    X_test = test_df[test_df.columns[3:]].as_matrix()\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    print('\\n')\n",
    "    print(ss, X_train.shape, X_test.shape)\n",
    "    for dict_map in [malig_map]: #[fourway_map]: \n",
    "        print('\\n')\n",
    "        print(dict_map)\n",
    "        y_train = [dict_map[a] for a in list(train_df['label'])]\n",
    "        y_test = [dict_map[a] for a in list(test_df['label'])]        \n",
    "        #scores = ['precision', 'recall','f1']\n",
    "        scores = ['recall']\n",
    "        #scores = ['roc_auc']\n",
    "        #scores = ['f1_micro', 'f1_macro','f1_weighted','accuracy']#,'cohen_kappa']\n",
    "        #scorers = [metrics.make_scorer(metrics.f1_score), metrics.scorer(metrics.recall_score),\n",
    "        #           metrics.make_scorer(metrics.roc_auc_score), metrics.make_scorer(metrics.cohen_kappa_score)]\n",
    "        #for score,scorer in zip(scores, scorers):\n",
    "        for score in scores:\n",
    "            print('\\nOptimized for %s' %score)\n",
    "            tuned_parameters = {'C': [1e3, 1e4, 1e5]}#, 'smote__ratio': np.arange(0.2,1,step=0.2)}\n",
    "            cart = sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "            clf = GridSearchCV(cart,param_grid=tuned_parameters,\n",
    "                                   cv = 3, scoring= '%s' %score, n_jobs = 7)\n",
    "            clf.fit(X_train,y_train)\n",
    "            print(clf.best_params_)\n",
    "            print('Training result')\n",
    "            print(classification_report_imbalanced(y_train, clf.predict(X_train)))\n",
    "            print('Accuracy = ', metrics.accuracy_score(y_train, clf.predict(X_train)))\n",
    "            print('roc_auc = ', metrics.roc_auc_score(y_train, clf.predict(X_train)))\n",
    "            #print('F1micro = ', metrics.f1_score(y_train, clf.predict(X_train), average='micro'))\n",
    "            #print('F1macro = ', metrics.f1_score(y_train, clf.predict(X_train), average='macro'))\n",
    "            #print('F1weighted = ', metrics.f1_score(y_train, clf.predict(X_train), average='weighted'))\n",
    "            print('Confusion matrix')\n",
    "            print(metrics.confusion_matrix(y_train, clf.predict(X_train)))\n",
    "            print('Testing result')\n",
    "            print(classification_report_imbalanced(y_test, clf.predict(X_test)))\n",
    "            print('Accuracy = ', metrics.accuracy_score(y_test, clf.predict(X_test)))\n",
    "            print('roc_auc = ', metrics.roc_auc_score(y_test, clf.predict(X_test)))\n",
    "            #print('F1micro = ', metrics.f1_score(y_test, clf.predict(X_test), average='micro'))\n",
    "            #print('F1macro = ', metrics.f1_score(y_test, clf.predict(X_test), average='macro'))\n",
    "            #print('F1weighted = ', metrics.f1_score(y_test, clf.predict(X_test), average='weighted'))\n",
    "            print('Confusion matrix')\n",
    "            print(metrics.confusion_matrix(y_test, clf.predict(X_test)))\n",
    "            #y_pred_probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:sql]",
   "language": "python",
   "name": "conda-env-sql-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
